{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Welcome to the Cyber Defence Kit","text":""},{"location":"index.html#introduction","title":"Introduction","text":"<p>The Cyber Defence Kit is a cybersecurity toolkit designed to enhance your organisation's cybersecurity posture. It combines a selection of open-source and proprietary tools, methodologies, and best practices to help you proactively detect, respond to, and mitigate cybersecurity threats.</p> <p></p>"},{"location":"index.html#getting-started","title":"Getting Started","text":"<p>To begin leveraging the Cyber Defence Kit:</p> <ol> <li> <p>Understand the Toolkit:</p> <ul> <li>Familiarise yourself with the components of the kit.</li> <li>Review the Project Overview for a high-level understanding.</li> </ul> </li> <li> <p>Set Up Your Environment:</p> <ul> <li>Ensure you have the necessary hardware and software prerequisites.</li> <li>Prepare your systems for installation (e.g., air-gapped environment considerations).</li> </ul> </li> <li> <p>Install Core Components:</p> <ul> <li>Start with the SIEM solutions</li> <li>Refer to installtion guide for Splunk and Wazuh</li> </ul> </li> <li> <p>Learn and Explore:</p> <ul> <li>Explore proof of concept videos and documentation on attack simulation.</li> </ul> </li> </ol>"},{"location":"index.html#documentation-navigation","title":"Documentation Navigation","text":"<ul> <li>Project Overview: Detailed information about the project's objectives, scope, and phases.</li> <li>Understanding SIEM: An introduction to SIEM, its importance, and how it benefits your organisation.</li> <li>Splunk: Installation and configuration guides for Splunk Enterprise and Universal Forwarder.</li> <li>Wazuh: Steps to set up Wazuh for endpoint detection and response.</li> </ul>"},{"location":"index.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Technical Expertise: Basic understanding of cybersecurity principles and system administration.</li> <li>Hardware Requirements: Servers or virtual machines meeting the minimum specifications.</li> <li>Access Rights: Administrative privileges to install and configure software.</li> </ul>"},{"location":"index.html#support-and-resources","title":"Support and Resources","text":"<ul> <li>Online Resources: Access free online training materials, tutorials, and documentation.</li> <li>Assistance: Reach out to the cybersecurity team via internal support channels for help.</li> </ul>"},{"location":"index.html#important-notes","title":"Important Notes","text":"<ul> <li>Security First: Always follow security best practices when installing and configuring tools.</li> <li>Air-Gapped Environments: Special considerations are required for installations without internet access.</li> <li>Legal Compliance: Ensure all activities comply with legal and regulatory requirements.</li> </ul>"},{"location":"index.html#next-steps","title":"Next Steps","text":"<ul> <li>Proceed to the Project Overview to understand the detailed objectives and plan.</li> <li>Dive into Understanding SIEM to grasp the fundamentals of Security Information and Event Management.</li> </ul>"},{"location":"CDK-explained/CDK-explained.html","title":"Cyber Defence Kit Explained","text":""},{"location":"CDK-explained/CDK-explained.html#why-is-cybersecurity-important-to-us","title":"Why is Cybersecurity Important to Us?","text":"<p>In our increasingly digital world, protecting our organisation's information and systems from cyber threats is crucial. Cyber attacks can lead to:</p> <ul> <li>Loss of Sensitive Data: Confidential information could be stolen.</li> <li>Operational Disruptions: Our daily activities might be halted.</li> <li>Damage to Reputation: Trust from our clients and partners could diminish.</li> </ul> <p>Real-World Examples:</p> <ul> <li>Increased Cyber Threats: New Zealand's National Cyber Security Centre (NCSC) has reported a rise in cyber incidents targeting both public and private sectors, including attempts to access sensitive government information.</li> </ul>"},{"location":"CDK-explained/CDK-explained.html#what-is-cyber-defence-kit","title":"What is Cyber Defence Kit?","text":"<p>The Cyber Defence Kit is our initiative to strengthen our defences against cyber threats. We aim to:</p> <ul> <li>Enhance Protection: Implement advanced tools to better safeguard our systems.</li> <li>Improve Detection: Quickly identify potential security issues.</li> <li>Automate Responses: Speed up how we react to threats to minimise impact.</li> <li>Ensure Compliance: Meet all necessary cybersecurity standards and regulations.</li> <li>Promote Proactive Security: Stay ahead of threats before they become problems.</li> </ul> <p></p>"},{"location":"CDK-explained/CDK-explained.html#how-will-we-achieve-this","title":"How Will We Achieve This?","text":"<p>We plan to introduce several tools and practices:</p> <ol> <li>Advanced Monitoring Systems:<ul> <li>Tools that watch over our network to spot unusual activities.</li> <li>They alert us immediately if something suspicious happens.</li> </ul> </li> <li>Automated Response Mechanisms:<ul> <li>Systems that can automatically take action against certain threats.</li> <li>This speeds up our response time and reduces manual effort.</li> </ul> </li> <li>Improved Incident Management:<ul> <li>A structured way to handle any security incidents.</li> <li>Ensures we address issues efficiently and learn from them.</li> </ul> </li> <li>Enhanced Endpoint Protection:<ul> <li>Better security for individual devices like computers and servers.</li> <li>Protects against malware and unauthorized access.</li> </ul> </li> <li>Staff Awareness and Support:<ul> <li>Providing resources and assistance to help everyone understand these new tools.</li> <li>Encouraging a culture where cybersecurity is everyone's responsibility.</li> </ul> </li> </ol>"},{"location":"CDK-explained/CDK-explained.html#what-does-this-mean-for-you","title":"What Does This Mean for You?","text":"<ul> <li>Safer Work Environment: Reduced risk of cyber attacks affecting your work.</li> <li>Better Tools and Support: Access to improved systems that protect your daily activities.</li> <li>Peace of Mind: Confidence that our organization's information is secure.</li> <li>Compliance Assurance: Knowing we meet industry standards protects us legally and ethically.</li> </ul>"},{"location":"CDK-explained/CDK-explained.html#using-plain-language","title":"Using Plain Language","text":"<ul> <li>Cyber Threats: Bad activities that try to harm our computer systems or steal information.</li> <li>Monitoring Tools: Programs that keep an eye on our systems to ensure everything is normal.</li> <li>Automated Responses: Actions taken by our systems without needing manual input when a threat is detected.</li> <li>Incident Management: The process we follow when dealing with security problems.</li> <li>Endpoint Protection: Security measures for devices like laptops and smartphones.</li> </ul>"},{"location":"CDK-explained/CDK-explained.html#why-this-matters","title":"Why This Matters","text":"<p>By implementing the Cyber Defence Kit, we are taking important steps to:</p> <ul> <li>Protect Our Assets: Keeping our information and systems secure.</li> <li>Support Our Mission: Ensuring we can carry out our work without disruptions.</li> <li>Maintain Trust: Showing our clients and partners that we take security seriously.</li> <li>Stay Ahead: Being proactive rather than reactive to cyber threats.</li> </ul>"},{"location":"CDK-explained/CDK-explained.html#summary","title":"Summary","text":"<p>Our goal is to create a secure and efficient environment where everyone can perform their best work without worrying about cyber threats. The Cyber Defence Kit project is our commitment to safeguarding our organisation now and in the future.</p>"},{"location":"project-overview/project-overview.html","title":"Project Overview","text":""},{"location":"project-overview/project-overview.html#1-executive-summary","title":"1. Executive Summary","text":""},{"location":"project-overview/project-overview.html#11-purpose-of-cyber-defence-kit","title":"1.1 Purpose of Cyber Defence Kit","text":"<p>The main purpose of project Cyber Defence Kit is to enhance the cybersecurity infrastructure of our organisation. By researching and implementing cybersecurity tools in a phased approach\u2014starting with Security Information and Event Management (SIEM) tools, specifically Splunk and Wazuh\u2014the project aims to:</p> <ul> <li>Strengthen cyber defence capabilities</li> <li>Integrate advanced cybersecurity tools</li> <li>Enhance threat detection and response</li> <li>Automate security operations</li> <li>Ensure compliance with cybersecurity standards</li> <li>Promote a proactive security posture</li> </ul> <p>This phased implementation allows us to focus on establishing a strong foundation with SIEM solutions before gradually introducing additional tools like Security Orchestration, Automation, and Response (SOAR), Incident Response and Case Management, Intrusion Detection and Prevention Systems (IDS/IPS), Endpoint Detection and Response (EDR), Extended Detection and Response (XDR), and Digital Forensics and Incident Response (DFIR).</p> <p>This project aligns with our strategic goal of protecting our assets and developing a small Security Operations Center (SOC) within our organisation. By integrating these tools and practices gradually, we will enhance our ability to proactively detect, respond to, and mitigate cybersecurity threats.</p>"},{"location":"project-overview/project-overview.html#2-background-and-introduction","title":"2. Background and Introduction","text":""},{"location":"project-overview/project-overview.html#21-current-cybersecurity-posture","title":"2.1 Current Cybersecurity Posture","text":"<p>Understanding our current cybersecurity posture is crucial for identifying gaps and areas for improvement as we implement the Cyber Defence Kit. Presently, our organisation's cybersecurity infrastructure includes the following components:</p> <ul> <li>Vulnerability Management<ul> <li>Nessus Vulnerability Scanner<ul> <li>Function: Performs periodic scans to identify known vulnerabilities and misconfigurations.</li> <li>Strength: Provides comprehensive reports to prioritise remediation efforts.</li> </ul> </li> </ul> </li> <li>Endpoint Protection<ul> <li>Trend Micro Endpoint Detection and Response (EDR)<ul> <li>Function: Detects and blocks malware and monitors endpoint activities for suspicious behavior.</li> <li>Strength: Leverages threat intelligence for up-to-date protection.</li> </ul> </li> <li>Windows Defender (EDR)<ul> <li>Function: Offers basic real-time protection against common threats on Windows devices.</li> <li>Strength: Integrates seamlessly with Windows OS and provides regular updates.</li> </ul> </li> </ul> </li> </ul>"},{"location":"project-overview/project-overview.html#strengths","title":"Strengths","text":"<ul> <li>Foundational Security Measures: Basic protection against common cyber threats is in place.</li> <li>Regular Vulnerability Assessments: Nessus helps identify and address known vulnerabilities.</li> <li>Endpoint Protection Layer: Trend Micro EDR and Windows Defender offer a layer of defence at the endpoint level.</li> </ul>"},{"location":"project-overview/project-overview.html#weaknesses-and-gaps","title":"Weaknesses and Gaps","text":"<ol> <li>Lack of Centralised Monitoring and Incident Management<ul> <li>No SIEM Solution: Limited visibility into security events across the network.</li> <li>No SOAR Capabilities: Incident response processes are manual and slow.</li> <li>No Incident Response Platform: Inefficient handling of security incidents.</li> </ul> </li> <li>Limited Threat Detection Capabilities<ul> <li>No IDS/IPS Deployment: Absence of real-time network traffic analysis.</li> <li>No Network Traffic Analyser: Limited insight into network behaviors and anomalies.</li> </ul> </li> <li>Endpoint Security Limitations<ul> <li>Inconsistent EDR Deployment: Potential security policy inconsistencies.</li> <li>Lack of Advanced Features: Current EDR solutions may not detect sophisticated threats.</li> </ul> </li> <li>No Extended Detection and Response (XDR)<ul> <li>Limited Cross-Platform Detection: Cannot correlate threats across multiple security layers.</li> </ul> </li> <li>No Digital Forensics and Incident Response (DFIR) Capability<ul> <li>Inability to Investigate Incidents Thoroughly: Hinders in-depth incident analysis.</li> <li>Compliance Risks: Potential non-compliance due to inadequate incident response processes.</li> </ul> </li> </ol>"},{"location":"project-overview/project-overview.html#recommendations","title":"Recommendations","text":"<ol> <li>Phase 1: Implement SIEM Solution<ul> <li>Deploy SIEM Platforms: Begin with Splunk and Wazuh for centralised event monitoring.</li> <li>Integrate XDR Capabilities: Through Wazuh, explore XDR solutions for cross-platform threat detection.</li> </ul> </li> <li>Subsequent Phases: Gradually Introduce Additional Tools<ul> <li>Adopt SOAR Technology: Introduce SOAR tools such as Shuffle to automate and orchestrate security workflows.</li> <li>Deploy IDS/IPS and Network Traffic Analysis Tools: Use tools like Suricata, Snort, and Zeek for real-time network monitoring.</li> <li>Establish Incident Response and Case Management System: Implement a platform like TheHive for managing security incidents.</li> <li>Develop DFIR Capabilities: Introduce tools such as Velociraptor for digital forensics and incident response.</li> </ul> </li> </ol> <p>By focusing on SIEM implementation first, we address the most critical gap in our cybersecurity posture\u2014lack of centralised monitoring\u2014and lay the groundwork for future enhancements.</p>"},{"location":"project-overview/project-overview.html#22-introduction-to-project-cyber-defence-kit","title":"2.2 Introduction to Project Cyber Defence Kit","text":"<p>By addressing these gaps through a phased approach in Project Cyber Defence Kit, we aim to:</p> <ul> <li>Mitigate Risks: Reduce the likelihood and impact of security incidents.</li> <li>Enhance Compliance: Meet industry and military cybersecurity standards.</li> <li>Improve Operational Efficiency: Automate processes and improve response times.</li> <li>Support Strategic Goals: Protect critical assets and ensure mission success.</li> </ul>"},{"location":"project-overview/project-overview.html#3-project-objectives","title":"3. Project Objectives","text":"<ul> <li>Phase 1: Research and implement SIEM tools (Splunk and Wazuh) to enhance security infrastructure.</li> <li>Subsequent Phases: Gradually research and implement additional cybersecurity tools (SOAR, Incident Response and Case Management, IDS/IPS, EDR, DFIR).</li> <li>Integrate solutions for streamlined operations.</li> <li>Improve threat detection and response times.</li> <li>Comply with military cybersecurity standards.</li> </ul>"},{"location":"project-overview/project-overview.html#4-project-scope","title":"4. Project Scope","text":""},{"location":"project-overview/project-overview.html#41-in-scope","title":"4.1 In-Scope","text":"<p>Phase 1: - SIEM Tools: Splunk and Wazuh - Research and implementation of the SIEM solutions. - Introductory Training Sessions: We will offer beginner-level training to help you get started with the SIEM tools and understand the basics of configuring and using them. - Documentation and proof-of-concept videos for the SIEM tools. Future Phases: - Introduction of additional tools like Shuffle, TheHive, Zeek, Snort, Suricata, and Velociraptor.</p>"},{"location":"project-overview/project-overview.html#42-out-of-scope","title":"4.2 Out-of-Scope","text":"<ul> <li>Phase 1:<ul> <li>In-depth staff training for SIEM tools: Comprehensive training beyond the introductory sessions is not included. Free training materials are available online; assistance can be provided if required.</li> <li>Upgrades to unrelated IT infrastructure.</li> </ul> </li> <li>Future Phases:<ul> <li>Implementation and training for additional tools (to be addressed in subsequent project iterations).</li> </ul> </li> </ul>"},{"location":"project-overview/project-overview.html#5-methodology-and-approach","title":"5. Methodology and Approach","text":""},{"location":"project-overview/project-overview.html#51-phase-1-siem-implementation","title":"5.1 Phase 1: SIEM Implementation","text":""},{"location":"project-overview/project-overview.html#research-and-selection","title":"Research and Selection","text":"<ul> <li>Conduct Research: Investigate SIEM tools, focusing on Splunk and Wazuh.</li> <li>Evaluate Tools: Determine the best fit for our organisational needs.</li> </ul>"},{"location":"project-overview/project-overview.html#implementation","title":"Implementation","text":"<ul> <li>Install and Configure: Set up Splunk and Wazuh in a testing environment.</li> <li>Design Proof of Concepts: Demonstrate SIEM capabilities and integration potential.</li> </ul>"},{"location":"project-overview/project-overview.html#testing-and-validation","title":"Testing and Validation","text":"<ul> <li>Deploy on Production Systems: Carefully roll out SIEM tools to live environments.</li> <li>Functional Testing: Ensure tools operate as intended and meet security requirements.</li> </ul>"},{"location":"project-overview/project-overview.html#documentation","title":"Documentation","text":"<ul> <li>Create User Manuals: Develop comprehensive guides for SIEM tools.</li> <li>Expert Review: Have documentation reviewed by cybersecurity experts.</li> </ul>"},{"location":"project-overview/project-overview.html#implementation-support-and-feedback","title":"Implementation Support and Feedback","text":"<ul> <li>Assist Operators: Support the implementation of SIEM tools into daily operations.</li> <li>Feedback Loop: Update tools based on operational feedback.</li> </ul>"},{"location":"project-overview/project-overview.html#52-future-phases","title":"5.2 Future Phases","text":"<ul> <li>Plan Subsequent Implementations: Develop detailed methodologies for introducing additional tools.</li> <li>Iterative Approach: Apply lessons learned from Phase 1 to future phases.</li> </ul>"},{"location":"project-overview/project-overview.html#6-draft-project-timeline","title":"6. Draft Project Timeline","text":""},{"location":"project-overview/project-overview.html#phase-1-siem-implementation","title":"Phase 1: SIEM Implementation","text":"<ul> <li>Phase 1.1: Research and Selection </li> <li>Phase 1.2: Implementation </li> <li>Phase 1.3: Testing and Validation </li> <li>Phase 1.4: Documentation </li> <li>Phase 1.5: Implementation Support and Feedback </li> </ul>"},{"location":"project-overview/project-overview.html#future-phases","title":"Future Phases","text":"<ul> <li>To Be Scheduled: Timelines for introducing additional tools will be planned after the successful completion of Phase 1.</li> </ul>"},{"location":"project-overview/project-overview.html#7-budget-estimate","title":"7. Budget Estimate","text":"<p>Phase 1: SIEM Implementation</p> <ul> <li>Splunk Licensing:<ul> <li>Free Trial Version: Limited capabilities suitable for initial testing.</li> <li>Enterprise Licence: Costs based on data ingestion rates; necessary for full functionality. Our company currently has access to Enterprise Licence.</li> </ul> </li> <li>Wazuh:<ul> <li>Open-Source: Free to use with community support.</li> <li>Paid Support (Optional): For additional features and professional support services.</li> </ul> </li> </ul> <p>Documentation:</p> <ul> <li>Use open-source documentation platforms compatible with an air-gapped environment.</li> <li>Consider paid documentation platforms for advanced features if needed.</li> </ul> <p>Contingency Fund:</p> <ul> <li>Allocate funds to address potential cost increases or the need for additional resources.</li> </ul> <p>Future Phases:</p> <ul> <li>Budget Planning: Costs for additional tools and training will be estimated in subsequent proposals.</li> </ul>"},{"location":"project-overview/project-overview.html#8-risk-assessment-and-mitigation","title":"8. Risk Assessment and Mitigation","text":"<p>Identify potential risks and mitigation strategies for Phase 1:</p> Risk Likelihood Impact Mitigation Strategy Integration challenges with existing systems High Medium Conduct compatibility assessments beforehand Cost changes for Splunk licensing Medium Medium Explore alternative SIEM solutions or adjust usage levels Staff unfamiliarity with SIEM tools Medium Medium Provide training resources and ongoing support Version changes to open-source tools High Low Regularly monitor for updates and apply patches as needed Data privacy concerns Low High Ensure compliance with data protection regulations"},{"location":"project-overview/project-overview.html#9-conclusion","title":"9. Conclusion","text":"<p>Cyber Defence Kit is essential for our organisation's security, starting with the implementation of SIEM tools in Phase 1. This phased approach will:</p> <ul> <li>Strengthen cybersecurity defences by implementing advanced SIEM solutions to detect and respond to threats effectively.</li> <li>Enhance compliance with cybersecurity standards, ensuring we meet all regulatory and operational requirements.</li> <li>Reduce the risk of cyber incidents, minimising potential operational disruptions and losses.</li> <li>Improve operational efficiency through automation, allowing our team to focus on strategic initiatives.</li> <li>Elevate trust with stakeholders and partners, reinforcing our reputation for security and reliability.</li> </ul> <p>By successfully implementing SIEM tools in the initial phase, the Cyber Defence Kit project not only fortifies our cyber defences but also sets the stage for introducing additional tools in future phases. This strategic, phased approach aligns with our mission to protect critical CIS assets and develop a Security Operations Centre (SOC) capability. By undertaking this initiative, we are taking essential steps to protect our organisation's future, improve operational readiness, and close the gap in our cybersecurity posture.</p>"},{"location":"snort/snort.html","title":"Snort","text":"<p>Snort is an open-source network intrusion detection and prevention system (IDS/IPS) maintained by Cisco Systems. It is designed to monitor network traffic in real-time, analysing packets for signs of malicious activity, such as attacks, probes, or scans. Snort uses a combination of protocol analysis, content searching, and various preprocessors to detect and prevent intrusions.</p>"},{"location":"snort/snort.html#install-snort3-on-host","title":"Install Snort3 on Host","text":"<p>In this demonstration, we will be installing Snort3 on an Ubuntu virtual machine. We will be simulating install in an air-gapped environment but note that some parts of the step requires internet connection.</p>"},{"location":"snort/snort.html#lab-setup-for-proof-of-concept","title":"Lab Setup for Proof of Concept","text":"<p>In this proof of concept, attack simulation was conducted on the Kali machine in a safe and controlled setting. </p> <p>Note: Do not attempt to replicate the attack simulation demonstrated here unless you are properly trained and it is safe to do so. Unauthorised attack simulation can lead to legal consequences and unintended damage to systems. Always ensure that such activities are conducted by qualified professionals in a secure, isolated environment.</p> Host OS Role IP Address pfsense FreeBSD (pfSense v2.7.2) Firewall/Router (Gateway IDS/IPS) 192.168.1.200 (WAN) / 10.0.0.2 (LAN) Snort Ubuntu 22.04 LTS Host IDS/IPS 10.0.0.22 WS2019 Windows Server 2019 Windows client 10.0.0.24 Kali Kali Linux 2024.2 Attacker machine 10.0.0.29"},{"location":"snort/snort.html#download-pre-requisites","title":"Download Pre-requisites","text":"<p>On a machine with internet connection:</p> <p>Make a folder called /snort/pre-reqs and cd into it.</p> <pre><code>mkdir snort/pre-reqs\ncd snort/pre-reqs\n</code></pre> <p>Update the package lists and upgrade all the installed packages on your system to the latest available versions.</p> <pre><code>sudo apt-get update &amp;&amp; sudo apt-get upgrade -y\n</code></pre> <p>Download the required packages and their dependencies as a root user:</p> <pre><code>apt-get install -y --download-only build-essential autotools-dev libdumbnet-dev libluajit-5.1-dev \\\nlibpcap-dev zlib1g-dev pkg-config libhwloc-dev cmake liblzma-dev openssl libssl-dev cpputest \\\nlibsqlite3-dev libtool uuid-dev git autoconf bison flex libcmocka-dev libnetfilter-queue-dev \\\nlibunwind-dev libmnl-dev ethtool libjemalloc-dev libpcre3-dev libpcre16-3 libpcre32-3 libpcrecpp0v5 -o Dir::Cache::archives=\"/home/cyber/snort/pre-reqs\"\n\n#apt-get download libpcre3-dev libpcre16-3 libpcre32-3 libpcrecpp0v5\n</code></pre> <p>If you get permission error, change the directory\u2019s permission</p> <p>Error message:</p> <pre><code>W: Download is performed unsandboxed as root as file '/home/cyber/snort/pre-reqs/libpcre16-3_2%3a8.39-13ubuntu0.22.04.1_amd64.deb' couldn't be accessed by user '_apt'. - pkgAcquire::Run (13: Permission denied)\n</code></pre> <p>Change the directory permission:</p> <pre><code>sudo chmod 755 /home/cyber/snort/pre-reqs\n</code></pre>"},{"location":"snort/snort.html#download-dependencies-and-snort3","title":"Download Dependencies and Snort3","text":"<p>Change directory into snort</p> <pre><code>cd ~/snort\n</code></pre> <p>Download dependencies (pcre, gperftools, ragel, boost, hyperscan, flatbuffers, libdaq, pulledpork3) and Snort by running:</p> <pre><code>wget https://github.com/PCRE2Project/pcre2/releases/download/pcre2-10.44/pcre2-10.44.tar.gz\nwget https://github.com/gperftools/gperftools/releases/download/gperftools-2.15/gperftools-2.15.tar.gz\nwget https://www.colm.net/files/ragel/ragel-6.10.tar.gz\nwget https://boostorg.jfrog.io/artifactory/main/release/1.86.0/source/boost_1_86_0.tar.gz\nwget [https://github.com/intel/hyperscan/archive/refs/tags/v5.4.2.tar.gz](https://github.com/intel/hyperscan/archive/refs/tags/v5.4.2.tar.gz) -O hyperscan-v5.4.2.tar.gz\nwget https://github.com/google/flatbuffers/archive/refs/tags/v2.0.0.tar.gz -O flatbuffers-v2.0.0.tar.gz\nwget https://github.com/snort3/libdaq/archive/refs/tags/v3.0.16.tar.gz -O libdaq-v3.0.16.tar.gz\nwget [https://github.com/snort3/snort3/archive/refs/tags/3.3.5.0.tar.gz](https://github.com/snort3/snort3/archive/refs/tags/3.3.5.0.tar.gz) -O snort3-3.3.5.0.tar.gz\ngit clone https://github.com/shirkdog/pulledpork3.git\n</code></pre>"},{"location":"snort/snort.html#install-pre-requisites","title":"Install Pre-requisites","text":"<p>Transfer the snort folder to your air-gapped host. </p> <p>Change directory into pre-reqs and install the downloaded <code>.deb</code> files using <code>dpkg</code>:</p> <pre><code>sudo dpkg -i *.deb\n</code></pre>"},{"location":"snort/snort.html#install-dependencies","title":"Install Dependencies","text":"<p>Change directory into snort folder and untar pcre2-10.44.tar.gz</p> <p>Change directory into pcre2-10.44 and run configure.</p> <p>Run make and then sudo make install.</p> <pre><code>tar -xzvf pcre2-10.44.tar.gz\ncd pcre2-10.44/\n./configure\nmake\nsudo make install\n</code></pre> <p>Repeat the same process for gperftools-2.15.tar.gz</p> <pre><code>tar -xzvf gperftools-2.15.tar.gz\ncd gperftools-2.15/\n./configure\nmake\nsudo make install\n</code></pre> <p>Repeat the same process for ragel</p> <pre><code>tar -xzvf ragel-6.10.tar.gz\ncd ragel-6.10\n./configure\nmake\nsudo make install\n</code></pre> <p>Untar Boost C++ Libraries:</p> <pre><code>tar -xvzf boost_1_86_0.tar.gz\n</code></pre> <p>For installing hyerperscan, run:</p> <pre><code>tar -xvzf hyperscan-v5.4.2.tar.gz\nmkdir ~/snort/hyperscan-5.4.2-build\ncd hyperscan-5.4.2-build/\ncmake -DCMAKE_INSTALL_PREFIX=/usr/local -DBOOST_ROOT=~/snort/boost_1_86_0/ ../hyperscan-5.4.2\nmake\nsudo make install\n</code></pre> <p>Install flatbuffers:</p> <pre><code>tar -xzvf flatbuffers-v2.0.0.tar.gz\nmkdir flatbuffers-build\ncd flatbuffers-build\ncmake ../flatbuffers-2.0.0\nmake\nsudo make install\n</code></pre> <p>Install Data Acquistion (DAQ) from Snort</p> <pre><code>tar -xzvf libdaq-v3.0.16.tar.gz\ncd libdaq-3.0.16\n./bootstrap\n./configure\nmake\nsudo make install\n</code></pre> <p>Update the system's dynamic linker run-time bindings (shared libraries)</p> <pre><code>sudo ldconfig\n</code></pre> <p>Install the latest version of Snort 3</p> <pre><code>tar -xzvf snort3-3.3.5.0.tar.gz\ncd snort3-3.3.5.0/\n./configure_cmake.sh --prefix=/usr/local --enable-jemalloc\ncd build\nmake\nsudo make install\n</code></pre> <p>Verify Snort3 is installed by running:</p> <pre><code>/usr/local/bin/snort -V\n\n   ,,_     -*&gt; Snort++ &lt;*-\n  o\"  )~   Version 3.3.5.0\n   ''''    By Martin Roesch &amp; The Snort Team\n           http://snort.org/contact#team\n           Copyright (C) 2014-2024 Cisco and/or its affiliates. All rights reserved.\n           Copyright (C) 1998-2013 Sourcefire, Inc., et al.\n           Using DAQ version 3.0.16\n           Using Hyperscan version 5.4.2 2024-09-10\n           Using Jemalloc version 5.2.1-0-gea6b3e973b477b8061e0076bb257dbd7f3faa756\n           Using libpcap version 1.10.1 (with TPACKET_V3)\n           Using LuaJIT version 2.1.0-beta3\n           Using LZMA version 5.2.5\n           Using OpenSSL 3.0.2 15 Mar 2022\n           Using PCRE version 8.39 2016-06-14\n           Using ZLIB version 1.2.11\n</code></pre> <p>Test snort by using its default config file:</p> <pre><code>snort -c /usr/local/etc/snort/snort.lua\n...\nSnort successfully validated the configuration (with 0 warnings).\n</code></pre> <p>Find your network interface by running <code>ip a</code></p> <pre><code>ip a\n...\n2: **ens32**: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UNKNOWN group default qlen 1000\n    link/ether 00:0c:29:86:08:64 brd ff:ff:ff:ff:ff:ff\n    altname enp2s0\n    inet 10.0.0.22/24 brd 10.0.0.255 scope global dynamic noprefixroute ens32\n</code></pre> <p>Run following:</p> <pre><code>sudo ethtool -k ens32 | grep receive-offload\n...\ngeneric-receive-offload: on\nlarge-receive-offload: off [fixed]\n</code></pre> <p>Create a service to disable Large Receive Offload (LRO)</p> <pre><code>sudo nano /lib/systemd/system/ethtool.service\n</code></pre> <p>Copy and paste following:</p> <p>Put your network interface </p> <pre><code>[Unit]\nDescription=Ethtool Configration for Network Interface\n\n[Service]\nRequires=network.target\nType=oneshot\nExecStart=/sbin/ethtool -K ens32 gro off\nExecStart=/sbin/ethtool -K ens32 lro off\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Enable and start the service</p> <pre><code>sudo systemctl enable ethtool\nsudo service ethtool start\n</code></pre> <p>Verify that LRO is disabled by running</p> <pre><code>sudo ethtool -k ens32 | grep receive-offload\n...\ngeneric-receive-offload: off\nlarge-receive-offload: off [fixed]\n</code></pre>"},{"location":"snort/snort.html#test-ids-with-local-rules","title":"Test IDS with local rules","text":"<p>Create a folder called rules in the following directory</p> <pre><code>sudo mkdir /usr/local/etc/rules\n</code></pre> <p>Create a file called local.rules</p> <pre><code>sudo nano /usr/local/etc/rules/local.rules\n</code></pre> <p>Copy and paste following</p> <p>First alert detects any ICMP Ping traffic and second alert detects any SSH Authentication Attempt to our internal network </p> <pre><code>alert icmp any any -&gt; $HOME_NET any (msg:\"ICMP Ping Detected\"; sid:1000001; rev:1;)\nalert tcp any any -&gt; $HOME_NET 22 (msg:\"SSH Authentication Attempt\"; sid:1000002; rev:1;)\n</code></pre> <p>Run snort with configuration file to test the rule</p> <pre><code>snort -c /usr/local/etc/snort/snort.lua -R /usr/local/etc/rules/local.rules\n...\nSnort successfully validated the configuration (with 0 warnings).\n</code></pre> <p>Run snort to generate alert in a single line</p> <p>Snort will be listening on ens32 for any icmp traffic</p> <pre><code>sudo snort -c /usr/local/etc/snort/snort.lua -R /usr/local/etc/rules/local.rules -i ens32 -A alert_fast\n</code></pre> <p>From another Linux host, execute ping and attempt ssh to 10.0.0.22. This will generate alerts on terminal verifying that the rule works:</p> <pre><code>09/11-22:01:05.659667 [**] [1:1000002:1] \"SSH Authentication Attempt\" [**] [Priority: 0] {TCP} 10.0.0.21:36708 -&gt; 10.0.0.22:22\n09/11-22:01:19.086427 [**] [1:1000001:1] \"ICMP Ping Detected\" [**] [Priority: 0] {ICMP} 10.0.0.21 -&gt; 10.0.0.22\n</code></pre> <p>Edit Snort\u2019s configuration </p> <pre><code>sudo nano /usr/local/etc/snort/snort.lua\n</code></pre> <p>For HOME_NET, setup the network addresses you are protecting.</p> <p>For EXTERNAL_NET, leave as any.</p> <p>In the ips section, uncomment enable_builtin_rules = true and add include = \u201c/usr/local/etc/rules/local.rules\u201d, (include comma)</p> <p>In the configure ourputs section uncomment alert_fast = {file=true} to enable logging for the alerts</p> <pre><code>-- HOME_NET and EXTERNAL_NET must be set now\n-- setup the network addresses you are protecting\n**HOME_NET = '10.0.0.0/24'**\n\n-- set up the external network addresses.\n-- (leave as \"any\" in most situations)\nEXTERNAL_NET = 'any'\n...\nips =\n{\n    -- use this to enable decoder and inspector alerts\n    **enable_builtin_rules = true,**\n\n    -- use include for rules files; be sure to set your path\n    -- note that rules files can include other rules files\n    -- (see also related path vars at the top of snort_defaults.lua)\n    **include = \"/usr/local/etc/rules/local.rules\",**\n    variables = default_variables\n}\n...\n---------------------------------------------------------------------------\n-- 7. configure outputs\n---------------------------------------------------------------------------\n-- event logging\n-- you can enable with defaults from the command line with -A &lt;alert_type&gt;\n-- uncomment below to set non-default configs\n--alert_csv = { }\n**alert_fast = {file=true}**\n</code></pre> <p>Run snort to generate alert in a single line but exclude entry for local rules.</p> <p>Snort will be listening on ens32 for any icmp traffic</p> <pre><code>sudo snort -c /usr/local/etc/snort/snort.lua -i ens32 -A alert_fast\n</code></pre> <p>Verify that alerts are generated from ping</p> <pre><code>09/11-21:41:15.522160 [**] [1:1000001:1] \"ICMP Ping Detected\" [**] [Priority: 0] {ICMP} 10.0.0.24 -&gt; 10.0.0.22\n09/11-21:41:15.522206 [**] [1:1000001:1] \"ICMP Ping Detected\" [**] [Priority: 0] {ICMP} 10.0.0.22 -&gt; 10.0.0.24\n</code></pre> <p>To output alert_fast as a text log file, run</p> <pre><code>mkdir /var/log/snort\nsudo chown -R 1000:1000 /var/log/snort\n...\nsudo snort -c /usr/local/etc/snort/snort.lua -i ens32 -A alert_fast -l /var/log/snort\n</code></pre> <p>Verify that alert_fast.txt file is generated</p> <pre><code>ls /var/log/snort\n...\ncat /var/log/snort/alert_fast.txt\n...\n09/11-23:16:18.831740 [**] [1:1000001:1] \"ICMP Ping Detected\" [**] [Priority: 0] {ICMP} 10.0.0.21 -&gt; 10.0.0.22\n09/11-23:16:37.707792 [**] [1:1000002:1] \"SSH Authentication Attempt\" [**] [Priority: 0] {TCP} 10.0.0.21:60514 -&gt; 10.0.0.22:22\n</code></pre>"},{"location":"snort/snort.html#install-pulledpork3","title":"Install Pulledpork3","text":"<p>Note <code>git clone https://github.com/shirkdog/pulledpork3.git</code> command was run when downloading dependencies.</p> <pre><code>cd ~/snort/pulledpork3\nsudo mkdir /usr/local/bin/pulledpork3\nsudo cp pulledpork.py /usr/local/bin/pulledpork3\nsudo cp -r lib/ /usr/local/bin/pulledpork3\nsudo chmod +x /usr/local/bin/pulledpork3/pulledpork.py\nsudo mkdir /usr/local/etc/pulledpork3\nsudo cp etc/pulledpork.conf /usr/local/etc/pulledpork3/\n</code></pre> <p>Verify that pulled pork is running</p> <pre><code>/usr/local/bin/pulledpork3/pulledpork.py -V\n\nPulledPork v3.0.0.5\n\n    https://github.com/shirkdog/pulledpork3\n      _____ ____\n     `----,\\    )   PulledPork v3.0.0.5\n      `--==\\\\  /    Lowcountry yellow mustard bbq sauce is the best bbq sauce. Fight me.\n       `--==\\\\/\n     .-~~~~-.Y|\\\\_  Copyright (C) 2021 Noah Dietrich, Colin Grady, Michael Shirk\n  @_/        /  66\\_  and the PulledPork Team!\n    |    \\   \\   _(\")\n     \\   /-| ||'--'   Rules give me wings!\n      \\_\\  \\_\\\\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre> <p>Edit pulledpork.conf </p> <pre><code>sudo nano /usr/local/etc/pulledpork3/pulledpork.conf\n</code></pre> <p>Change the community ruleset value to true.</p> <p>Yon can select registered ruleset but due to incompatibility between registered ruleset version (3.1.7.0) and the snort version (3.3.5.0), selecting registered ruleset will give you an error. Either install Snort v 3.1.X.X or wait for registered ruleset version (3.3.X.X) to get released or use the community ruleset in the meantime. </p> <p>Copy and paste your Oinkcode (API Key). This step is optional.</p> <p>Comment out blocklist_path</p> <p>Uncomment snort_path and make sure it is set to the right path</p> <p>Uncomment local_rules and make sure it is set to the right path</p> <p>Comment sorule_path (optional but if uncommented, make a directory /usr/local/etc/so_rules/)</p> <pre><code># Which Snort/Talos rulesets do you want to download (recomended: choose only one)\ncommunity_ruleset = true\nregistered_ruleset = false\nLightSPD_ruleset = false\n\n# Your Snort oinkcode is required for snort/talos Subscription, Light_SPD, and Registered rules&gt;\noinkcode = \n\n# Where to write the blocklist file (single file containing all blocklists downloaded)\n#blocklist_path = /usr/local/etc/lists/default.blocklist\n\n# Where is the Snort Executable located (if not on the system path)\nsnort_path = /usr/local/bin/snort\n\n# Local Rules files\n# Specify local rules files, comma-separated\nlocal_rules = /usr/local/etc/rules/local.rules  \n\n# where should so rules be saved\n# so rules will only be processed if this is uncommented\nsorule_path = /usr/local/etc/so_rules/\n</code></pre> <p>To obtain the Oinkcode, create an account in Snort3.</p> <p></p> <p>Run Pulledpork3 </p> <pre><code>sudo /usr/local/bin/pulledpork3/pulledpork.py -c /usr/local/etc/pulledpork3/pulledpork.conf\n</code></pre> <p>If you receive error below, make a directory called so_rules</p> <pre><code>ERROR: `sorule_path` is configured but is not a directory:  /usr/local/etc/so_rules/\n...\nsudo mkdir /usr/local/etc/so_rules/\n</code></pre>"},{"location":"snort/snort.html#troubleshooting-for-registered-ruleset","title":"Troubleshooting for Registered Ruleset","text":"<p>If you have selected registered ruleset and receive the error below, edit snort rules version number in pulledpork.py</p> <pre><code>WARNING: Unable to load rules archive:  422 Client Error: Unprocessable Content for url: https://snort.org/rules/snortrules-snapshot-3350.tar.gz?oinkcode=&lt;hidden&gt;\n</code></pre> <p>Make a backup copy of pulledpork.py and edit pulledpork.py</p> <pre><code>sudo cp /usr/local/bin/pulledpork3/pulledpork.py /usr/local/bin/pulledpork3/oldpulledpork.py\nsudo nano /usr/local/bin/pulledpork3/pulledpork.py\n</code></pre> <p>Edit RULESET_URL_SNORT_REGISTERED</p> <p>The snortrules-snapshot version number can be found on https://www.snort.org/downloads</p> <p>The numbers indicate version number so 31730 (v3.1.7.0) is the latest registered Snort rulest. </p> <p>Community rules are free and maintained by the Snort community. Registered rules are available for free but require you to create an account on the Snort website and obtain an Oinkcode. Subscriber rules required a paid subscription and provides immediate access to the most up-to-date rules. </p> <pre><code>RULESET_URL_SNORT_REGISTERED = 'https://snort.org/rules/snortrules-snapshot-31470.tar.gz'\n</code></pre>"},{"location":"snort/snort.html#test-ids-with-community-ruleset","title":"Test IDS with Community Ruleset","text":"<p>Rerun Pulledpork:</p> <pre><code>sudo /usr/local/bin/pulledpork3/pulledpork.py -c /usr/local/etc/pulledpork3/pulledpork.conf\n...\nWriting rules to:  /usr/local/etc/rules/pulledpork.rules\nProgram execution complete.\n</code></pre> <p>Edit snort\u2019s config to point to Pulledpork\u2019s rules</p> <pre><code>sudo nano /usr/local/etc/snort/snort.lua\n</code></pre> <p>Change the include path to point to pulledpork.rules</p> <pre><code>ips =\n{\n    -- use this to enable decoder and inspector alerts\n    enable_builtin_rules = true,\n\n    -- use include for rules files; be sure to set your path\n    -- note that rules files can include other rules files\n    -- (see also related path vars at the top of snort_defaults.lua)\n    include = \"/usr/local/etc/rules/**pulledpork.rules**\",\n    variables = default_variables\n}\n</code></pre> <p>You can see what the rules look like</p> <pre><code>cat /usr/local/etc/rules/pulledpork.rules | less\n</code></pre> <p>Test Snort</p> <pre><code>snort -c /usr/local/etc/snort/snort.lua --plugin-path /usr/local/etc/so_rules/\n...\nSnort successfully validated the configuration (with 0 warnings).\n</code></pre> <p>Trigger alert by running:</p> <pre><code>curl http://testmyids.com\n</code></pre> <p>Verify that alerts are generated by the community rules</p> <pre><code>tail alert_fast.txt \n</code></pre> <pre><code>09/16-23:11:10.392572 [**] [1:498:11] \"INDICATOR-COMPROMISE id check returned root\" [**] [Classification: Potentially Bad Traffic] [Priority: 2] {TCP} 217.160.0.187:80 -&gt; 10.0.0.22:36062\n09/16-23:11:12.926837 [**] [1:498:11] \"INDICATOR-COMPROMISE id check returned root\" [**] [Classification: Potentially Bad Traffic] [Priority: 2] {TCP} 217.160.0.187:80 -&gt; 10.0.0.22:36076\n</code></pre>"},{"location":"snort/snort.html#test-ips","title":"Test IPS","text":"<p>Start Snort in IPS mode using DAQ AFPacket by running:</p> <pre><code>sudo snort -c /usr/local/etc/snort/snort.lua --daq afpacket -A alert_fast -l /var/log/snort -i ens32\n</code></pre> <p>Note to run Snort in IPS mode using DAQ NFQueue, run: </p> <pre><code>sudo snort -Q --daq nfq --daq-var device=ens32 --daq-var queue=1 -c /usr/local/etc/snort/snort.lua -A alert_fast -l /var/log/snort\n</code></pre> <p>Create the queue. To send traffic for the interface <code>ens32</code> to NFQ, for incoming and outgoing traffic on the <code>ens32</code> interface:</p> <pre><code>sudo iptables -I INPUT -i ens32 -j NFQUEUE --queue-num 1\nsudo iptables -I OUTPUT -o ens32 -j NFQUEUE --queue-num 1\n</code></pre> <p>For forwarded traffic (if Snort is installed at the gateway):</p> <pre><code>sudo iptables -I FORWARD -i ens32 -j NFQUEUE --queue-num 1\n</code></pre> <p>Verify iptables configuration by running:</p> <pre><code>sudo iptables -L -v -n\n</code></pre> <p>To determine the line numbers for your <code>NFQUEUE</code> rules, run:</p> <pre><code>sudo iptables -L --line-numbers\n</code></pre> <p>This will output a list of all the rules in your iptables with their corresponding line numbers. You should look for the rules in the <code>INPUT</code> and <code>OUTPUT</code> chains that mention <code>NFQUEUE</code>, and note their line numbers. Once you have the line numbers, you can delete the rules using:</p> <pre><code>sudo iptables -D INPUT &lt;line_number&gt;\nsudo iptables -D OUTPUT &lt;line_number&gt;\n</code></pre> <p>Change verb in the local.rules from <code>alert</code> to <code>drop</code> </p> <pre><code>nano /usr/local/etc/rules/local.rules\n</code></pre> <pre><code>drop icmp any any -&gt; $HOME_NET any (msg:\"ICMP Ping Detected\"; sid:1000001; rev:1;)\ndrop tcp any any -&gt; $HOME_NET 22 (msg:\"SSH Authentication Attempt\"; sid:1000002; rev:1;)\n</code></pre> <p>From another internal host, run ping to Snort virtual machine. Ping should not go through.</p> <pre><code>ping 10.0.0.22\n</code></pre> <p>Verify that alerts have been generated in alert_fast.txt</p> <pre><code>tail /var/log/snort/alert_fast.txt\n</code></pre> <p>Note: running Snort in IPS mode using DAQ NFQueue is ideal in this scenario but this does not generate logs in alert_fast.txt. For demonstration purposes, Snort was run in IPS mode using DAQ AFPacket.</p>"},{"location":"snort/snort.html#install-snort-ruleset-offline","title":"Install Snort Ruleset Offline","text":"<p>On a machine with internet connection, download snort3-community-rules.tar.gz from https://www.snort.org/downloads</p> <p>Transfer the tarball to the air-gapped environment. </p> <p>Make a folder called snort-rules</p> <p>Untar the tarball to snort-rules folder</p> <pre><code>mkdir ~/snort/snort-rules\ntar -xvzf snort3-community-rules.tar.gz -C /home/cyber/snort/snort-rules/\n</code></pre> <p>Merge all <code>.rules</code> into single rule file:</p> <pre><code>cat *.rules &gt; merged.rules\n</code></pre> <p>Move the Merged File to the pulledpork.rules in the Snort Rules Directory:</p> <pre><code>sudo mv merged.rules /etc/snort/rules/pulledpork.rules\n</code></pre>"},{"location":"snort/snort.html#malware-traffic-analysis-reading-pcap-with-snort","title":"Malware traffic analysis - reading pcap with Snort","text":"<p>Make a directory called test and cd into it.</p> <p>Download a sample pcap from https://www.malware-traffic-analysis.net</p> <pre><code>mkdir ~/test\ncd ~/test\nwget https://www.malware-traffic-analysis.net/2024/02/08/2024-02-08-TA577-Pikabot-infection-traffic.pcap.zip\nunzip 2024-02-08-TA577-Pikabot-infection-traffic.pcap.zip \n</code></pre> <p>Read the pcap with Snort and focus on signatures generated</p> <pre><code>snort -c /usr/local/etc/snort/snort.lua --plugin-path /usr/local/etc/so_rules/ -r 2024-02-08-TA577-Pikabot-infection-traffic.pcap -A alert_fast -q &gt; pcap-signatures_pikabot.txt\n</code></pre> <p>Cat out or grep out pcap-signatures_pikabot.txt</p> <pre><code>cyber@Snort:~/test$ cat pcap-signatures_pikabot.txt | cut -d \"]\" -f 3 | cut -d \"[\" -f 1 |  cut -d '\"' -f 2 | sort | uniq -c | sort -nr\n    110 (arp_spoof) unicast ARP request\n      4 PROTOCOL-DNS SPOOF query response with TTL of 1 min. and no authority\n      4 INDICATOR-SCAN UPnP service discover attempt\n      1 (http_inspect) URI path contains consecutive slash characters\n      1 (http_inspect) Content-Transfer-Encoding used as HTTP header\n</code></pre> <pre><code>grep -i spoof pcap-signatures_pikabot.txt \n02/09-05:25:59.548577 [**] [1:254:17] \"PROTOCOL-DNS SPOOF query response with TTL of 1 min. and no authority\" [**] [Classification: Potentially Bad Traffic] [Priority: 2] {UDP} 10.2.8.1:53 -&gt; 10.2.8.101:64560\n02/09-05:29:14.405544 [**] [112:1:1] \"(arp_spoof) unicast ARP request\" [**] [Priority: 3] {ARP}  -&gt; \n</code></pre>"},{"location":"snort/snort.html#install-snort-on-gateway","title":"Install Snort on Gateway","text":"<p>While Suricata can be installed on a host, it can also be installed on a gateway such as pfSense. The pfSense\u00a0is a free and open source firewall and router. For installing and configuring pfSense, refer to pfSense documentation and instruction video. pfSense can be downloaded from here.</p> <p>Full demonstration video on configuring Suricata on pfSense can be found here. </p> <p>After competing basic configuration on pfSense, navigate to System &gt; Package Manager &gt; Available Packages on pfSense web UI.</p> <p>Search for <code>snort</code> and click install (confirm when prompted). Internet connection is required.</p> <p></p> <p>Navigate to Services &gt; Snort &gt; Global Settings tab. </p>"},{"location":"snort/snort.html#test-ids-and-ips-with-open-source-rules","title":"Test IDS and IPS with open source rules","text":"<p>In this demonstration, we are running Snort on the WAN interface. Full demonstration video can be found here. </p> <p>Select Enable Snort VRT. Copy and paste your Snort Oinkmaster Code (you will need to create an account in https://www.snort.org/).</p> <p>Enable Snort GPLv2, and ET Open.</p> <p></p> <p>Enable OpenAppID, AppID Open Text Rules, and FEODO Tracker Botnet C2 IP Rules.</p> <p>Set Rule Update Interval to 1 Day and select Hide Deprecated Rules Categories.</p> <p></p> <p>Select Remove Blocked Hosts interval to your preferred time. Click save.</p> <p></p> <p>Navigate to the Updates tab and click Update Rules.</p> <p></p> <p>Once the update is complete, you will see timestamps of when the update is completed.</p> <p></p> <p>Navigate to Interfaces tab and add a WAN interface. Enable Interface and name it WAN.</p> <p></p> <p>Select Block Offenders. Set IPS Mode to Legacy Mode and select SRC IP to Block. Click Save.</p> <p></p> <p>Navigate to WAN Categories. Select Use IPS Policy and set IPS Policy to Security. Click Save.</p> <p></p> <p>Navigate to WAN Rules. Select IPS Policy-Security and click Apply.</p> <p></p> <p>Navigate to WAN IP Rep and select Enable IP Reputation. Click Save.</p> <p></p> <p>Make sure the WAN interface is up and running. If not, click the play button.</p> <p></p> <p>Navigate to Firewall &gt; NAT and add 1:1 NAT for Windows host. </p> <p></p> <p>Navigate to Firewall &gt; Virtual IPs and add Public IP for Windows host.</p> <p></p> <p>From Kali machine, run <code>nmap 47.72.145.64</code> </p> <p>Navigate to Alerts and verify that alerts have been generated.</p> <p></p> <p>Navigate to Blocked and verify that the Kali machine is being blocked</p> <p></p>"},{"location":"snort/snort.html#test-ids-and-ips-with-custom-rules","title":"Test IDS and IPS with custom rules","text":"<p>In this demonstration, we are running Snort on the LAN interface. </p> <p>Navigate to Snort Interfaces &gt; WAN Settings. In this demonstration, we have changed the WAN to LAN. Enable interface and name it as the LAN interface. </p> <p></p> <p>Save and Edit the LAN interface. Note instead of WAN Settings it now displays LAN Settings.</p> <p>Navigate to LAN Rules and select custom.rules. Copy and paste the following rule to detect ping from internal to external network.</p> <pre><code>alert icmp $HOME_NET any -&gt; [8.8.8.8] any (msg:\"ICMP Ping Detected to EXTERNAL IP\"; sid:1000001; rev:1;)\n</code></pre> <p></p> <p>Turn on the LAN interface by clicking the play button.</p> <p></p> <p>From the Windows host that is connect to an internal network, run ping to 8.8.8.8</p> <pre><code>ping 8.8.8.8\n</code></pre> <p>Navigate to Alerts and verify that Alerts have been generated.</p> <p></p> <p>Navigate to Snort Interfaces &gt; LAN Settings. </p> <p>Select Block Offenders. Set IPS Mode to Inline Mode and click Save.</p> <p></p> <p>Navigate to LAN Rules. Select custom.rules. Change the rule verb from <code>alert</code> to <code>drop</code> </p> <pre><code>drop icmp $HOME_NET any -&gt; [8.8.8.8] any (msg:\"ICMP Ping Detected to EXTERNAL IP\"; sid:1000001; rev:1;)\n</code></pre> <p></p> <p>From the Windows host that is connect to an internal network, run ping to 8.8.8.8</p> <pre><code>ping 8.8.8.8\n</code></pre> <p>Verify that pings were dropped.</p> <p></p>"},{"location":"snort/snort.html#references","title":"References","text":"<ul> <li>https://docs.snort.org/start/</li> <li>https://github.com/snort3/snort3</li> <li>https://youtu.be/j7Wapw3Gxvg?si=cVRojAePvL7z5rMx</li> <li>https://youtu.be/TvQfD5oUN5o?si=-Wx0jDCGnpeXz-8M</li> <li>https://youtu.be/SapAcfHbQSE?si=LPiMoqLVnZ5D2Lqx</li> </ul>"},{"location":"splunk/splunk.html","title":"Splunk","text":"<p>Splunk Enterprise is a Security Information and Event Management (SIEM) tool usually installed on the server. It is designed for searching, analysing, and visualising data. It allows users to collect and ingest data, and search across various data types. Splunk Universal Forwarders are usually installed on clients to provide reliable, secure data collection and forward that data into Splunk Enterprise for indexing. This part of documentation focuses on installing and configuring Splunk. For Splunk, the main focus will be installing Splunk Enterprise and Universal Forwarder. </p>"},{"location":"splunk/splunk.html#lab-setup-for-proof-of-concept","title":"Lab Setup for Proof of Concept","text":"<p>A virtual lab in an Unclassified environment is used as a proof of concept. Internet access was disabled during the installation to simulate an air-gapped environment. For a testing purpose, a free trial version was used for Splunk Enterprise and Universal Forwarder. Attack emulation was conducted on a FortiGate VM in a safe and controlled setting. </p> <p>Note: Do not attempt to replicate the attack emulation demonstrated here unless you are properly trained and it is safe to do so. Unauthorised attack emulation can lead to legal consequences and unintended damage to systems. Always ensure that such activities are conducted by qualified professionals in a secure, isolated environment.</p> Hostname OS Role IP Address Fortigate Fortios 7.6.0 Firewall/Router 192.168.1.111 (WAN)/10.0.0.1 (LAN) SplunkEnt Centos Stream 9 Splunk Enterprise (server), syslog server 10.0.0.120 WS2019-2 Windows Server 2019 Splunk Universal Forwarder (client) 10.0.0.140 Kali Kali Linux 2024.2 Attacker machine 192.168.1.161, 10.0.0.29 <p></p>"},{"location":"splunk/splunk.html#splunk-enterprise","title":"Splunk Enterprise","text":""},{"location":"splunk/splunk.html#configure-firewall","title":"Configure Firewall","text":"<p>On Ubuntu, run the following command:</p> <pre><code>sudo ufw allow 514/tcp  # syslog TCP\nsudo ufw allow 514/udp  # syslog UDP\nsudo ufw allow 6514/tcp # syslog TLS\nsudo ufw allow 5425/tcp # syslog\nsudo ufw allow 601/tcp  # syslog\n\nsudo ufw allow 8000/tcp # Web UI Port\nsudo ufw allow 8080/tcp # HEC Port\nsudo ufw allow 8088/tcp # HEC Port\nsudo ufw allow 8089/tcp # Management Port\nsudo ufw allow 9997/tcp # Data flow\nsudo ufw allow 8065/tcp # Appserver\nsudo ufw allow 8191/tcp # KVstore\n\n#Apply changes\nsudo ufw reload\n\n#Enable Firewall\n#sudo ufw enable\n\n#Apply changes\nsudo ufw status numbered\n</code></pre> <p>On CentOS, run the following command:</p> <pre><code>#Show original state\nsudo firewall-cmd --list-all\n\n#Syslog ports\nsudo firewall-cmd --zone=public --add-port=514/tcp --permanent # syslog TCP\nsudo firewall-cmd --zone=public --add-port=514/udp --permanent # syslog UDP\nsudo firewall-cmd --zone=public --add-port=5514/udp --permanent # syslog UDP\nsudo firewall-cmd --zone=public --add-port=6514/tcp --permanent # syslog TLS\nsudo firewall-cmd --zone=public --add-port=5425/tcp --permanent # syslog\nsudo firewall-cmd --zone=public --add-port=601/tcp --permanent # syslog\n\n#Splunk ports\nsudo firewall-cmd --zone=public --add-port=8000/tcp --permanent # Web UI Port\nsudo firewall-cmd --zone=public --add-port=8080/tcp --permanent # HEC port\nsudo firewall-cmd --zone=public --add-port=8088/tcp --permanent # HEC port\nsudo firewall-cmd --zone=public --add-port=8089/tcp --permanent # Management Port\nsudo firewall-cmd --zone=public --add-port=9997/tcp --permanent # Data flow\nsudo firewall-cmd --zone=public --add-port=8065/tcp --permanent # appserver\nsudo firewall-cmd --zone=public --add-port=8191/tcp --permanent # kvstore\n\n#Apply changes\nsudo firewall-cmd --reload\n\n#Check applied\nsudo firewall-cmd --list-all\n</code></pre>"},{"location":"splunk/splunk.html#install-and-configure-splunk-enterprise","title":"Install and Configure Splunk Enterprise","text":"<p>Splunk Enterprise enables you to search, analyze and visualise your data to quickly act on insights from across your technology landscape. This step focuses on installing and configuring Splunk Enterprise. </p> <p>Note: Linux, 4.X, 5.10, 5.14,5.15 and 5.4.X kernels are ideal so Ubuntu 20.04 LTS or CentOS Stream 9 are recommended. As internet is required to register the system, RHEL is not recommended in an air-gapped environment. </p> <p>Download Splunk Enterprise for Linux (.tgz).</p> <p>Untar (unzip) the tar archive to /opt directory</p> <pre><code>sudo tar xvzf splunk-9.3.1-0b8d769cb912-Linux-x86_64.tgz -C /opt\n</code></pre> <p>Create user splunk and change ownership of /opt/splunk directory to the splunk user </p> <p>On CentOS, after adding user, go to settings &gt; Users. Unlock to Change Settings. Set password for the <code>splunk</code> user</p> <p>On Ubuntu, enter password and user information for the <code>splunk</code> user (use default values by pressing <code>enter</code> ). </p> <pre><code>sudo adduser splunk\n</code></pre> <p>Make the splunk user the owner of the splunk directory. Change permissions and verify the ownership.</p> <pre><code>sudo chown -R splunk:splunk /opt/splunk\ncd /opt\nls -la\n</code></pre> <pre><code>#Example output\ntotal 12\ndrwxr-xr-x  3 root   root   4096 Sep 18 15:36 .\ndrwxr-xr-x 20 root   root   4096 Sep 18 15:21 ..\ndrwxr-xr-x 11 splunk splunk 4096 Sep  6 05:58 splunk\n</code></pre> <p>Switch to splunk user and start splunk. When prompted, create admin credentials.</p> <pre><code>su splunk\ncd splunk/bin\n./splunk start --accept-license\n</code></pre> <p>Wait for web server at <code>http://127.0.0.1:8000</code> to be available. Navigate to <code>http://&lt;IP address&gt;:8000</code>or <code>http://localhost:8000</code> on web browser.  </p> <p>Enter in splunk admin credentials you created when installing Splunk Enterprise</p> <p>Setup Splunk to listen on port 9997</p> <pre><code># in /opt/splunk/bin/\n./splunk enable listen 9997\n</code></pre> <p>Alternatively this can be done on the web UI</p> <p>Settings &gt; Forwarding and Receiving &gt; Add new under Receive Data &gt; Listen on this port: 9997 &gt; Save &gt; Verify the listen on port 9997 is enabled under Receive Data and Configure receiving</p> <p></p> <p></p> <p></p>"},{"location":"splunk/splunk.html#ingesting-fortigate-logs-through-sc4s-option-1","title":"Ingesting FortiGate Logs through SC4S (Option 1)","text":"<p>SC4S is an open source packaged solution for getting data into Splunk. It is based on the syslog-ng Open Source Edition (Syslog-NG OSE) and transports data to Splunk via the Splunk HTTP event Collector (HEC) rather than writing events to disk for collection by a Universal Forwarder.</p>"},{"location":"splunk/splunk.html#create-indexes-for-sc4s","title":"Create indexes for SC4S","text":"<p>Copy indexes.conf from here:</p> <pre><code>[default]\nlastChanceIndex = main\n\n[email]\nhomePath   = $SPLUNK_DB/email/db\ncoldPath   = $SPLUNK_DB/email/colddb\nthawedPath = $SPLUNK_DB/email/thaweddb\n\n[epav]\nhomePath   = $SPLUNK_DB/epav/db\ncoldPath   = $SPLUNK_DB/epav/colddb\nthawedPath = $SPLUNK_DB/epav/thaweddb\n\n[epintel]\nhomePath   = $SPLUNK_DB/epintel/db\ncoldPath   = $SPLUNK_DB/epintel/colddb\nthawedPath = $SPLUNK_DB/epintel/thaweddb\n\n[fireeye]\nhomePath   = $SPLUNK_DB/fireeye/db\ncoldPath   = $SPLUNK_DB/fireeye/colddb\nthawedPath = $SPLUNK_DB/fireeye/thaweddb\n\n[gitops]\nhomePath   = $SPLUNK_DB/gitops/db\ncoldPath   = $SPLUNK_DB/gitops/colddb\nthawedPath = $SPLUNK_DB/gitops/thaweddb\n\n[infraops]\nhomePath   = $SPLUNK_DB/infraops/db\ncoldPath   = $SPLUNK_DB/infraops/colddb\nthawedPath = $SPLUNK_DB/infraops/thaweddb\n\n[netauth]\nhomePath   = $SPLUNK_DB/netauth/db\ncoldPath   = $SPLUNK_DB/netauth/colddb\nthawedPath = $SPLUNK_DB/netauth/thaweddb\n\n[netdlp]\nhomePath   = $SPLUNK_DB/netdlp/db\ncoldPath   = $SPLUNK_DB/netdlp/colddb\nthawedPath = $SPLUNK_DB/netdlp/thaweddb\n\n[netdns]\nhomePath   = $SPLUNK_DB/netdns/db\ncoldPath   = $SPLUNK_DB/netdns/colddb\nthawedPath = $SPLUNK_DB/netdns/thaweddb\n\n[netfw]\nhomePath   = $SPLUNK_DB/netfw/db\ncoldPath   = $SPLUNK_DB/netfw/colddb\nthawedPath = $SPLUNK_DB/netfw/thaweddb\n\n[netids]\nhomePath   = $SPLUNK_DB/netids/db\ncoldPath   = $SPLUNK_DB/netids/colddb\nthawedPath = $SPLUNK_DB/netids/thaweddb\n\n[netlb]\nhomePath   = $SPLUNK_DB/netlb/db\ncoldPath   = $SPLUNK_DB/netlb/colddb\nthawedPath = $SPLUNK_DB/netlb/thaweddb\n\n[netops]\nhomePath   = $SPLUNK_DB/netops/db\ncoldPath   = $SPLUNK_DB/netops/colddb\nthawedPath = $SPLUNK_DB/netops/thaweddb\n\n[netwaf]\nhomePath   = $SPLUNK_DB/netwaf/db\ncoldPath   = $SPLUNK_DB/netwaf/colddb\nthawedPath = $SPLUNK_DB/netwaf/thaweddb\n\n[netproxy]\nhomePath   = $SPLUNK_DB/netproxy/db\ncoldPath   = $SPLUNK_DB/netproxy/colddb\nthawedPath = $SPLUNK_DB/netproxy/thaweddb\n\n[netipam]\nhomePath   = $SPLUNK_DB/netipam/db\ncoldPath   = $SPLUNK_DB/netipam/colddb\nthawedPath = $SPLUNK_DB/netipam/thaweddb\n\n[oswinsec]\nhomePath   = $SPLUNK_DB/oswinsec/db\ncoldPath   = $SPLUNK_DB/oswinsec/colddb\nthawedPath = $SPLUNK_DB/oswinsec/thaweddb\n\n[osnix]\nhomePath   = $SPLUNK_DB/osnix/db\ncoldPath   = $SPLUNK_DB/osnix/colddb\nthawedPath = $SPLUNK_DB/osnix/thaweddb\n\n[oswin]\nhomePath   = $SPLUNK_DB/oswin/db\ncoldPath   = $SPLUNK_DB/oswin/colddb\nthawedPath = $SPLUNK_DB/oswin/thaweddb\n\n[syslogng_fallback]\nhomePath   = $SPLUNK_DB/syslogng_fallback/db\ncoldPath   = $SPLUNK_DB/syslogng_fallback/colddb\nthawedPath = $SPLUNK_DB/syslogng_fallback/thaweddb\n\n[_metrics]\ndatatype=metric\nhomePath   = $SPLUNK_DB/_metrics/db\ncoldPath   = $SPLUNK_DB/_metrics/colddb\nthawedPath = $SPLUNK_DB/_metrics/thaweddb\n</code></pre> <p>Save indexes.conf to <code>/opt/splunk/etc/system/local</code> </p> <p>Note: execute this command as root or your standard user (not <code>splunk</code>)</p> <pre><code>sudo nano /opt/splunk/etc/system/local/indexes.conf\n</code></pre> <p>Change into <code>/opt/splunk/bin</code> and restart Splunk Enterprise as the <code>splunk</code> user.</p> <pre><code>./splunk restart\n</code></pre> <p>Note: do not edit <code>/opt/splunk/etc/system/default/indexes.conf</code> This step will create the following default indexes that are used by SC4S:</p> <ul> <li><code>email</code></li> <li><code>epav</code></li> <li><code>fireeye</code></li> <li><code>gitops</code></li> <li><code>infraops</code></li> <li><code>netauth</code></li> <li><code>netdlp</code></li> <li><code>netdns</code></li> <li><code>netfw</code></li> <li><code>netids</code></li> <li><code>netops</code></li> <li><code>netwaf</code></li> <li><code>netproxy</code></li> <li><code>netipam</code></li> <li><code>oswinsec</code></li> <li><code>osnix</code></li> <li><code>_metrics</code>\u00a0(Optional opt-in for SC4S operational metrics; ensure this is created as a metrics index)</li> </ul> <p>Verify that the SC4S default indexes are created on web UI (Settings &gt; Indexes).</p>"},{"location":"splunk/splunk.html#create-a-http-event-collector-hec-token-for-sc4s","title":"Create a HTTP Event Collector (HEC) token for SC4S","text":"<p>On Splunk Web UI, go to Settings &gt; Data Inputs &gt; HTTP Event Collector &gt; Global Settings</p> <p>Select Enabled for All Tokens</p> <p>Set Default Index as main</p> <p>Uncheck Enable SSL </p> <p>Leave HTTP Port Number as 8088</p> <p>Save</p> <p></p> <p>Click New Token. Name your token and click Next.</p> <p></p> <p>Leave Source type as Automatic. Click add all for Allowed Indexes. Select main for Default Index.</p> <p>Click Review and Submit.</p> <p></p> <p>Copy your Token Value and save it on a notepad (we will need this later)</p> <p>You can also find your token value on Settings &gt; Data Inputs &gt; HTTP Event Collector</p> <p></p> <p></p>"},{"location":"splunk/splunk.html#configure-linux-for-sc4s","title":"Configure Linux for SC4S","text":"<p>Set the host OS kernel to match the default receiver buffer of SC4S, which is set to 16MB.</p> <p>Add the following to\u00a0<code>/etc/sysctl.conf</code>:</p> <pre><code>sudo nano /etc/sysctl.conf\n</code></pre> <pre><code>net.core.rmem_default = 17039360\nnet.core.rmem_max = 17039360\n</code></pre> <p>Apply to the kernel by running the command  <code>sysctl -p</code></p> <pre><code>sudo sysctl -p\n</code></pre> <p>Ensure the kernel is not dropping packets (optional)</p> <pre><code>netstat -su | grep \"receive errors\" \n</code></pre> <p>For Ubuntu, download net-tools on Ubuntu VM with internet connection. Transfer it over to Ubuntu VM without internet connection and install net-tools (optional)</p> <pre><code>#On Ubuntu VM with internet connection\nmkdir net-tools-offline\ncd net-tools-offline\nsudo chmod -R 755 /home/cyber/net-tools-offline\nsudo apt-get download net-tools\n</code></pre> <pre><code>#On Ubuntu VM without internet connection\ncd net-tools-offline\nsudo dpkg -i net-tools_1.60+git20181103.0eebece-1ubuntu5_amd64.deb\n</code></pre>"},{"location":"splunk/splunk.html#install-podman-offline-on-ubuntu","title":"Install Podman offline on Ubuntu","text":"<p>By default, Podman is installed on CentOS Stream 9 but it is not installed on Ubuntu. </p> <p>On a Ubuntu machine with internet connection:</p> <pre><code>mkdir podman-offline\ncd podman-offline\nsudo chmod -R 755 /home/cyber/podman-offline\nsudo apt-get install --download-only podman -o Dir::Cache=/home/cyber/podman-offline\n</code></pre> <p>If you get permission denied error, run the <code>sudo apt-get install --download-only</code> command again.</p> <p>Transfer <code>podman-offline</code> to the Ubuntu host without internet connection.</p> <p>To install Podman (note archives directory should have been automatically created)</p> <pre><code>cd podman-offline/archives\nsudo dpkg -i *.deb\n</code></pre>"},{"location":"splunk/splunk.html#install-sc4s-container-while-offline","title":"Install SC4S container while offline","text":"<p>You can stage SC4S by downloading the image so that it can be loaded on a host machine, for example on an airgapped system, without internet connectivity.</p> <p>Download the latest container image\u00a0<code>oci_container.tgz</code>\u00a0from SC4S GitHub page.</p> <p>Transfer the container image to your host machine.</p> <p>Execute the following command using Podman.</p> <p>Make a note of the container ID for the resulting load</p> <pre><code>sudo podman load &lt; oci_container.tar.gz\n</code></pre> <pre><code>#Example output\nLoaded image: ghcr.io/splunk/splunk-connect-for-syslog/container3:3.30.1\n</code></pre> <p>Use the container ID to create a local label: </p> <p><code>podman tag &lt;container ID&gt; sc4slocal:latest</code></p> <pre><code>sudo podman tag ghcr.io/splunk/splunk-connect-for-syslog/container3:3.30.1 sc4slocal:latest\n</code></pre> <p>Create the systemd unit file\u00a0<code>/lib/systemd/system/sc4s.service</code></p> <pre><code>sudo nano /lib/systemd/system/sc4s.service\n</code></pre> <p>Copy and paste the following - note that this is the edited version of SC4S sample unit file for Podman</p> <pre><code>[Unit]\nDescription=SC4S Container\nWants=NetworkManager.service network-online.target\nAfter=NetworkManager.service network-online.target\n\n[Install]\nWantedBy=multi-user.target\n\n[Service]\n# Select the locally loaded image\nEnvironment=\"SC4S_IMAGE=sc4slocal:latest\"\n\n# Required mount point for syslog-ng persist data (including disk buffer)\nEnvironment=\"SC4S_PERSIST_MOUNT=splunk-sc4s-var:/var/lib/syslog-ng\"\n\n# Optional mount point for local overrides and configurations; see notes in docs\nEnvironment=\"SC4S_LOCAL_MOUNT=/opt/sc4s/local:/etc/syslog-ng/conf.d/local:z\"\n\n# Optional mount point for local disk archive (EWMM output) files\nEnvironment=\"SC4S_ARCHIVE_MOUNT=/opt/sc4s/archive:/var/lib/syslog-ng/archive:z\"\n\n# Map location of TLS custom TLS\nEnvironment=\"SC4S_TLS_MOUNT=/opt/sc4s/tls:/etc/syslog-ng/tls:z\"\n\nTimeoutStartSec=0\n\n#ExecStartPre=/usr/bin/podman pull $SC4S_IMAGE\n\n# Note: /usr/bin/bash will not be valid path for all OS\n# when startup fails on running bash check if the path is correct\nExecStartPre=/usr/bin/bash -c \"/usr/bin/systemctl set-environment SC4SHOST=$(hostname -s)\"\n\nExecStart=/usr/bin/podman run \\\n        -e \"SC4S_CONTAINER_HOST=${SC4SHOST}\" \\\n        -v \"$SC4S_PERSIST_MOUNT\" \\\n        -v \"$SC4S_LOCAL_MOUNT\" \\\n        -v \"$SC4S_ARCHIVE_MOUNT\" \\\n        -v \"$SC4S_TLS_MOUNT\" \\\n        --env-file=/opt/sc4s/env_file \\\n        --health-cmd=\"/healthcheck.sh\" \\\n        --health-interval=10s --health-retries=6 --health-timeout=6s \\\n        --network host \\\n        --name SC4S \\\n        --rm $SC4S_IMAGE\n\nRestart=on-abnormal\n</code></pre>"},{"location":"splunk/splunk.html#configure-ipv4-forwarding","title":"Configure IPv4 forwarding","text":"<p>IPv4 forwarding is not enabled by default. IPv4 forwarding must be enabled for container networking.</p> <p>To check that IPv4 forwarding is enabled:\u00a0</p> <pre><code>sudo sysctl net.ipv4.ip_forward\n</code></pre> <p>To enable IPv4 forwarding:\u00a0</p> <pre><code>sudo sysctl net.ipv4.ip_forward=1\n</code></pre> <p>To ensure your changes persist upon reboot:</p> <ul> <li>Define sysctl settings through files in\u00a0<code>/usr/lib/sysctl.d/</code>and\u00a0<code>/etc/sysctl.d/</code>.</li> <li>To override only specific settings, either add a file with a lexically later name in\u00a0<code>/etc/sysctl.d/</code>\u00a0and put following setting there or find this specific setting in one of the existing configuration files and set the value to\u00a0<code>1</code>.</li> </ul> <pre><code>cd /usr/lib/sysctl.d/\n</code></pre> <pre><code>sudo nano 100-custom.conf\n</code></pre> <pre><code>net.ipv4.ip_forward=1\n</code></pre> <ul> <li>Repeat the same steps for <code>/etc/sysctl.d/</code>.</li> <li>For example, in the <code>/usr/lib/sysctl.d/</code> directory, there are few config files. The naming convention is XX-name.conf with XX being a number. Create a custom.conf with a higher number e.g. <code>100-custom.conf</code> with the content <code>net.ipv4.ip_forward=1</code> .</li> </ul> <pre><code>cyber@SplunkEnt:/usr/lib/sysctl.d$ ls\n100-custom.conf  50-bubblewrap.conf  50-pid-max.conf\n30-tracker.conf  50-default.conf     99-protect-links.conf\n</code></pre> <p>Create a Podman/Docker local volume that will contain the disk buffer files and other SC4S state files:</p> <pre><code>sudo podman volume create splunk-sc4s-var\n</code></pre> <p>Create directories to be used as a mount point for local overrides and configurations:</p> <pre><code>sudo mkdir -p /opt/sc4s/local\nsudo mkdir -p /opt/sc4s/archive\nsudo mkdir -p /opt/sc4s/tls\n</code></pre> <p>Create the environment file\u00a0<code>/opt/sc4s/env_file</code>\u00a0and replace the HEC_URL and HEC_TOKEN as necessary:</p> <pre><code>sudo nano /opt/sc4s/env_file\n</code></pre> <pre><code>SC4S_DEST_SPLUNK_HEC_DEFAULT_URL=https://your.splunk.instance:8088\nSC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n#Uncomment the following line if using untrusted SSL certificates\nSC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY=no\n</code></pre> <p>For example:</p> <pre><code>SC4S_DEST_SPLUNK_HEC_DEFAULT_URL=http://10.0.0.120:8088\nSC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN=8be8e3f3-49fc-4158-a20c-bcf82be93dda\n#Uncomment the following line if using untrusted SSL certificates\nSC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY=no\n</code></pre> <p>Configure SC4S for systemd and start SC4S. Verify sc4s is active and running (exit with <code>q</code>)</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable sc4s\nsudo systemctl start sc4s\nsudo systemctl status sc4s\n</code></pre> <p>Check podman/docker logs for errors:</p> <pre><code>sudo podman logs SC4S\n</code></pre> <pre><code>#Example Output\nSC4S_ENV_CHECK_HEC: Splunk HEC connection test successful to index=main for sourcetype=sc4s:fallback...\nSC4S_ENV_CHECK_HEC: Splunk HEC connection test successful to index=main for sourcetype=sc4s:events...\nsyslog-ng checking config\nsc4s version=3.30.0\nstarting goss\nstarting syslog-ng\n</code></pre> <p>Search on Splunk for successful installation of SC4S:</p> <pre><code>index=* sourcetype=sc4s:events \"starting up\"\n</code></pre> <p></p> <p>Send sample data to default udp port 514 of SC4S host: <code>echo \u201cHello SC4S\u201d &gt; /dev/udp/&lt;SC4S_ip&gt;/514</code> </p> <pre><code>echo \u201cHello SC4S\u201d &gt; /dev/udp/10.0.0.120/514\n</code></pre> <p>Search for <code>index=* \"Hello SC4S\"</code></p> <p></p> <p>Verify that SC4S is receiving Fortigate logs</p> <p></p>"},{"location":"splunk/splunk.html#ingesting-fortigate-logs-through-fortigate-app-option-2","title":"Ingesting FortiGate Logs through FortiGate App (Option 2)","text":"<p>If SC4S does not work for your environment, another option to ingest FortiGate logs on Splunk is through FortiGate App.</p> <p>Install from file on Splunk web UI: Manage Apps-&gt;Install from file-&gt;Upload the .tgz file which is downloaded from https://splunkbase.splunk.com/app/2846 -&gt;check the upgrade box-&gt; click restart splunk service.</p> <p></p>"},{"location":"splunk/splunk.html#add-data-input-on-splunk-server","title":"Add data input on Splunk server:","text":"<p>Note: From version 1.2, the Splunk TA(Add-on) for fortigate no longer match wildcard source or sourcetype to extract fortigate log data, a default sourcetype fortigate_log is specified in default/props.conf instead, please follow the instruction below to configure your input and props.conf for the App and TA(Add-on).</p> <p>Navigate to Settings-&gt;Data Input-&gt;UDP on Splunk Web UI. Click New Local UDP.</p> <p>For Port, enter <code>514</code> and leave other parameters as is.</p> <p></p> <p>For Source type, select <code>fortigate_log</code> (search for <code>fortigate_log</code> in the search bar)</p> <p></p> <p>Click Review and Submit. If you get the error <code>UDP 514 is not available</code> use other UDP port (e.g. <code>5514</code>). Restart Splunk service for the change to take effect.</p> <pre><code>/opt/splunk/bin/splunk restart\n</code></pre> <p>Configure FortiGate to send syslog by following the steps below.</p> <p>Navigate to Search &amp; Reporting on Splunk web UI. </p> <p>Search for <code>fortigate</code> and verify that FortiGate logs are being ingested.  </p> <p></p>"},{"location":"splunk/splunk.html#configure-fortigate","title":"Configure FortiGate","text":"<p>Configure Port 1 as WAN interface </p> <p>Configure Port 2 as LAN interface. </p> <p>Configure DHCP to automatically assign IP addresses to clients connecting to LAN</p> <p></p> <p>Create a new firewall policy to allow LAN to WAN</p> <p>To simulate an air-gapped environment without internet access, disable the policy for now. </p> <p></p> <p></p>"},{"location":"splunk/splunk.html#configure-fortigate-to-send-syslog","title":"Configure FortiGate to send syslog","text":"<p>Refer to the admin manual for specific details of configuration to send Reliable syslog using RFC 3195 format, a typical logging configuration will include the following features.</p> <pre><code>config log syslogd setting \n\nset status enable\nset server (syslog-ng ip)\nset source-ip (fortigate ip)\n#set port (port number) (default port is 514)\n#Verify settings by running \"show\"\nend \n\nconfig log memory filter\nset forward-traffic enable\nset local-traffic enable\nset sniffer-traffic disable\nset anomaly enable\nset voip disable\nset multicast-traffic enable\n#Verify settings by running \"show full-configuration\"\nend\n\nconfig system global\nset cli-audit-log enable\n#Verify settings by running \"show\"\n#Make sure timezone is correct e.g. \"Pacific/Auckland\"\nend\n\nconfig log setting\nset neighbor-event enable\nend\n</code></pre>"},{"location":"splunk/splunk.html#configure-cisco-isr-to-send-syslog","title":"Configure Cisco ISR to send syslog","text":"<p>Note: this step needs to be verified with a Cisco device in a testing environment. </p> <pre><code>show clock\nntp server (IP address of Fortigate)\n\nconf f\nlogging on\nlogging (IP address of Syslog server)\nlogging trap 6\n#Use \"?\" to see what options are available\nexit\n\n#Turn on interface by no shut\n\nshow logging\n#port 514 udp by default\n\nsh run | inc logging\n#we can set multiple syslog servers\n\n#Set IP address for int vlan 1\n#Test ping to syslog server\nconf t\n\nservice sequence-numbers\n#Assign sequence-numbers to syslogs in order that events occurred on\n\nconf t\nline console 0\nlogging synchronous\n#Force Syslog messages to be displayed once configuration has been completed.\n</code></pre> <p>Note: in this scenario, we are sending syslogs from network devices to a containerised syslog-ng server using HTTP/HTTPS. This is Splunk team\u2019s recommended method when using Splunk products. Alternatively, you can send syslogs from network devices to a rsyslog server and rotate the logs. This method is used by other SIEMs like Wazuh. For more details, refer to the Wazuh documentation. </p>"},{"location":"splunk/splunk.html#splunk-universal-forwarder","title":"Splunk Universal Forwarder","text":""},{"location":"splunk/splunk.html#install-sysmon-on-windows","title":"Install Sysmon on Windows","text":"<p>Download Sysmon and sysmonconfig.xml</p> <p>Extract Sysmon.zip and move sysmonconfig.xml into the Sysmon folder where Sysmon.exe is located.</p> <p>Run PowerShell as Administrator and change directory to path where extracted Sysmon is located</p> <p>Move sysmonconfig.xml to the same directory</p> <p>Install Symon by running <code>.\\Sysmon64.exe -accepteula -i sysmonconfig.xml</code></p> <pre><code>PS C:\\Users\\Administrator\\Downloads\\Sysmon\\Sysmon&gt; ls\n\n    Directory: C:\\Users\\Administrator\\Downloads\\Sysmon\\Sysmon\n\nMode                LastWriteTime         Length Name\n----                -------------         ------ ----\n------        7/23/2024   2:08 PM           7490 Eula.txt\n------        7/23/2024   2:08 PM        8480560 Sysmon.exe\n------        7/23/2024   2:08 PM        4563248 Sysmon64.exe\n------        7/23/2024   2:08 PM        4993440 Sysmon64a.exe\n-a----        8/26/2024   7:31 PM         123257 sysmonconfig.xml\n\nPS C:\\Users\\Administrator\\Downloads\\Sysmon\\Sysmon&gt; .\\Sysmon64.exe -accepteula -i .\\sysmonconfig.xml\n\nSystem Monitor v15.15 - System activity monitor\nBy Mark Russinovich and Thomas Garnier\nCopyright (C) 2014-2024 Microsoft Corporation\nUsing libxml2. libxml2 is Copyright (C) 1998-2012 Daniel Veillard. All Rights Reserved.\nSysinternals - www.sysinternals.com\n\nLoading configuration file with schema version 4.50\nSysmon schema version: 4.90\nConfiguration file validated.\nSysmon64 installed.\nSysmonDrv installed.\nStarting SysmonDrv.\nSysmonDrv started.\nStarting Sysmon64..\nSysmon64 started.\n</code></pre> <p>Verify that Sysmon is installed by checking Services (Sysmon64) and Windows EventViewer (Applications and Services Logs &gt; Microsoft &gt; Windows &gt; Sysmon)</p> <p></p> <p></p>"},{"location":"splunk/splunk.html#create-a-domain-account","title":"Create a Domain Account","text":"<p>Note: in this lab, WS2019 host was joined to a domain called cyber.local and promoted as a domain controller. This step is applicable to a domain-joined environment. </p> <p>Create a domain user called <code>splunk</code> and assign it as a member of <code>Event Log Readers Group</code>.</p> <p>This account will be used to run Splunk Forwarder. </p> <ul> <li>Go to Active Directory Users and Computers &gt; domain &gt; Users</li> <li>Right Users &gt; New &gt; User</li> <li>Right-click splunk user &gt; Properties &gt; Member of &gt; Add &gt; Type Event Log Readers and click Check Names &gt; OK &gt; Apply and OK</li> </ul> <p></p>"},{"location":"splunk/splunk.html#configure-rdp-for-domain-user-splunk-optional","title":"Configure RDP for domain user splunk (optional)","text":"<p>Note: in this lab, RDP configuration was required for the <code>splunk</code> user to login to WS2019 host. This step is optional. </p> <p>If RDP needs to be configured and there is an error after configuring firewall and enabling RDP, edit group policy.</p> <p>Open Local Group Policy Editor by clicking Run &gt; type <code>gpedit.msc</code></p> <p>In the Local Group Policy Editor, navigate to Windows Settings &gt; Security Settings &gt; Local Policies &gt; User Rights Assignment &gt; Allow log on through Remote Desktop Services</p> <p>Add user splunk</p> <p></p> <p>In the Local Group Policy Editor, navigate to Computer configuration &gt; Windows Settings &gt; Administrative Templates &gt; Windows Components &gt; Remote Desktop Services &gt; Remote Desktop Session Host &gt; Connections &gt; Allow users to connect remotely by using Remote Desktop Services &gt;Enabled </p> <p></p> <p>Navigate to Remote Desktop Session Host &gt; Security &gt; Require user authentication for remote connections by using Network Level Authentication &gt; Enabled</p> <p></p> <p>In Server Manager, go to Local Server. Make sure Remote Desktop is Enabled. Add user <code>splunk</code>.</p> <p></p> <p>Enable inbound firewall rules related to Remote Desktop</p> <p></p> <p>RDP into WS2019 host as the splunk user from another internal host.</p>"},{"location":"splunk/splunk.html#configure-splunk-universal-forwarder-on-windows","title":"Configure Splunk Universal Forwarder on Windows","text":"<p>Download and transfer the Splunk Universal Forwarder msi for Windows.</p> <p>Run Universal Forwarder msi, accept license, select on-premise Splunk Enterprise instance, and click Customize Options</p> <p></p> <p>Leave Path as default and click Next</p> <p></p> <p>Leave Certificate Password empty and click Next</p> <p></p> <p>Select Domain Account</p> <p>Note: using Virtual Account is recommended but you may encounter errors with the Virtual Account. Test your install with the Virtual Account before selecting Domain Account. </p> <p>Refer to Annex 1. </p> <p></p> <p>Specify DOMAIN\\splunk and password for the account</p> <p></p> <p>Leave permissions as default</p> <p></p> <p>Leave everything unchecked and click Next</p> <p></p> <p>Create credentials for the administrator account.</p> <p>Note: in this lab, the administrator account for Splunk Universal Forwarder is also configured as splunk but this is different to the domain account splunk that has been created earlier.</p> <p></p> <p>Enter IP address of your Deployment Server (Splunk server) and port 8089. Note the IP address in the screenshot points to the previous version of lab where Splunk server's IP address was 10.0.0.20.</p> <p></p> <p>Enter IP address of your Receiving Indexer (Splunk server) and port 9997</p> <p></p> <p>Click Install. Click Finish after install is complete.</p> <p></p>"},{"location":"splunk/splunk.html#create-a-new-outbound-firewall-rule","title":"Create a new outbound Firewall rule","text":"<p>Navigate to Windows Defender Firewall with Advanced Security </p> <p>Right-click on Outbound Rules and select New Rule</p> <p>Select Program as Rule Type</p> <p></p> <p>For program path, browse to C:\\Program Files\\SplunkUniversalForwarder\\bin\\splund.exe</p> <p></p> <p>Select Allow the Connection</p> <p></p> <p>Check all boxes for Domain, Private and Public</p> <p></p> <p>Name the rule as Splunk outbound</p> <p></p> <p>Verify that yours Windows host is connected to the Deployment Server.</p> <p>On the Splunk Enterprise web UI (CentOS), go to Settings &gt; Forwarder Management &gt; Clients</p> <p>You should be able to see your Windows host</p> <p></p>"},{"location":"splunk/splunk.html#install-splunk-apps","title":"Install Splunk Apps","text":"<p>Download the following Splunk Apps (tar archive files)</p> <ul> <li>Splunk Add-on for MS Windows</li> <li>Splunk Add-on for Sysmon</li> <li>Splunk Add-on for Unix and Linux (optional: applicable to Linux clients)</li> </ul> <p>Install the add-ons (apps) on Splunk Enterprise web UI</p> <p>Go to Apps &gt; Manage Apps &gt; Install app from file &gt; Upload the tar archive files</p> <p></p> <p></p> <p></p> <p></p> <p>If there is an error while uploading the file, try uploading it again. </p> <p>If prompted to set up the apps, click set up later.</p> <p></p> <p>Make sure Splunk Add-ons for Microsoft Windows and Sysmon are enabled.</p> <p>On terminal of the host where Splunk Enterprise is installed, verify that there are <code>Splunk_TA_microsoft_sysmon</code> and <code>Splunk_TA_windows</code> in <code>/opt/splunk/etc/apps</code> directory</p> <p>Copy the apps to <code>/opt/splunk/etc/deployment-apps</code> directory</p> <pre><code>cd /opt/splunk/etc/apps\nsudo cp -r Splunk_TA_* /opt/splunk/etc/deployment-apps/\n</code></pre> <p>Verify that the apps are shown in the Splunk Enterprise web UI</p> <p>Go to Settings &gt; Forwarder Management &gt; Apps</p> <p>Search for Splunk</p> <p></p>"},{"location":"splunk/splunk.html#configure-unix-app-and-create-unix-server-class-optional","title":"Configure Unix app and create unix server class (optional)","text":"<p>Note: this step is applicable if you installed Splunk_TA_nix app.</p> <p>On the same page, next to the apps, click Edit under Actions for Splunk_TA_nix.</p> <p>Select Restart Splunkd After Installation, create New Server Class called nix,  and click Save</p> <p></p> <p></p> <p>Add Apps</p> <p></p> <p>Select Splunk_TA_nix and click Save</p> <p></p> <p>Add Clients</p> <p></p> <p>In the Include, put *, and in filter by Machine Type, add linux-x86_64</p> <p>Click Preview</p> <p>You should see a tick next to your Linux host and your Linux host should appear under Matched</p> <p>Click Save</p> <p></p> <p>Go to Forwarder Management and verify that your Linux host is connected to Splunk_TA_nix Apps and nix Server Class</p> <p></p> <p>If the settings are not applied try reloading the deployment server </p> <p>On the terminal of the host where Splunk Enterprise is installed, run the command</p> <pre><code>splunk@siem:/opt/splunk/bin# ./splunk reload deploy-server\n</code></pre>"},{"location":"splunk/splunk.html#configure-windows-and-sysmon-apps-and-create-windows-server-class","title":"Configure Windows and Sysmon apps and create windows server class","text":"<p>To avoid permission denied error, change ownership and adjust directory permissions for the <code>/opt/splunk/etc/deployment-apps</code> </p> <pre><code>sudo chown -R splunk:splunk /opt/splunk/etc/deployment-apps\nsudo chmod -R 755 /opt/splunk/etc/deployment-apps\n</code></pre> <p>On the Forwarder Management page of the web UI, click Edit under Actions for Splunk_TA_windows</p> <p>Select Restart Splunkd After Installation, add New Server Class called win, and click Save</p> <p></p> <p>Click Add Apps and select Splunk_TA_windows and Splunk_TA_micorsoft_sysmon. Click Save</p> <p></p> <p>Click Add Clients. Put * in Include, and filter by windows-x64.</p> <p>Click Preview</p> <p>Click Save</p> <p></p> <p>You should see Restart Splunkd in the After installation column. </p> <p>If only Enable App is shown, Edit each app and select Restart Splunkd.</p> <p></p> <p></p> <p>Verify the configuration in the Forwarder Management</p> <p></p> <p></p> <p>If the configuration is not applied, try reloading the deployment-server</p> <pre><code>splunk@siem:/opt/splunk/bin# ./splunk reload deploy-server\n</code></pre> <p>Verify that <code>/opt/splunk/etc/system/local/serverclass.conf</code> aligns with our configuration so far</p> <pre><code>sudo cat /opt/splunk/etc/system/local/serverclass.conf\n</code></pre> <pre><code>[serverClass:win:app:Splunk_TA_microsoft_sysmon]\nrestartSplunkWeb = 0\nrestartSplunkd = 1\nstateOnClient = enabled\n\n[serverClass:win:app:Splunk_TA_windows]\nrestartSplunkWeb = 0\nrestartSplunkd = 1\nstateOnClient = enabled\n\n[serverClass:win]\nmachineTypesFilter = windows-x64\nwhitelist.0 = *\n</code></pre>"},{"location":"splunk/splunk.html#create-indexes","title":"Create Indexes","text":"<p>Create indexes on the web UI.</p> <p>Note: your index name must match with index name in inputs.conf in each app.</p> <p>Go to settings &gt; indexes &gt; New Index</p> Index Name wineventlog sysmonlog unixlog (optional) Index Data Type Events Events Events Max Size of entire Index 1 GB (Default is 500 GB so adjust accordingly) 1 GB (Default is 500 GB so adjust accordingly) 1 GB (Default is 500 GB so adjust accordingly) Enable Reduction Enable (optional) Enable (optional) Enable (optional) Reduce tisdx files older than 90 days 90 days 90 days <p>Verify that indexes have been created and enabled</p> <p></p> <p></p> <p></p>"},{"location":"splunk/splunk.html#edit-config-files-for-windows-app","title":"Edit config files for Windows app","text":"<p>On the Linux host where Splunk Enterprise is installed, change into <code>opt/splunk/etc/deployment-apps/Splunk_TA_windows/local</code> directory</p> <p>Copy <code>app.conf</code> and <code>inputs.conf</code> from <code>/opt/splunk/etc/deployment-apps/Splunk_TA_windows/default</code> directory</p> <pre><code>cd /opt/splunk/etc/deployment-apps/Splunk_TA_windows/local\ncp /opt/splunk/etc/deployment-apps/Splunk_TA_windows/default/app.conf .\ncp /opt/splunk/etc/deployment-apps/Splunk_TA_windows/default/inputs.conf .\n</code></pre> <p>Make the following changes to <code>inputs.conf</code></p> <pre><code>nano inputs.conf\n</code></pre> <pre><code>[default]\nindex = wineventlog\n\n###### OS Logs ######\n[WinEventLog://Application]\ndisabled = 0\nstart_from = oldest\ncurrent_only = 0\ncheckpointInterval = 5\nrenderXml=false\n\n[WinEventLog://Security]\ndisabled = 0\nstart_from = oldest\ncurrent_only = 0\nevt_resolve_ad_obj = 1\ncheckpointInterval = 5\nblacklist1 = EventCode=\"4662\" Message=\"Object Type:(?!\\s*groupPolicyContainer)\"\nblacklist2 = EventCode=\"566\" Message=\"Object Type:(?!\\s*groupPolicyContainer)\"\nrenderXml=false\n\n[WinEventLog://System]\ndisabled = 0\nstart_from = oldest\ncurrent_only = 0\ncheckpointInterval = 5\nrenderXml=false\n</code></pre> <p>On WS2019 host where Splunk Universal Forwarder is configured, navigate to </p> <p><code>C:\\Program Files\\SplunkUniversalForwarder\\etc\\apps\\Splunk_TA_windows\\local</code></p> <p>Copy <code>app.conf</code> and <code>inputs.conf</code> from <code>C:\\Program Files\\SplunkUniversalForwarder\\etc\\apps\\Splunk_TA_windows\\default</code></p> <p>Edit <code>inputs.conf</code> (same as above)</p> <p></p> <p>Restart Splunk Universal Forwarder</p> <p>On PowerShell, change directory into <code>C:\\program files\\SplunkUniversalForwarder\\bin</code></p> <p>Run <code>./splunk restart</code></p> <pre><code>PS C:\\Users\\Administrator&gt; cd \"C:\\program files\\SplunkUniversalForwarder\\bin\"\nPS C:\\program files\\SplunkUniversalForwarder\\bin&gt; ./splunk restart\nSplunkForwarder: Stopped\n\nSplunk&gt; Another one.\n\nChecking prerequisites...\n        Checking mgmt port [8089]: open\n        Checking conf files for problems...\n        Done\n        Checking default conf files for edits...\n        Validating installed files against hashes from 'C:\\program files\\SplunkUniversalForwarder\\splunkforwarder-9.3.0-51ccf43db5bd-windows-64-manifest'\n        All installed files intact.\n        Done\nAll preliminary checks passed.\n\nStarting splunk server daemon (splunkd)...\n\nSplunkForwarder: Starting (pid 2328)\nDone\n</code></pre> <p>Verify that data is being forwarded on wineventlog index</p> <p>On web UI, navigate to Settings &gt; Indexes and refresh the page</p> <p>Go to Apps &gt; Search &amp; Reporting &gt; Search for index=wineventlog</p> <p></p> <p></p> <p>If the logs are not being indexed, try refreshing the web UI. </p> <p>If searching for <code>index=wineventlog</code> does not return any result, try searching All time instead of Last 24 hours.</p>"},{"location":"splunk/splunk.html#edit-config-files-for-sysmon-app","title":"Edit config files for Sysmon app","text":"<p>On CentOS host where Splunk Enterprise is installed, change into <code>/opt/splunk/etc/deployment-apps/Splunk_TA_microsoft_sysmon/local</code> directory</p> <p>Copy <code>app.conf</code> and <code>inputs.conf</code> from <code>/opt/splunk/etc/deployment-apps/Splunk_TA_microsoft_sysmon/default</code> directory</p> <pre><code>cd /opt/splunk/etc/deployment-apps/Splunk_TA_microsoft_sysmon/local\ncp /opt/splunk/etc/deployment-apps/Splunk_TA_microsoft_sysmon/default/app.conf .\ncp /opt/splunk/etc/deployment-apps/Splunk_TA_microsoft_sysmon/default/inputs.conf .\n</code></pre> <p>Make the following changes to <code>inputs.conf</code></p> <pre><code>nano inputs.conf\n</code></pre> <p>Note: your index name must match with the index name you created earlier</p> <pre><code>[default]\nindex = sysmonlog\n\n[WinEventLog://Microsoft-Windows-Sysmon/Operational]\ndisabled = false\nrenderXml = 1\nsource = XmlWinEventLog:Microsoft-Windows-Sysmon/Operational\n\n[WinEventLog://WEC-Sysmon]\ndisabled = true\nrenderXml = 1\nsource = XmlWinEventLog:Microsoft-Windows-Sysmon/Operational\nsourcetype = XmlWinEventLog:WEC-Sysmon\nhost = WinEventLogForwardHost\n</code></pre> <p>On WS2019 host where Splunk Universal Forwarder is configured, navigate to </p> <p><code>C:\\Program Files\\SplunkUniversalForwarder\\etc\\apps\\Splunk_TA_microsoft_sysmon\\local</code></p> <p>Copy <code>app.conf</code> and <code>inputs.conf</code> from <code>C:\\Program Files\\SplunkUniversalForwarder\\etc\\apps\\Splunk_TA_microsoft_sysmon\\default</code></p> <p>Edit <code>inputs.conf</code> (same as above) </p> <p></p> <p>Restart Splunk Universal Forwarder</p> <p>On PowerShell, change directory into <code>C:\\program files\\SplunkUniversalForwarder\\bin</code></p> <p>Run <code>./splunk restart</code></p> <pre><code>PS C:\\program files\\SplunkUniversalForwarder\\bin&gt; ./splunk restart\nSplunkForwarder: Stopped\n\nSplunk&gt; Another one.\n\nChecking prerequisites...\n        Checking mgmt port [8089]: open\n        Checking conf files for problems...\n        Done\n        Checking default conf files for edits...\n        Validating installed files against hashes from 'C:\\program files\\SplunkUniversalForwarder\\splunkforwarder-9.3.0-51ccf43db5bd-windows-64-manifest'\n        All installed files intact.\n        Done\nAll preliminary checks passed.\n\nStarting splunk server daemon (splunkd)...\n\nSplunkForwarder: Starting (pid 4824)\nDone\n\nPS C:\\program files\\SplunkUniversalForwarder\\bin&gt;\n</code></pre> <p>Verify that Sysmon logs are being indexed</p> <p></p> <p>Search for <code>index=sysmonlog source=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational</code></p> <p></p>"},{"location":"splunk/splunk.html#edit-config-files-for-unix-app-optional","title":"Edit config files for Unix app (optional)","text":"<p>On a Linux host where Splunk Enterprise is installed, change into /opt/splunk/etc/deployment-apps/Splunk_TA_nix/local*directory</p> <p>Copy app.conf, inputs.conf and props.conf from /opt/splunk/etc/deployment-apps/Splunk_TA_nix/default directory</p> <pre><code>splunk@siem:/opt/splunk/etc/deployment-apps/Splunk_TA_nix/local$ cp /opt/splunk/etc/deployment-apps/Splunk_TA_nix/default/app.conf .\nsplunk@siem:/opt/splunk/etc/deployment-apps/Splunk_TA_nix/local$ cp /opt/splunk/etc/deployment-apps/Splunk_TA_nix/default/inputs.conf .\nsplunk@siem:/opt/splunk/etc/deployment-apps/Splunk_TA_nix/local$ cp /opt/splunk/etc/deployment-apps/Splunk_TA_nix/default/props.conf .\n</code></pre> <p>Make the following changes to inputs.conf</p> <p>Add your index name</p> <pre><code>[default]\nindex = unixlog\n...\n[monitor:///var/log]\nwhitelist=(\\.log|log$|messages|secure|auth|mesg$|cron$|acpid$|\\.out)\nblacklist=(lastlog|anaconda\\.syslog)\ndisabled = 0\n...\n</code></pre> <p>On CentOShost where UF is configured, navigate to /opt/splunkforwarder/etc/apps/Splunk_TA_nix/local directory</p> <p>Copy app.conf, inputs.conf and props.conf from /opt/splunkforwarder/etc/apps/Splunk_TA_nix/default directory</p> <pre><code>splunk@siem3:/opt/splunkforwarder/etc/apps/Splunk_TA_nix/local$ cp /opt/splunkforwarder/etc/apps/Splunk_TA_nix/default/app.conf .\nsplunk@siem3:/opt/splunkforwarder/etc/apps/Splunk_TA_nix/local$ cp /opt/splunkforwarder/etc/apps/Splunk_TA_nix/default/inputs.conf .\nsplunk@siem3:/opt/splunkforwarder/etc/apps/Splunk_TA_nix/local$ cp /opt/splunkforwarder/etc/apps/Splunk_TA_nix/default/props.conf .\n</code></pre> <p>Edit inputs.conf (same as above)</p> <p>Restart Splunk Universal Forwarder</p> <pre><code>cd /opt/splunkuniversalforwarder/bin\n./splunk restart\n</code></pre> <p>Verify data being indexed</p> <p></p> <p></p>"},{"location":"splunk/splunk.html#annex-1-using-virtual-account-to-install-universal-forwarder-windows","title":"Annex 1: Using Virtual Account to install Universal Forwarder (Windows)","text":"<p>Selecting Virtual Account will create a service account called NT SERVICE\\SplunkForwarder. For Sysmon Log Forwarding to work, NT SERVCIE\\SplunkForwarder must be assigned as a member of Event Log Readers group through Group Policy. If your Windows host is not joined to a domain and you have technical issues with the Virtual Account, use Local System but note that this is not best security practice. </p> <p></p> <p>Leave the values as default and click Next</p> <p></p> <p>Leave the values as default and click Next (Windows Event Logs forwarding will be configured later)</p> <p></p> <p>Create admin credentials</p> <p></p> <p>Enter IP address of your Deployment Server (Splunk server) and port 8089</p> <p></p> <p>Enter IP address of your Receiving Indexer (Splunk server) and port 9997</p> <p></p> <p>Click Next and finish install. </p> <p>Navigate to C:\\Program Files\\SplunkUniversalForwarder</p> <p>Right-click and select properties</p> <p>Verify that Splunk Universal Forwarder is configured to run by virtual account SplunkForwarder</p> <p></p> <p>Open Group Policy Management</p> <p>Right click on domain name and select Create a GPO in this domain and link it here</p> <p></p> <p>Name it as Restricted Groups</p> <p></p> <p>Right click on Restricted Groups and click Edit</p> <p></p> <p>Navigate to Restricted Groups and Add Group</p> <p></p> <p>Click Browse</p> <p></p> <p>Type event log readers and click Check Names</p> <p>Make sure that the names is underlined. Click OK</p> <p></p> <p>Add NT SERVICE\\SplunkForwarder as a member of this group</p> <p>Click OK. Click Apply and OK</p> <p></p> <p>Verify the configuration</p> <p></p> <p>On Command Prompt as Administrator run gpupdate /force</p> <pre><code>C:\\Users\\Administrator&gt;gpupdate /force\nUpdating policy...\n\nComputer Policy update has completed successfully.\nUser Policy update has completed successfully.\n</code></pre> <p>Restart SplunkForwarder service. </p> <p>Go to Services &gt; SplunkForwarder &gt; Right-click and select restart</p> <p></p> <p>If Sysmon logs are not being ingested by Splunk, check Channel Access setting for Sysmon.</p> <p>It is likely that SplunkForwarder is not added to the Channel Access.</p> <pre><code>wevtutil gl \"Microsoft-Windows-Sysmon/Operational\"\n</code></pre> <p>Get SecurityIdentifier(sid) of SplunkForwarder by running this PowerShell script</p> <pre><code>$user = [System.Security.Principal.NTAccount]\"NT SERVICE\\SplunkForwarder\"\n$sid = $user.Translate([System.Security.Principal.SecurityIdentifier])\nWrite-Output $sid.Value\n</code></pre> <p>Add SplunkForwarder to Channel Access bu running the command below</p> <p>Note: add your sid of SplunkForwarder</p> <pre><code>wevtutil sl \"Microsoft-Windows-Sysmon/Operational\" /ca:\"O:BAG:SYD:(A;;0x2;;;S-1-15-2-1)(A;;0x2;;;S-1-5-80-972488765-139171986-783781252-3188962990-3730692313)(A;;0xf0007;;;SY)(A;;0x7;;;BA)(A;;0x1;;;BO)(A;;0x1;;;SO)(A;;0x1;;;S-1-5-32-573)\"\n</code></pre> <p>Restart SplunkForwarder Service</p>"},{"location":"splunk/splunk.html#annex-2-configure-splunk-universal-forwarder-on-linux-optional","title":"Annex 2: Configure Splunk Universal Forwarder on Linux (optional)","text":"<p>Note: this step is optional and is only applicable to Linux host. In this demonstration, Ubuntu was used for two hosts. Splunk Enterprise was configured in one host and Splunk Universal Forwarder was configured in another host. </p> <p>Demonstration Setup</p> Hostname OS Role IP Address siem Ubuntu 22.04 LTS Splunk Enterprise (server) 192.168.1.217 siem3 Ubuntu 22.04 LTS Splunk Universal Forwarder (client) 192.168.1.117 <p>Download or transfer Splunk Universal Forwarder (tar archive)</p> <p>Unpack the tar archive to /opt directory as a non-root user</p> <pre><code>sudo tar xvzf Splunk_UF_package_name.tgz -C /opt\n</code></pre> <p>Create a user called splunk and change the ownership of /opt/splunkforwarder/bin to splunk user</p> <pre><code>#Create user splunk \nsudo su -\nroot@siem3:~# adduser splunk\nAdding user `splunk' ...\nAdding new group `splunk' (1001) ...\nAdding new user `splunk' (1001) with group `splunk' ...\nCreating home directory `/home/splunk' ...\nCopying files from `/etc/skel' ...\nNew password: \nRetype new password: \npasswd: password updated successfully\nChanging the user information for splunk\nEnter the new value, or press ENTER for the default\n    Full Name []: \n    Room Number []: \n    Work Phone []: \n    Home Phone []: \n    Other []: \nIs the information correct? [Y/n] Y \n\n#make the splunk user the owner of the splunk directory and verify\nsiem@siem3:~$ sudo chown -R splunk:splunk /opt/splunkforwarder/\nsiem@siem3:~$ cd /opt\nsiem@siem3:/opt$ ls -la\ntotal 12\ndrwxr-xr-x  3 root   root   4096 Aug 13 10:05 .\ndrwxr-xr-x 20 root   root   4096 Aug 13 07:48 ..\ndrwxr-xr-x  9 splunk splunk 4096 Jul 20 10:23 splunkforwarder\n\nsiem@siem3:/opt$ su splunk\nPassword: \nsplunk@siem3:/opt$ cd splunkforwarder/bin\nsplunk@siem3:/opt/splunkforwarder/bin$ ./splunk start --accept-license\n#Create admin credentials (i.e. user account for UF, e.g. splunk:password)\n\n#At some point after the setup, enable boot-start by running\nsiem@siem3:/opt/splunkforwarder/bin$ sudo ./splunk enable boot-start\n</code></pre> <p>Connect to the deployment server</p> <p>Deployment server allows engineers/system admins to push out apps to multiple splunk instances and apps is easier way to handle changes (e.g. changes in config)</p> <pre><code>splunk@siem3:/opt/splunkforwarder/bin$ ./splunk set deploy-poll 192.168.1.217:8089\n#Enter admin credentials\n</code></pre> <p>Verify that there is deploymentclient.conf in /opt/splunkforwarder/etc/system/local</p> <pre><code>cat /opt/splunkforwarder/etc/system/local/deploymentclient.conf\n...\ntargetUri = 192.168.1.217:8089\n</code></pre> <p>Setup Splunk to send logs to another location by adding forward server</p> <pre><code>splunk@siem3:/opt/splunkforwarder/bin$ ./splunk add forward-server 192.168.1.217:9997\n</code></pre> <p>Verify that there is outputs.conf in /opt/splunkforwarder/etc/system/local</p> <pre><code>cat /opt/splunkforwarder/etc/system/local/outputs.conf\n...\nserver = 192.168.1.217:9997\n</code></pre> <p>Restart Splunk Forwarder for changes to take effect</p> <pre><code>splunk@siem3:/opt/splunkforwarder/bin$ ./splunk restart\n</code></pre> <p>On web UI of Splunk Enterprise, go to settings, forwarder management.</p> <p>You should be able to see your host machine that has been connected to your deployment server.</p> <p>Try refreshing the web browser or restart Splunk Enterprise</p> <pre><code>splunk@siem:/opt/splunk/bin$ ./splunk restart\n</code></pre> <p></p>"},{"location":"splunk/splunk.html#annex-3-manual-configuration-of-data-input-on-linux-host","title":"Annex 3: Manual configuration of data input on Linux host","text":"<p>Note: this step is optional and is only applicable to Linux host. In this demonstration, apache2 have been started on siem3 host and apache logs are being forwarded.</p> <p>Demonstration Setup</p> Hostname OS Role IP Address siem Ubuntu 22.04 LTS Splunk Enterprise (server) 192.168.1.217 siem3 Ubuntu 22.04 LTS Splunk Universal Forwarder (client) 192.168.1.117 <p>Add data that you want to forward to the UF using add monitor command</p> <pre><code>./splunk add monitor -auth splunk:password /var/log/apache2\n</code></pre> <p>Verify that data is being indexed (i.e. forwarded) on Splunk Enterprise</p> <p>Navigate to Splunk Enterprise web UI &gt; Search &amp; Reporting &gt; Data Summary</p>"},{"location":"splunk/splunk.html#introduction-to-splunk","title":"Introduction to Splunk","text":"<p>Splunk offers free training. You will need to create a user account to access free training materials. The following content is available from the free course \u201cIntroduction to Splunk.\u201d Alternatively, same contents are available from SplunkHowTo YouTube channel.</p>"},{"location":"splunk/splunk.html#creating-reports","title":"Creating Reports","text":"<p>For demonstration, SSH Brute Force attack was simulated from Kali machine to FortiGate. Also SSH login attempts were made from other internal hosts to FortiGate. </p> <p>On Splunk Enterprise web UI, search for Admin login failed on FortiGate</p> <pre><code>index=* sourcetype=fgt_event \u201cAdmin login failed\u201d\n</code></pre> <p>Select srcip form Interesting Fields, then select Top values</p> <p></p> <p>This will visualise data as a bar chart. Save As Report</p> <p></p> <p>Set Title as Security_Report_Failed_SSH_Login_Attempts</p> <p>Set Content as Bar Chart</p> <p>Select Yes for Time Range Picker</p> <p>Save</p> <p></p> <p>Select View</p> <p></p> <p>Note Time Range Picker can be adjusted to your preference (e.g. All time or Last 24 hours)</p> <p>Select Reports</p> <p></p> <p>Navigate to Reports tab. Edit Permissions for Security_Report_Failed_SSH_Login_Attempts.</p> <p></p> <p>Select following options:</p> <ul> <li>Display For App</li> <li>Run As User</li> <li>Assign Read to Everyone</li> </ul> <p>Click Save</p> <p></p> <p>Edit Schedule (optional)</p> <p>Scheduling Report can reduce strain on your environment caused by repeatedly running new ad-hoc searches</p> <p>Select Schedule and Time Range of your preference</p> <p>click Save</p> <p></p> <p></p>"},{"location":"splunk/splunk.html#creating-alerts","title":"Creating Alerts","text":"<p>On Splunk Enterprise web UI, search for Admin login failed on FortiGate.</p> <pre><code>index=* sourcetype=fgt_event \"Admin login failed\"\n</code></pre> <p>Save As Alert</p> <p></p> <p>Set Title as FortiGate Login Failures</p> <p>Set Permissions to Private</p> <p>Set Alert type as Schedules to Run every hours and Expire after 24 hours</p> <p>Set Trigger Conditions to trigger alert when Number of Results is greater than 10 and trigger Once.</p> <p>Select Throttle (after an alert is triggered, subsequent alerts will not be triggered until after the throttle period).</p> <p>Suppress trigger for 60 seconds</p> <p>Set Trigger Actions to Add to Trigger Alerts with High Severity.</p> <p>Click Save. </p> <p></p> <p></p> <p>Click Permissions</p> <p></p> <p>Select Display For App</p> <p>Assign Read access to Everyone</p> <p>Click Save</p> <p></p> <p>Select Edit Alert again</p> <p></p> <p>Change Alert type to Real-time</p> <p>Suppress all fields containing field value by entering a wildcard</p> <p></p> <p>Click Save</p> <p>View Triggered Alerts</p> <p></p> <p>Alternatively, Triggered Alerts can be viewed on the Activity tab</p> <p></p> <p>Alerts and Reports can be viewed from Setting &gt; Searches, reports, and alerts</p> <p></p> <p>Alerts can also be viewed from the Alerts tab</p> <p></p>"},{"location":"splunk/splunk.html#creating-dashboards","title":"Creating Dashboards","text":"<p>On Splunk Enterprise web UI, search for Admin login failed events are generated on FortiGate</p> <pre><code>index=* sourcetype=fgt_event \"Admin login failed\"\n</code></pre> <p></p> <p>From the Interesting Fields panel, Select user and Top values. Alternatively, you can filter on srcip Top values if there are multiple source IP addresses.</p> <p></p> <p>This will generate a Visualisation that is most suitable for our data</p> <p></p> <p>Select Bar Chart and select Pie Chart</p> <p></p> <p>Click Save As and select New Dashboard</p> <p></p> <p>Set Dashboard Title and Permissions.</p> <p>Select Classic Dashboards (we will explore Dashboard Studio later)</p> <p>Set Panel Title </p> <p>Set Visualization Type as Pie Chart</p> <p>Save to Dashboard</p> <p></p> <p>View Dashboard</p> <p></p> <p></p> <p>Go back to Search and search for <code>index=* sourcetype=fgt_event \u201cAdmin login\u201d</code></p> <p>In the Interesting Fields panel, select logdesc, then Top values by time</p> <p></p> <p>This allows us to see login trends over time as a line chart (select Last 24 hours)</p> <p></p> <p>Select Format</p> <p>Select Legend, then Legend Position as Left</p> <p></p> <p>Select General</p> <p>Select Min/Max in Show Data Values</p> <p></p> <p>Save As Existing Dashboard</p> <p>Select FortiGate Logins</p> <p>Save to Dashboard</p> <p></p> <p>View Dashboard</p> <p></p> <p></p> <p>Click Edit on top right</p> <p>Add Panel</p> <p>Select New from Report </p> <p>Select Security_Report_Failed_SSH_Login_Attempts</p> <p></p> <p>Select Add to Dashboard</p> <p></p> <p>Drag and Drop Bar Chart next to the Pie Chart</p> <p>Edit Drilldown on the Pie Chart</p> <p></p> <p>Set Drilldown Action On click to Link to Search </p> <p>click Apply</p> <p></p> <p>Save the Dashboard</p> <p></p>"},{"location":"splunk/splunk.html#dashboard-studio","title":"Dashboard Studio","text":"<p>Make sure FortiGate Logins Dashboard is opened</p> <p>Select Clone in Dashboard Studio</p> <p></p> <p>Set Title as FortiGate Logins - Dashboard Studio</p> <p>Select Grid layout</p> <p>Click Convert &amp; Save</p> <p></p> <p>Click Save</p> <p>If Save button is greyed out, toggle Add submit button then click Save.</p> <p>Revert the changes then click Save. </p> <p>Click View</p> <p></p> <p></p>"},{"location":"splunk/splunk.html#references","title":"References","text":"<ul> <li>https://youtu.be/gNeF_mT6Eng?si=No3aBK1EDt_LuK80</li> <li>https://youtu.be/Wze0yXsMKVM?si=N6Y4iW3m5ewxD1Hv</li> <li>https://youtu.be/Iol1CHyv23A?si=ZWXFI-QOZVA8BUaa</li> <li>https://youtu.be/zFosqdAadJg?si=mn5HtZHhud3jkcPR</li> <li>https://docs.splunk.com/Documentation/Splunk/9.3.0/Installation/Whatsinthismanual</li> <li>https://community.splunk.com/t5/Getting-Data-In/Sysmon-events-not-getting-indexed/m-p/688793?lightbox-message-images-688793=31015i33DABC9A02E482CD#M114683</li> <li>https://youtu.be/1Ur3xDNaE4s?si=Dfh4-4PDkOccbnTR</li> <li>https://splunk.github.io/splunk-connect-for-syslog/main/</li> <li>https://gitlab.com/J-C-B/community-splunk-scripts/-/tree/master/</li> <li>https://youtu.be/zWkGVnsNY8M?si=9iNqCFLlktpQq6qQ</li> <li>https://youtu.be/Xepw_Xk9HX8?si=-D53cGVAs7Ckcrp6</li> <li>https://youtu.be/8jvEmAmQNug?si=tc2tzJh4uOG9I62V</li> <li>https://youtu.be/uQUAvY5M3RU?si=JKk_M_60LLsvk0w6</li> <li>https://youtu.be/2kU1ZTAZphY?si=H3zP0QD9m8MmL2bG</li> </ul>"},{"location":"suricata/suricata.html","title":"Suricata","text":"<p>Suricata is an open-source network threat detection engine developed by the Open Information Security Foundation (OISF). It provides capabilities for real-time intrusion detection (IDS), inline intrusion prevention (IPS), network security monitoring (NSM), and offline packet capture (pcap) processing. </p>"},{"location":"suricata/suricata.html#lab-setup-for-proof-of-concept","title":"Lab Setup for Proof of Concept","text":"<p>In this proof of concept, instead of simulating attacks, the Windows host acted as a compromised machine where malicious websites were visited to trigger alerts in a safe and controlled setting.</p> Host OS Role IP Address pfsense FreeBSD (pfSense v2.7.2) Firewall/Router (Gateway IDS/IPS) 192.168.1.200 (WAN) / 10.0.0.2 (LAN) Suricata Ubuntu 22.04 LTS Host IDS/IPS 10.0.0.27 WS2019 Windows Server 2019 Compromised machine 10.0.0.24 <p></p>"},{"location":"suricata/suricata.html#install-suricata-on-host","title":"Install Suricata on Host","text":"<p>In this demonstration, we will be installing Suricata on the Ubuntu virtual machine. We will be simulating install in an air-gapped environment but note that some parts of the step requires internet connection.</p> <p>On a Ubuntu machine with internet access Add the necessary repository for Suricata:</p> <pre><code>sudo apt-get install software-properties-common\nsudo add-apt-repository ppa:oisf/suricata-stable\nsudo apt-get update\n</code></pre> <p>Create a directory to store Suricata. Adjust the directory permissions:</p> <pre><code>sudo mkdir ~/suricata-offline\ncd ~/suricata-offline\nsudo chmod 755 ~/suricata-offline\n</code></pre> <p>Download the Suricata package and all its dependencies:</p> <p>Download the Emerging Threats Open rule set:</p> <pre><code>sudo apt-get download suricata\nsudo wget https://rules.emergingthreats.net/open/suricata-7.0.6/emerging.rules.tar.gz\n</code></pre> <p>Create a directory to store dependencies. Adjust the directory permissions:</p> <pre><code>sudo mkdir dependencies\ncd dependencies\nsudo chmod 755 ~/suricata-offline/dependencies\n</code></pre> <p>Download the required dependencies</p> <pre><code>sudo apt-get download autoconf automake build-essential cargo cbindgen \\\n    libjansson-dev libpcap-dev libpcre2-dev libtool libyaml-dev make \\\n    pkg-config rustc zlib1g-dev libc6-dev gcc g++ dpkg-dev binutils \\\n    libpcre2-16-0 libpcre2-posix3 libdpkg-perl libstd-rust-dev libssh2-1 \\\n    libpcap0.8-dev m4 autotools-dev binutils-common libbinutils \\\n    binutils-x86-64-linux-gnu g++-11 gcc-11 libc-dev-bin linux-libc-dev \\\n    libcrypt-dev rpcsvc-proto libtirpc-dev libnsl-dev libdbus-1-dev \\\n    libstd-rust-1.75 libctf-nobfd0 libctf0 lto-disabled-list libstdc++-11-dev \\\n    libcc1-0 libgcc-11-dev libsigsegv2 libc6=2.35-0ubuntu3.8 libitm1 \\\n    libasan6 liblsan0 libtsan0 libubsan1 libquadmath0 \\\n    libevent-pthreads-2.1-7 libhiredis0.14 libhtp2 libhyperscan5 \\\n    libluajit-5.1-2 libnet1 libnetfilter-queue1 libluajit-5.1-common \\\n    liblzma-dev libevent-core-2.1-7 curl jq libcurl4=7.81.0-1ubuntu1.17 libjq1=1.6-2.1ubuntu3 libonig5 libc6-dbg libc6 zlib1g\n</code></pre> <p>Transfer suricata-offline folder to /opt directory in Ubuntu machine without internet access. </p> <p>Install dependencies and suricata</p> <pre><code>cd /opt/suricata-offline/dependencies\nsudo dpkg -i \n</code></pre> <p>Install Suricata</p> <pre><code>cd /opt/suricata-offline/\nsudo dpkg -i suricata_1%3a7.0.6-0ubuntu2_amd64.deb\n</code></pre> <p>After installing Suricata, you can check which version of Suricata you have running and with what options, as well as the service state:</p> <p>Suricata is running in exited state, which typically indicates that the service started successfully and then exited without issues because it's running in IDS mode.</p> <pre><code>sudo suricata --build-info\nsudo systemctl status suricata\n</code></pre>"},{"location":"suricata/suricata.html#basic-setup","title":"Basic setup","text":"<p>First, determine the interface(s) and IP address(es) on which Suricata should be inspecting network packets:</p> <pre><code>ip a\n...\n2: ens32: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000\n    link/ether 00:0c:29:51:ef:1b brd ff:ff:ff:ff:ff:ff\n    altname enp2s0\n    inet 10.0.0.25/24 brd 10.0.0.255 scope global noprefixroute ens32\n</code></pre> <p>Use that information to configure Suricata:</p> <pre><code>sudo nano /etc/suricata/suricata.yaml\n</code></pre> <p>Specify internal network in the HOME_NET </p> <p>Specify network interface in af-packet and pcap.</p> <p>Set use-mmap to yes.</p> <p>Set community-id to true</p> <pre><code>vars:\n  # more specific is better for alert accuracy and performance\n  address-groups:\n    HOME_NET: \"[10.0.0.0/24]\"\n...\ncommunity-id: true\n...\naf-packet:\n    - interface: ens32\n      cluster-id: 99\n      cluster-type: cluster_flow\n      defrag: yes\n      use-mmap: yes\n...\n# Cross platform libpcap capture support\npcap:\n  - interface: ens32\n\n checksum-validation: no\n</code></pre>"},{"location":"suricata/suricata.html#suricata-update-offline","title":"Suricata-update offline","text":"<p>Run <code>suricata-update</code> to update rules and create /var/lib/suricata folder</p> <p>Note it is expected to get the error \u201cFailed to fetch https://rules.emergingthreats.net/open/suricata-7.0.6/emerging.rules.tar.gz:\u201d</p> <pre><code>sudo suricata-update\n</code></pre> <p>Make a folder called suricata-rules and extract <code>emerging.rules.tar.gz</code> to that directory</p> <pre><code>sudo mkdir suricata-rules\nsudo tar -xvzf emerging.rules.tar.gz -C /opt/suricata-offline/suricata-rules/\n</code></pre> <p>Append the rules from the file to the main /var/lib/suricata/rules/suricata.rules file</p> <pre><code>sudo bash -c 'find /opt/suricata-offline/suricata-rules/rules/ -name \".rules\" -exec cat {} + &gt;&gt; /var/lib/suricata/rules/suricata.rules'\n</code></pre>"},{"location":"suricata/suricata.html#suricata-update-online-recommended","title":"Suricata-update online (recommended)","text":"<p>Running suricata-update with internet connection simplifies the process of downloading and installing rulesets.</p> <pre><code>sudo suricata-update\n</code></pre> <p>You can also list sources and download rules from a specific source</p> <pre><code>sudo suricata-update list-sources\n</code></pre> <p>Summary of different license types:</p> <ul> <li>MIT is very permissive, allowing almost any use, even commercial.</li> <li>Commercial requires you to pay or subscribe for usage rights, often with strict terms.</li> <li>CC-BY-SA-4.0 requires you to give credit and share any modifications under the same license.</li> <li>GPL-3.0 requires sharing modifications under the same open-source license and offering the source code.</li> <li>Non-Commercial restricts usage to personal or non-commercial contexts.</li> </ul> <p>To download the ruleset from a specific source, run:</p> <p>If required, update sources</p> <pre><code>sudo suricata-update update-sources\nsudo suricata-update enable-source &lt;Name&gt;\nsudo suricata-update\n</code></pre> <p>Test Suricata configuration file by running</p> <pre><code>sudo suricata -T -c /etc/suricata/suricata.yaml -v\n</code></pre> <pre><code>#Example output\n\nNotice: suricata: This is Suricata version 7.0.6 RELEASE running in SYSTEM mode\nInfo: cpu: CPUs/cores online: 2\nInfo: suricata: Running suricata under test mode\nInfo: suricata: Setting engine mode to IDS mode by default\nInfo: exception-policy: master exception-policy set to: auto\nInfo: logopenfile: fast output device (regular) initialized: fast.log\nInfo: logopenfile: eve-log output device (regular) initialized: eve.json\nInfo: logopenfile: stats output device (regular) initialized: stats.log\nInfo: detect: 1 rule files processed. 39802 rules successfully loaded, 0 rules failed, 0\nInfo: threshold-config: Threshold config parsed: 0 rule(s) found\nInfo: detect: 39805 signatures processed. 1158 are IP-only rules, 4116 are inspecting packet payload, 34321 inspect application layer, 108 are decoder event only\nNotice: suricata: Configuration provided was successfully loaded. Exiting.\n</code></pre> <p>Note the difference in number of signatures processed, inspecting packet payload and inspect application layers when suricata-update was executed without internet access:</p> <pre><code>Info: detect: 39669 signatures processed. 1158 are IP-only rules, 4110 are inspecting packet payload, 34193 inspect application layer, 108 are decoder event only\nNotice: suricata: Configuration provided was successfully loaded. Exiting.\n</code></pre>"},{"location":"suricata/suricata.html#running-suricata","title":"Running Suricata","text":"<p>With the rules installed, Suricata can run properly and thus we restart it:</p> <pre><code>sudo systemctl restart suricata\n</code></pre> <p>To make sure Suricata is running check the Suricata log:</p> <pre><code>sudo tail /var/log/suricata/suricata.log\n</code></pre> <p>The last line will be similar to this:</p> <pre><code>5933 - Suricata-Main] 2024-09-12 13:26:11 Notice: threads: Threads created -&gt; W: 2 FM: 1 FR: 1   Engine started.\n</code></pre> <p>The actual thread count will depend on the system and the configuration.</p> <p>To see statistics, check the\u00a0<code>stats.log</code>\u00a0file:</p> <pre><code>sudo tail -f /var/log/suricata/stats.log\n</code></pre> <p>By default, it is updated every 8 seconds to show updated values with the current state, like how many packets have been processed and what type of traffic was decoded.</p>"},{"location":"suricata/suricata.html#alerting","title":"Alerting","text":"<p>To test the IDS functionality of Suricata it's best to test with a signature. The signature with ID\u00a0<code>2100498</code>\u00a0from the ET Open ruleset is written specific for such test cases.</p> <p>2100498:</p> <pre><code>alert ip any any -&gt; any any (msg:\"GPL ATTACK_RESPONSE id check returned root\"; content:\"uid=0|28|root|29|\"; classtype:bad-unknown; sid:2100498; rev:7; metadata:created_at 2010_09_23, updated_at 2010_09_23;)\n</code></pre> <p>The syntax and logic behind those signatures is covered in other chapters. This will alert on any IP traffic that has the content within its payload. This rule can be triggered quite easy. Before we trigger it, start\u00a0<code>tail</code>\u00a0to see updates to\u00a0<code>fast.log</code>.</p> <pre><code>curl http://testmynids.org/uid/index.html\nsudo tail /var/log/suricata/fast.log\n</code></pre> <p>The following output should now be seen in the log:</p> <pre><code>09/12/2024-13:51:32.520238  [] [1:2100498:7] GPL ATTACK_RESPONSE id check returned root [] [Classification: Potentially Bad Traffic] [Priority: 2] {TCP} 65.9.141.53:80 -&gt; 10.0.0.25:34606Alerts:\n</code></pre> <p>This should include the timestamp and the IP of your system.</p>"},{"location":"suricata/suricata.html#custom-rules","title":"Custom rules","text":"<p>Stop Suricata service:</p> <pre><code>sudo systemctl stop suricata\n</code></pre> <p>Create local.rules</p> <pre><code>sudo nano /usr/share/suricata/rules/local.rules\n</code></pre> <p>Write following rule to alert on ping to internal network (note syntax is very similar to Snort)</p> <pre><code>alert icmp any any -&gt; $HOME_NET any (msg: \"ICMP Ping Detected\"; sid:1; rev:1;)\n</code></pre> <p>Edit suricata.yml</p> <pre><code>sudo nano /etc/suricata/suricata.yaml \n</code></pre> <p>Add local.rules to rule-files</p> <pre><code>default-rule-path: /var/lib/suricata/rules\n\nrule-files:\n  - suricata.rules\n  - /usr/share/suricata/rules/local.rules\n</code></pre> <p>Test Suricata configuration:</p> <pre><code>sudo suricata -T -c /etc/suricata/suricata.yaml -v\n</code></pre> <p>Start Suricata and verify it is running and active. </p> <pre><code>sudo systemctl start suricata\nsudo systemctl status suricata\n</code></pre> <p>Execute ping to Suricata host from another host in internal network</p> <p>Verify that the alerts have been logged</p> <pre><code>sudo tail /var/log/suricata/fast.log\n</code></pre> <pre><code>09/12/2024-14:14:31.052314  [] [1:1:1] ICMP Ping Detected [] [Classification: (null)] [Priority: 3] {ICMP} 10.0.0.25:0 -&gt; 10.0.0.20:0\n09/12/2024-14:14:57.907164  [] [1:1:1] ICMP Ping Detected [] [Classification: (null)] [Priority: 3] {ICMP} 10.0.0.20:3 -&gt; 10.0.0.1:3\n</code></pre>"},{"location":"suricata/suricata.html#eve-json","title":"EVE JSON","text":"<p>The more advanced output is the EVE JSON output which is explained in detail in\u00a0Eve JSON Output. To see what this looks like it's recommended to use\u00a0<code>jq</code>\u00a0to parse the JSON output. Alerts:</p> <pre><code>sudo tail /var/log/suricata/eve.json | jq 'select(.event_type==\"alert\")'\n</code></pre> <p>This will display more detail about each alert with a better readability, including meta-data.</p> <pre><code>{\n  \"timestamp\": \"2024-09-12T14:21:18.932116+1200\",\n  \"flow_id\": 1750955545135946,\n  \"in_iface\": \"ens32\",\n  \"event_type\": \"alert\",\n  \"src_ip\": \"10.0.0.25\",\n  \"src_port\": 0,\n  \"dest_ip\": \"10.0.0.20\",\n  \"dest_port\": 0,\n  \"proto\": \"ICMP\",\n  \"icmp_type\": 0,\n  \"icmp_code\": 0,\n  \"pkt_src\": \"wire/pcap\",\n  \"community_id\": \"1:7Z0C1taw8mzKweAktDBR9AYDoBA=\",\n  \"alert\": {\n    \"action\": \"allowed\",\n    \"gid\": 1,\n    \"signature_id\": 1,\n    \"rev\": 1,\n    \"signature\": \"ICMP Ping Detected\",\n    \"category\": \"\",\n    \"severity\": 3\n  },\n  \"direction\": \"to_client\",\n  \"flow\": {\n    \"pkts_toserver\": 1,\n    \"pkts_toclient\": 1,\n    \"bytes_toserver\": 98,\n    \"bytes_toclient\": 98,\n    \"start\": \"2024-09-12T14:21:18.931964+1200\",\n    \"src_ip\": \"10.0.0.20\",\n    \"dest_ip\": \"10.0.0.25\"\n  }\n}\n</code></pre> <p>Stats:</p> <pre><code>sudo tail -f /var/log/suricata/eve.json | jq 'select(.event_type==\"stats\")|.stats.capture.kernel_packets'\nsudo tail -f /var/log/suricata/eve.json | jq 'select(.event_type==\"stats\")'\n</code></pre> <p>The first example displays the number of packets captured by the kernel; the second examples shows all of the statistics.</p>"},{"location":"suricata/suricata.html#setting-up-ips-inline-for-linux","title":"Setting up IPS inline for Linux","text":""},{"location":"suricata/suricata.html#setting-up-ips-with-netfilter","title":"Setting up IPS with Netfilter","text":"<p>To check if you have NFQ enabled in your Suricata build, enter the following command:</p> <pre><code>suricata --build-info\n</code></pre> <p>and make sure that <code>NFQueue support: yes</code> is listed in the output.</p> <p>Edit local.rules to add a sample rule for IPS mode:</p> <pre><code>sudo nano /usr/share/suricata/rules/local.rules\n</code></pre> <pre><code>#IDS Mode\nalert icmp any any -&gt; $HOME_NET any (msg: \"ICMP Ping Detected\"; sid:1; rev:1;)\n\n#IPS Mode\ndrop icmp any any -&gt; 1.1.1.1 any (msg:\"ICMP Detected and Blocked to 1.1.1.1\"; sid:2; rev:1;)\n</code></pre> <p>Run Suricata with the NFQ mode and use the\u00a0<code>-q</code>\u00a0option. This option tells Suricata which queue numbers it should use.</p> <pre><code>sudo suricata -c /etc/suricata/suricata.yaml -q 0\n</code></pre> <p>In this scenario, you are sending traffic that is generated by your computer to Suricata. Run:</p> <pre><code>sudo iptables -I INPUT -j NFQUEUE\nsudo iptables -I OUTPUT -j NFQUEUE\n</code></pre> <p>If Suricata is installed on the gateway (e.g. Firewall), you can send traffic that passes through Suricata by running:</p> <pre><code>sudo iptables -I FORWARD -j NFQUEUE\n</code></pre> <p>Execute <code>ping 1.1.1.1</code> and check Suricata alerts:</p> <pre><code>ping 1.1.1.1\ntail -f /var/log/suricata/fast.log\n</code></pre> <pre><code>09/14/2024-16:11:08.050136  [Drop] [] [1:2:1] ICMP Detected and Blocked to 1.1.1.1 [] [Classification: (null)] [Priority: 3] {ICMP} 10.0.0.27:8 -&gt; 1.1.1.1:0\n</code></pre> <p>To see if you have set your\u00a0<code>iptables</code>\u00a0rules correct make sure Suricata is running and enter:</p> <pre><code>sudo iptables -vnL\n</code></pre> <p>In the example you can see if packets are being logged.</p> <pre><code>Chain INPUT (policy ACCEPT 0 packets, 0 bytes)\n pkts bytes target     prot opt in     out     source               destination         \n 1032 1101K NFQUEUE    all  --               0.0.0.0/0            0.0.0.0/0            NFQUEUE num 0\n\nChain FORWARD (policy ACCEPT 0 packets, 0 bytes)\n pkts bytes target     prot opt in     out     source               destination         \n\nChain OUTPUT (policy ACCEPT 0 packets, 0 bytes)\n pkts bytes target     prot opt in     out     source               destination         \n 1469  126K NFQUEUE    all  --               0.0.0.0/0            0.0.0.0/0            NFQUEUE num 0\n</code></pre>"},{"location":"suricata/suricata.html#install-suricata-on-gateway","title":"Install Suricata on Gateway","text":"<p>While Suricata can be installed on a host, it can also be installed on a gateway such as pfSense. The pfSense\u00a0is a free and open source firewall and router. For installing and configuring pfSense, refer to pfSense documentation and instruction video. pfSense can be downloaded from here.</p> <p>Full demonstration video on configuring Suricata on pfSense can be found here. </p> <p>After competing basic configuration on pfSense, navigate to System &gt; Package Manager &gt; Available Packages on pfSense web UI.</p> <p>Search for <code>suricata</code> and click install (confirm when prompted). Internet connection is required.</p> <p></p> <p></p> <p>Once install is complete, navigate to Services &gt; Suricata &gt; Global Settings.</p> <p>Select Install ETOpen Emerging Threats rules, Install Feodo Tracker Botnet C2 IP rules and Install ABUSE.ch SSL Blacklist rules.</p> <p></p> <p>Select 1 Day for Update Interval and select Live Rule Swap on Update.</p> <p></p> <p>Leave rest of settings default and click save.</p> <p>Navigate to Update section and click Update.</p> <p></p> <p>Once rule set update is complete, you will see timestamps of recent update.</p> <p></p> <p>Navigate to Interfaces section and click Add.</p> <p></p> <p>Select interface to run Suricata. In this demonstration, Suricata is installed on the LAN interface.</p> <p></p> <p>For the EVE Output Settings, select EVE JSON Log and Output Type as FILE. Leave rest of the settings as default values and click Save.</p> <p></p> <p>Within the Interface section, navigate to LAN Categories and Select All rulesets and click Save.</p> <p>You can read about each rule in the LAN Rules section and enable certain rule instead of enabling all rules. Pointproof documentation explains about the emerging rules. </p> <p></p> <p>On pfSense VM, selection option 8 for shell and run <code>top -s 1</code> to monitor CPU</p> <pre><code>top -s 1\n</code></pre> <p></p> <p>Navigate back to Interfaces section and run Suricata by clicking the play button.</p> <p></p> <p>After a while, you will see a green tick box on Suricata Status, but CPU usage is still at 99%. Wait until CPU usage drops below 30% of pfSense VM CLI.</p> <p></p> <p>Navigate to the Alerts tab, and verify that there are no alerts.</p> <p></p>"},{"location":"suricata/suricata.html#testing-ids","title":"Testing IDS","text":"<p>Suricata by default generates alert when a user access .to domain. From the Windows host connected to pfSense on an internal network, navigate to https://amzn.to/3xPjJbS on a web browser.</p> <p>Note that the alerts have been generated but these are false positives.</p> <p></p>"},{"location":"suricata/suricata.html#finetuning-rules-to-reduce-false-positives","title":"Finetuning rules to reduce false positives","text":"<p>Copy GID:SID <code>1:2027757</code> . Navigate to SID Mgmt tab, select Enable Automatic SID State Management. Edit the disablesid-sample.conf</p> <p></p> <p>Edit the List Name as LAN-Disabled. Delete the existing content and copy and paste the following:</p> <pre><code>#ET DNS Query for .to TLD\n1:2027757\n</code></pre> <p></p> <p>Repeat the same process for dropsid-sample.conf and enablesid-sample.conf. Change the List Name of dropsid-sample.conf to LAN-Drops and enablesid-sample.conf to LAN-Enabled. Make sure they each have nothing in the content.</p> <p>For Interface SID Management List Assignments, select Rebuild. Select LAN-Enabled for Enable SID List, LAN-Disabled for Disable SID List.</p> <p></p> <p>Navigate back to Alerts tab and clear alerts</p> <p></p> <p>From the Windows host connected to pfSense on an internal network. Wait for CPU percentage to drop. Navigate to https://amzn.to/3xPjJbS on a web browser. Verify that alerts have not been generated.</p> <p></p> <p>Navigate to Interface Settings &gt; LAN Rules. Select emerging-dns.rules.</p> <p></p> <p>Search for <code>.to</code> . Verify that ET DNS Query for .to TLD is Auto-disabled by settings on SID Mgmt tab.</p> <p></p>"},{"location":"suricata/suricata.html#testing-ips","title":"Testing IPS","text":"<p>Disable Hardware Checksum Offloading. Navigate to System &gt; Advanced &gt; Networking.</p> <p>Select Disable hardware checksum offload and save. pfSense will reboot to apply changes.</p> <p></p> <p>Navigate to Suricata &gt; LAN Interface settings</p> <p>In the Alert and Block Settings, select Block Offenders and Inline mode for IPS mode.</p> <p></p> <p>Navigate to SID Mgmt and edit LAN-Drops. Copy and paste the following list:</p> <pre><code>emerging-3coresec\nemerging-ciarmy\nemerging-compromised\nemerging-current_events\nemerging-drop\nemerging-dshield\nemerging-dns\nemerging-botcc\nemerging-malware\nemerging-tor\nemerging-trojan\nemerging-scan\nfeodotracker\nsslblacklist_tls_cert\n</code></pre> <p></p> <p>For Interface SID Management List Assignments, select Rebuild and select LAN-Drops for Drop SID LIst. Click Save.</p> <p></p> <p>Navigate to Interface tab and restart Suricata</p> <p></p> <p>On Windows host, browse through <code>http://malware.wicar.org/</code>: This site hosts files and URLs that trigger IPS/IDS signatures without actually hosting real malware.</p> <p>Verify that the alerts have been generated.</p> <p></p> <p>Part of our LAN-Drops includes a rule that will drop a traffic when a user visits <code>.cc</code> TLD</p> <p>From Windows host, run <code>nslookup something.cc</code> </p> <pre><code>PS C:\\Users\\Administrator\\Downloads&gt; nslookup something.cc\nServer:  UnKnown\nAddress:  ::1\n\nDNS request timed out.\n    timeout was 2 seconds.\nDNS request timed out.\n    timeout was 2 seconds.\n Request to UnKnown timed-out\n</code></pre> <p>Alerts log shows that DNS query to .cc TLD has been dropped</p> <p></p>"},{"location":"suricata/suricata.html#references","title":"References","text":"<ul> <li>https://docs.suricata.io/en/latest/index.html</li> <li>https://documentation.wazuh.com/current/proof-of-concept-guide/integrate-network-ids-suricata.html</li> <li>https://youtu.be/UXKbh0jPPpg?si=9_Ry4dN7_X7HHpvH</li> <li>https://github.com/nn-df/suricata-installation-ips-mode</li> <li>https://tools.emergingthreats.net/docs/ETPro Rule Categories.pdf</li> </ul>"},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html","title":"Understanding IDS/IPS","text":""},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html#introduction","title":"Introduction","text":"<p>In today's digital world, cybersecurity is more important than ever. Protecting our organisation's information and systems from cyber threats is essential to maintaining our operations, reputation, and the trust of our clients and partners. To strengthen our defenses, we are implementing Intrusion Detection Systems (IDS) and Intrusion Prevention Systems (IPS).</p> <p>This document explains what IDS and IPS are, why they're important, and how they affect different members of our organisation.</p>"},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html#what-are-ids-and-ips","title":"What are IDS and IPS?","text":"<p>Intrusion Detection Systems (IDS) and Intrusion Prevention Systems (IPS) are cybersecurity technologies designed to monitor network traffic for signs of malicious activity.</p> <ul> <li>IDS: Monitors network traffic and alerts security teams when suspicious activities are detected.</li> <li>IPS: Not only detects suspicious activities but also takes action to prevent potential threats from causing harm.</li> </ul>"},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html#why-idsips-matter-to-us","title":"Why IDS/IPS Matter to Us","text":"<ol> <li>Proactive Threat Detection<ul> <li>Early Warning: IDS alerts us to potential security threats before they become serious issues.</li> <li>Immediate Action: IPS can block malicious traffic in real-time, preventing attacks.</li> </ul> </li> <li>Real-Time Monitoring<ul> <li>Continuous Surveillance: Keeps an eye on network activity around the clock.</li> <li>Swift Response: Enables quick action to mitigate threats as they arise.</li> </ul> </li> <li>Regulatory Compliance<ul> <li>Meeting Standards: Helps us comply with cybersecurity regulations and industry best practices.</li> <li>Audit Trails: Provides detailed logs required for compliance reporting.</li> </ul> </li> <li>Risk Mitigation<ul> <li>Reducing Breaches: Helps prevent security incidents that could harm our operations and reputation.</li> <li>Strategic Planning: Informs decisions on improving our cybersecurity measures.</li> </ul> </li> </ol>"},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html#benefits-of-implementing-idsips","title":"Benefits of Implementing IDS/IPS","text":"<ul> <li>Enhanced Security: Strengthens our defenses against cyber attacks.</li> <li>Operational Efficiency: Automates threat detection and prevention, reducing manual efforts.</li> <li>Stakeholder Confidence: Shows our commitment to security, building trust with clients and partners.</li> <li>Cost Savings: Prevents costly security breaches and downtime.</li> </ul>"},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html#how-idsips-work","title":"How IDS/IPS Work","text":"<ol> <li>Traffic Monitoring: Continuously scans network traffic for unusual patterns or known threat signatures.</li> <li>Analysis: Uses rules and algorithms to detect potential threats based on predefined criteria.</li> <li>Alerting (IDS): Sends notifications to the security team when suspicious activity is detected.</li> <li>Prevention (IPS): Automatically blocks or quarantines malicious traffic to prevent damage.</li> </ol>"},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html#our-idsips-solutions","title":"Our IDS/IPS Solutions","text":"<ul> <li>Snort<ul> <li>Open-Source IDS/IPS: Widely used for real-time traffic analysis and packet logging.</li> <li>Customisation: Allows us to tailor rules to our specific network environment.</li> <li>Community Support: Extensive community and a large repository of rules for threat detection.</li> </ul> </li> <li>Suricata<ul> <li>Open-Source IDS/IPS: Provides robust intrusion detection and prevention capabilities.</li> <li>Protocol Detection: Automatically detects and parses various protocols such as HTTP for deeper inspection.</li> <li>Integration Capabilities: Easily integrates with other security tools and platforms, enhancing overall security infrastructure.</li> </ul> </li> </ul>"},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html#support-available","title":"Support Available","text":"<ul> <li>Resources: We will provide easy-to-understand materials to help you implement IDS/IPS solutions and recognize potential threats.</li> <li>Assistance: Our cybersecurity team is here to support you with any concerns or issues.</li> </ul>"},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html#summary","title":"Summary","text":"<p>IDS and IPS are crucial cybersecurity tools that help detect and prevent threats, ensuring the safety of our organisation's assets and reputation. Implementing these systems enhances our security posture, aids in compliance, and demonstrates our commitment to protecting our network. Your participation is essential for the successful integration and management of these systems.</p>"},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html#frequently-asked-questions","title":"Frequently Asked Questions","text":""},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html#1-will-implementing-idsips-affect-my-daily-work","title":"1. Will implementing IDS/IPS affect my daily work?","text":"<ul> <li>There should be minimal impact on your daily activities. IDS/IPS operate in the background to enhance network security.</li> </ul>"},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html#2-how-do-ids-and-ips-differ","title":"2. How do IDS and IPS differ?","text":"<ul> <li>IDS alerts the security team about potential threats but doesn't take action to block them. IPS not only detects threats but also takes steps to prevent them from causing harm.</li> </ul>"},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html#3-how-do-idsips-help-with-compliance","title":"3. How do IDS/IPS help with compliance?","text":"<ul> <li>They provide detailed logs and monitoring required for regulatory compliance, making it easier to meet industry standards and pass audits.</li> </ul>"},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html#4-can-idsips-be-used-in-an-air-gapped-environment","title":"4. Can IDS/IPS be used in an air-gapped environment?","text":"<ul> <li>Yes, IDS/IPS solutions like Snort and Suricata can be deployed in air-gapped networks. We will provide documentation on how to implement these tools without internet connectivity, ensuring your network remains secure and isolated.</li> </ul>"},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html#5-what-kind-of-training-will-be-provided","title":"5. What kind of training will be provided?","text":"<ul> <li>Introductory Training Sessions: We will offer basic training to help you get started with IDS/IPS tools and understand how to use them effectively.</li> <li>Free Training Resources: Access to online tutorials, guides, and documentation will be provided for further learning at your own pace.</li> </ul>"},{"location":"understanding-IDS-IPS/understanding-IDS-IPS.html#6-who-do-i-contact-if-i-have-questions-or-notice-a-security-issue","title":"6. Who do I contact if I have questions or notice a security issue?","text":"<ul> <li>Please reach out to the cybersecurity team through the internal support channels for any assistance or to report concerns.</li> </ul>"},{"location":"understanding-SIEM/understanding-SIEM.html","title":"Understanding SIEM","text":""},{"location":"understanding-SIEM/understanding-SIEM.html#introduction","title":"Introduction","text":"<p>In today's digital landscape, cybersecurity is more important than ever. Protecting our organisation's information and systems from cyber threats is crucial to maintaining our operations, reputation, and trust with clients and partners. To enhance our defences, we are implementing Security Information and Event Management (SIEM) solutions, focusing on Splunk and Wazuh. This document explains what SIEM is, why it's important, and how it affects different members of our organisation.</p>"},{"location":"understanding-SIEM/understanding-SIEM.html#what-is-siem","title":"What is SIEM?","text":"<p>Security Information and Event Management (SIEM) is a technology that provides real-time analysis of security alerts generated by applications and network hardware. SIEM systems collect and analyse security events from various sources within the IT infrastructure to detect anomalies, threats, and compliance issues, giving a centralised view of the organisation's security posture.</p>"},{"location":"understanding-SIEM/understanding-SIEM.html#why-siem-matters-to-us","title":"Why SIEM Matters to Us","text":"<ol> <li>Proactive Threat Detection<ul> <li>Early Identification: SIEM enables us to detect potential security incidents before they escalate.</li> <li>Real-Time Monitoring: Continuous surveillance helps us respond swiftly to threats.</li> </ul> </li> <li>Regulatory Compliance<ul> <li>Meeting Standards: SIEM assists in complying with military cybersecurity standards and other regulations.</li> <li>Audit Trails: Maintains comprehensive logs necessary for audits and compliance reporting.</li> </ul> </li> <li>Risk Mitigation<ul> <li>Reducing Breaches: Consolidated security events help prevent breaches that could harm operations and reputation.</li> <li>Strategic Decision-Making: Provides insights to inform cybersecurity investments and policies.</li> </ul> </li> </ol>"},{"location":"understanding-SIEM/understanding-SIEM.html#benefits-of-implementing-siem","title":"Benefits of Implementing SIEM","text":"<ul> <li>Enhanced Security: Strengthens defenses against sophisticated cyber threats.</li> <li>Operational Efficiency: Automates security monitoring, reducing manual efforts.</li> <li>Stakeholder Confidence: Demonstrates a commitment to security, bolstering trust.</li> <li>Cost Savings: Prevents costly breaches and downtime, safeguarding financial resources.</li> </ul>"},{"location":"understanding-SIEM/understanding-SIEM.html#how-siem-works","title":"How SIEM Works","text":"<ol> <li>Data Collection: Aggregates logs and events from servers, network devices, applications, and security tools.</li> <li>Normalisation: Converts data into a consistent format for easier analysis.</li> <li>Correlation: Uses rules and algorithms to link related events and identify patterns indicative of security incidents.</li> <li>Alerting and Reporting: Generates real-time alerts and comprehensive reports for security teams.</li> </ol>"},{"location":"understanding-SIEM/understanding-SIEM.html#our-siem-solutions-splunk-and-wazuh","title":"Our SIEM Solutions: Splunk and Wazuh","text":"<ul> <li>Splunk</li> <li>Data Analytics Platform: Excels at indexing, searching, and analyzing large volumes of machine-generated data.</li> <li>Real-Time Monitoring: Provides live dashboards and visualizations for immediate insight.</li> <li>Extensibility: Supports a wide range of data inputs and third-party integrations.</li> <li>Wazuh</li> <li>Open-Source SIEM and XDR: SIEM and XDR (Extended Detection and Response) offers unified security monitoring and endpoint detection capabilities.</li> <li>Agent-Based Architecture: Deploys agents on endpoints for detailed data collection and active response.</li> <li>Compliance Management: Includes built-in checks for regulatory standards.</li> </ul>"},{"location":"understanding-SIEM/understanding-SIEM.html#support-available","title":"Support Available","text":"<ul> <li>Resources: We will provide easy-to-understand materials to help you implement SIEM solutions and recognize potential threats.</li> <li>Assistance: Our cybersecurity team is here to support you with any concerns or issues.</li> </ul>"},{"location":"understanding-SIEM/understanding-SIEM.html#summary","title":"Summary","text":"<p>SIEM is a cybersecurity tool that enhances security, ensures compliance, and protects our organisation's assets and reputation. SIEM systems like Splunk and Wazuh provide powerful capabilities for detecting and responding to security threats. Your technical expertise is crucial for the successful integration and ongoing management of these systems.</p>"},{"location":"understanding-SIEM/understanding-SIEM.html#frequently-asked-questions","title":"Frequently Asked Questions","text":""},{"location":"understanding-SIEM/understanding-SIEM.html#1-will-the-siem-implementation-affect-my-daily-work","title":"1. Will the SIEM implementation affect my daily work?","text":"<p>No significant changes are expected in your daily activities. SIEM operates in the background to enhance security.</p>"},{"location":"understanding-SIEM/understanding-SIEM.html#2-how-does-siem-help-with-compliance","title":"2. How does SIEM help with compliance?","text":"<p>SIEM systems maintain detailed logs and audit trails required for regulatory compliance, making it easier to meet and demonstrate adherence to standards.</p>"},{"location":"understanding-SIEM/understanding-SIEM.html#3-is-it-possible-to-install-siem-solutions-in-an-air-gapped-environment","title":"3. Is it possible to install SIEM solutions in an air-gapped environment?","text":"<p>Yes, SIEM solutions like Splunk and Wazuh can be installed in air-gapped environments. We will provide documentation that explains how to implement these tools without internet connectivity, ensuring your network remains secure and isolated.</p>"},{"location":"understanding-SIEM/understanding-SIEM.html#4-what-kind-of-training-will-be-provided","title":"4. What kind of training will be provided?","text":"<ul> <li>Introductory Training Sessions: We will offer beginner-level training to help you get started with the SIEM tools and understand the basics of configuring and using them.</li> <li>Free Training Resources: For more in-depth learning, we will provide access to free online training materials, tutorials, and documentation that you can explore at your own pace.</li> </ul>"},{"location":"understanding-SIEM/understanding-SIEM.html#5-who-do-i-contact-if-i-have-questions-or-notice-a-security-issue","title":"5. Who do I contact if I have questions or notice a security issue?","text":"<p>Reach out to the cybersecurity team via the internal support channels for assistance or to report concerns.</p>"},{"location":"wazuh/wazuh.html","title":"Wazuh","text":"<p>Wazuh\u00a0is the open source security platform that unifies XDR and SIEM protection for endpoints and cloud workloads. It is designed to help organisations detect threats, monitor integrity, and ensure compliance across their infrastructure, including physical, virtual, containerised, and cloud environments.</p>"},{"location":"wazuh/wazuh.html#lab-setup-for-proof-of-concept","title":"Lab Setup for Proof of Concept","text":"<p>In this proof of concept, attack emulation was conducted on the FortiGate VM, Windows and Ubuntu hosts in a safe and controlled setting. </p> <p>Note: Do not attempt to replicate the attack emulation demonstrated here unless you are properly trained and it is safe to do so. Unauthorised attack emulation can lead to legal consequences and unintended damage to systems. Always ensure that such activities are conducted by qualified professionals in a secure, isolated environment.</p> Host OS Role IP Address Fortigate Fortios 7.6.0 Firewall/Router 192.168.1.111 (WAN) / 10.0.0.1 (LAN) WazuhServer Centos Stream 9 Wazuh server 10.0.0.20 WS2019 Windows Server 2019 Wazuh agent 10.0.0.24 SyslogUbuntu Ubuntu 22.04 LTS Wazuh agent, rsyslog server 10.0.0.26 Kali Kali Linux 2024.2 Attacker machine 192.168.1.161, 10.0.0.29 <p></p>"},{"location":"wazuh/wazuh.html#wazuh_1","title":"Wazuh","text":""},{"location":"wazuh/wazuh.html#install-wazuh-server-offline","title":"Install Wazuh Server offline","text":"<p>You can install Wazuh even when there is no connection to the Internet. Installing the solution offline involves downloading the Wazuh central components to later install them on a system with no Internet connection. The Wazuh server, the Wazuh indexer, and the Wazuh dashboard can be installed and configured on the same host in an all-in-one deployment, or each component can be installed on a separate host as a distributed deployment, depending on your environment needs. Check requirements for Wazuh Server.</p> <p>Note: You need root user privileges to run all the commands described below.</p>"},{"location":"wazuh/wazuh.html#configure-firewall-rule","title":"Configure Firewall rule","text":"<p>Configure Firewall rule to allow access on required ports</p> <p>CentOS:</p> <pre><code>firewall-cmd --zone=public --add-port=9200/tcp --permanent #Wazuh-indexer\nfirewall-cmd --zone=public --add-port=55000/tcp --permanent #enrollment service\nfirewall-cmd --zone=public --add-port=1514/tcp --permanent #agent communication\nfirewall-cmd --zone=public --add-port=1515/tcp --permanent #enrollment service\n\n#Apply changes\nfirewall-cmd --reload\n\n#Check applied\nfirewall-cmd --list-all\n</code></pre> <p>Ubuntu:</p> <pre><code>ufw allow 9200/tcp\nufw allow 55000/tcp\nufw allow 1514/tcp\nufw allow 1515/tcp\n</code></pre>"},{"location":"wazuh/wazuh.html#download-the-packages-and-configuration-files","title":"Download the packages and configuration files","text":"<p>Run the following commands from any Linux system with Internet connection. This action executes a script that downloads all required files for the offline installation on x86_64 architectures. Select the package format to download.</p> <p>For rpm:</p> <pre><code>curl -sO https://packages.wazuh.com/4.9/wazuh-install.sh\nchmod 744 wazuh-install.sh\n./wazuh-install.sh -dw rpm\n</code></pre> <p>For deb:</p> <pre><code>curl -sO https://packages.wazuh.com/4.9/wazuh-install.sh\nchmod 744 wazuh-install.sh\n./wazuh-install.sh -dw deb\n</code></pre> <p>Download the certificates configuration file.</p> <pre><code>curl -sO https://packages.wazuh.com/4.9/config.yml\n</code></pre> <p>Edit\u00a0<code>config.yml</code>\u00a0to prepare the certificates creation. As we are performing an all-in-one deployment, replace\u00a0<code>\"&lt;indexer-node-ip&gt;\"</code>,\u00a0<code>\"&lt;wazuh-manager-ip&gt;\"</code>, and\u00a0<code>\"&lt;dashboard-node-ip&gt;\"</code>\u00a0with\u00a0<code>127.0.0.1</code> or your preferred IP address.</p> <pre><code>nodes:\n  # Wazuh indexer nodes\n  indexer:\n    - name: node-1\n      ip: 10.0.0.20\n    #- name: node-2\n    #  ip: \"&lt;indexer-node-ip&gt;\"\n    #- name: node-3\n    #  ip: \"&lt;indexer-node-ip&gt;\"\n\n  # Wazuh server nodes\n  # If there is more than one Wazuh server\n  # node, each one must have a node_type\n  server:\n    - name: wazuh-1\n      ip: 10.0.0.20\n    #  node_type: master\n    #- name: wazuh-2\n    #  ip: \"&lt;wazuh-manager-ip&gt;\"\n    #  node_type: worker\n    #- name: wazuh-3\n    #  ip: \"&lt;wazuh-manager-ip&gt;\"\n    #  node_type: worker\n\n  # Wazuh dashboard nodes\n  dashboard:\n    - name: dashboard\n      ip: 10.0.0.20\n</code></pre> <p>Run the ./wazuh-install.sh -g to create the certificates. For a multi-node cluster, these certificates need to be later deployed to all Wazuh instances in your cluster.</p> <pre><code>./wazuh-install.sh -g\n</code></pre> <p>Copy or move the following files to a directory on the host(s) from where the offline installation will be carried out. You can use\u00a0<code>scp</code>\u00a0for this.</p> <ul> <li><code>wazuh-install.sh</code></li> <li><code>wazuh-offline.tar.gz</code></li> <li><code>wazuh-install-files.tar</code></li> </ul>"},{"location":"wazuh/wazuh.html#install-wazuh-components-from-local-files","title":"Install Wazuh components from local files","text":"<p>Note: Internet access was disabled at this point for offline installation.</p> <p>In the working directory where you placed\u00a0<code>wazuh-offline.tar.gz</code>\u00a0and\u00a0<code>wazuh-install-files.tar</code>, execute the following command to decompress the installation files:</p> <pre><code>tar xf wazuh-offline.tar.gz\ntar xf wazuh-install-files.tar\n</code></pre>"},{"location":"wazuh/wazuh.html#install-the-wazuh-indexer","title":"Install the Wazuh indexer","text":"<p>Run the following commands to install the Wazuh indexer.</p> <p>For rpm:</p> <pre><code>rpm --import ./wazuh-offline/wazuh-files/GPG-KEY-WAZUH\nrpm -ivh ./wazuh-offline/wazuh-packages/wazuh-indexer*.rpm\n</code></pre> <p>For deb:</p> <pre><code>dpkg -i ./wazuh-offline/wazuh-packages/wazuh-indexer*.deb\n</code></pre> <p>Run the following commands replacing\u00a0<code>&lt;indexer-node-name&gt;</code>\u00a0with the name of the Wazuh indexer node you are configuring as defined in\u00a0<code>config.yml</code>. For example,\u00a0<code>node-1</code>. This deploys the SSL certificates to encrypt communications between the Wazuh central components.</p> <p>Note: On CentOS, if you encounter the error chmod: cannot access '/etc/wazuh-indexer/certs/*': No such file or directort, cd /etc/wazuh-indexer/certs/ and run chmod 400 * as a root user</p> <pre><code>NODE_NAME=node-1\n</code></pre> <pre><code>mkdir /etc/wazuh-indexer/certs\nmv -n wazuh-install-files/$NODE_NAME.pem /etc/wazuh-indexer/certs/indexer.pem\nmv -n wazuh-install-files/$NODE_NAME-key.pem /etc/wazuh-indexer/certs/indexer-key.pem\nmv wazuh-install-files/admin-key.pem /etc/wazuh-indexer/certs/\nmv wazuh-install-files/admin.pem /etc/wazuh-indexer/certs/\ncp wazuh-install-files/root-ca.pem /etc/wazuh-indexer/certs/\nchmod 500 /etc/wazuh-indexer/certs\nchmod 400 /etc/wazuh-indexer/certs/*\nchown -R wazuh-indexer:wazuh-indexer /etc/wazuh-indexer/certs\n</code></pre> <p>Here you move the node certificate and key files, such as\u00a0node-1.pem\u00a0and\u00a0node-1-key.pem, to their corresponding\u00a0certs\u00a0folder. They are specific to the node and are not required on the other nodes. However, note that the\u00a0root-ca.pem\u00a0certificate isn't moved but copied to the\u00a0certs\u00a0folder. This way, you can continue deploying it to other component folders in the next steps.</p> <p>Edit\u00a0<code>/etc/wazuh-indexer/opensearch.yml</code>\u00a0and replace the following values:</p> <ol> <li> <p><code>network.host</code>: Sets the address of this node for both HTTP and transport traffic. The node will bind to this address and will also use it as its publish address. Accepts an IP address or a hostname.</p> <p>Use the same node address set in\u00a0<code>config.yml</code>\u00a0to create the SSL certificates.</p> </li> <li> <p><code>node.name</code>: Name of the Wazuh indexer node as defined in the\u00a0<code>config.yml</code>\u00a0file. For example,\u00a0<code>node-1</code>.</p> </li> <li><code>cluster.initial_master_nodes</code>: List of the names of the master-eligible nodes. These names are defined in the\u00a0<code>config.yml</code>\u00a0file. </li> </ol> <pre><code>network.host: \"10.0.0.20\"\nnode.name: \"node-1\"\ncluster.initial_master_nodes:\n- \"node-1\"\n#- \"node-2\"\n#- \"node-3\"\n</code></pre> <p>Enable and start the Wazuh indexer service. Verify Wazuh indexer is active and running (exit with <code>q</code>)</p> <pre><code>systemctl daemon-reload\nsystemctl enable wazuh-indexer\nsystemctl start wazuh-indexer\nsys\n</code></pre> <p>When all Wazuh indexer nodes are running, run the Wazuh indexer\u00a0<code>indexer-security-init.sh</code>\u00a0script on\u00a0any Wazuh indexer node\u00a0to load the new certificates information and start the cluster.</p> <pre><code>/usr/share/wazuh-indexer/bin/indexer-security-init.sh\n</code></pre> <p>Run the following command to check that the installation is successful. </p> <pre><code>curl -XGET https://10.0.0.20:9200 -u admin:admin -k\n</code></pre> <pre><code>#Example response\n{\n  \"name\" : \"node-1\",\n  \"cluster_name\" : \"wazuh-cluster\",\n  \"cluster_uuid\" : \"6hQpHd5cSzCLrhFo0T-Crg\",\n  \"version\" : {\n    \"number\" : \"7.10.2\",\n    \"build_type\" : \"rpm\",\n    \"build_hash\" : \"eee49cb340edc6c4d489bcd9324dda571fc8dc03\",\n    \"build_date\" : \"2023-09-20T23:54:29.889267151Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"9.7.0\",\n    \"minimum_wire_compatibility_version\" : \"7.10.0\",\n    \"minimum_index_compatibility_version\" : \"7.0.0\"\n  },\n  \"tagline\" : \"The OpenSearch Project: https://opensearch.org/\"\n}\n</code></pre>"},{"location":"wazuh/wazuh.html#installing-the-wazuh-server","title":"Installing the Wazuh server","text":""},{"location":"wazuh/wazuh.html#installing-the-wazuh-manager","title":"Installing the Wazuh manager","text":"<p>Run the following commands to import the Wazuh key and install the Wazuh manager.</p> <p>For rpm:</p> <pre><code>rpm --import ./wazuh-offline/wazuh-files/GPG-KEY-WAZUH\nrpm -ivh ./wazuh-offline/wazuh-packages/wazuh-manager*.rpm\n</code></pre> <p>For deb:</p> <pre><code>dpkg -i ./wazuh-offline/wazuh-packages/wazuh-manager*.deb\n</code></pre> <p>Save the Wazuh indexer username and password into the Wazuh manager keystore using the wazuh-keystore tool. The default offline-installation credentials are\u00a0<code>admin</code>:<code>admin</code></p> <pre><code>/var/ossec/bin/wazuh-keystore -f indexer -k username -v admin\n/var/ossec/bin/wazuh-keystore -f indexer -k password -v admin\n</code></pre> <p>Enable and start the Wazuh manager service. Verify Wazuh manager is active and running (exit with <code>q</code>)</p> <pre><code>systemctl daemon-reload\nsystemctl enable wazuh-manager\nsystemctl start wazuh-manager\nsystemctl status wazuh-manager\n</code></pre>"},{"location":"wazuh/wazuh.html#installing-filebeat","title":"Installing Filebeat","text":"<p>Filebeat must be installed and configured on the same server as the Wazuh manager.</p> <p>Run the following command to install Filebeat.</p> <p>For rpm:</p> <pre><code>rpm -ivh ./wazuh-offline/wazuh-packages/filebeat*.rpm\n</code></pre> <p>For deb:</p> <pre><code>dpkg -i ./wazuh-offline/wazuh-packages/filebeat*.deb\n</code></pre> <p>Move a copy of the configuration files to the appropriate location. Ensure to type \u201cyes\u201d at the prompt to overwrite\u00a0<code>/etc/filebeat/filebeat.yml</code>.</p> <p>Note for CentOS, remove <code>&amp;&amp;\\</code></p> <pre><code>cp ./wazuh-offline/wazuh-files/filebeat.yml /etc/filebeat/ &amp;&amp;\\\ncp ./wazuh-offline/wazuh-files/wazuh-template.json /etc/filebeat/ &amp;&amp;\\\nchmod go+r /etc/filebeat/wazuh-template.json\n</code></pre> <p>Edit the\u00a0<code>/etc/filebeat/filebeat.yml</code>\u00a0configuration file and replace the following value: <code>hosts</code>: The list of Wazuh indexer nodes to connect to. You can use either IP addresses or hostnames. By default, the host is set to localhost\u00a0<code>hosts:\u00a0[\"127.0.0.1:9200\"]</code>. Replace it with your Wazuh indexer address accordingly.</p> <pre><code># Wazuh - Filebeat configuration file\n output.elasticsearch:\n **hosts: [\"10.0.0.20:9200\"]**\n protocol: https\n username: ${username}\n password: ${password}\n</code></pre> <p>Create a Filebeat keystore to securely store authentication credentials.</p> <pre><code>filebeat keystore create\n</code></pre> <p>Add the username and password\u00a0<code>admin</code>:<code>admin</code>\u00a0to the secrets keystore.</p> <pre><code>echo admin | filebeat keystore add username --stdin --force\necho admin | filebeat keystore add password --stdin --force\n</code></pre> <p>Install the Wazuh module for Filebeat.</p> <pre><code>tar -xzf ./wazuh-offline/wazuh-files/wazuh-filebeat-0.4.tar.gz -C /usr/share/filebeat/module\n</code></pre> <p>Replace\u00a0<code>&lt;SERVER_NODE_NAME&gt;</code>\u00a0with your Wazuh server node certificate name, the same used in\u00a0<code>config.yml</code>\u00a0when creating the certificates. For example,\u00a0<code>wazuh-1</code>. Then, move the certificates to their corresponding location.</p> <p>Note: On CentOS, if you encounter the error chmod: cannot access '/etc/filebeat/certs/*': No such file or directort, cd /etc/filebeat/certs/ and run chmod 400 * as a root user</p> <pre><code>NODE_NAME=wazuh-1\n</code></pre> <pre><code>mkdir /etc/filebeat/certs\nmv -n wazuh-install-files/$NODE_NAME.pem /etc/filebeat/certs/filebeat.pem\nmv -n wazuh-install-files/$NODE_NAME-key.pem /etc/filebeat/certs/filebeat-key.pem\ncp wazuh-install-files/root-ca.pem /etc/filebeat/certs/\nchmod 500 /etc/filebeat/certs\nchmod 400 /etc/filebeat/certs/*\nchown -R root:root /etc/filebeat/certs\n</code></pre> <p>Enable and start the Filebeat service. Verify Filebeat is active and running (exit with <code>q</code>)</p> <pre><code>systemctl daemon-reload\nsystemctl enable filebeat\nsystemctl start filebeat\nsystemctl status filebeat\n</code></pre> <p>Run the following command to make sure Filebeat is successfully installed.</p> <pre><code>filebeat test output\n</code></pre> <pre><code>#Example output\nelasticsearch: https://10.0.0.20:9200...\n  parse url... OK\n  connection...\n    parse host... OK\n    dns lookup... OK\n    addresses: 10.0.0.20\n    dial up... OK\n  TLS...\n    security: server's certificate chain verification is enabled\n    handshake... OK\n    TLS version: TLSv1.3\n    dial up... OK\n  talk to server... OK\n  version: 7.10.2\n</code></pre> <p>Wazuh server node is now successfully installed.</p>"},{"location":"wazuh/wazuh.html#install-the-wazuh-dashboard","title":"Install the Wazuh dashboard","text":"<p>Run the following commands to install the Wazuh dashboard.</p> <p>For rpm:</p> <pre><code>rpm --import ./wazuh-offline/wazuh-files/GPG-KEY-WAZUH\nrpm -ivh ./wazuh-offline/wazuh-packages/wazuh-dashboard*.rpm\n</code></pre> <p>For deb:</p> <pre><code>dpkg -i ./wazuh-offline/wazuh-packages/wazuh-dashboard*.deb\n</code></pre> <p>Replace\u00a0<code>&lt;DASHBOARD_NODE_NAME&gt;</code>\u00a0with your Wazuh dashboard node name, the same used in\u00a0<code>config.yml</code>\u00a0to create the certificates. For example,\u00a0<code>dashboard</code>. Then, move the certificates to their corresponding location.</p> <p>Note: On CentOS, if you encounter the error chmod: cannot access '/etc/wazuh-dashboard/certs/*': No such file or directort, cd /etc/wazuh-dashboard/certs/ and run chmod 400 * as a root user</p> <pre><code>NODE_NAME=dashboard\n</code></pre> <pre><code>mkdir /etc/wazuh-dashboard/certs\nmv -n wazuh-install-files/$NODE_NAME.pem /etc/wazuh-dashboard/certs/dashboard.pem\nmv -n wazuh-install-files/$NODE_NAME-key.pem /etc/wazuh-dashboard/certs/dashboard-key.pem\ncp wazuh-install-files/root-ca.pem /etc/wazuh-dashboard/certs/\nchmod 500 /etc/wazuh-dashboard/certs\nchmod 400 /etc/wazuh-dashboard/certs/*\nchown -R wazuh-dashboard:wazuh-dashboard /etc/wazuh-dashboard/certs\n</code></pre> <p>Edit the\u00a0<code>/etc/wazuh-dashboard/opensearch_dashboards.yml</code>\u00a0file and replace the following values:</p> <ol> <li><code>server.host</code>: This setting specifies the host of the back end server. To allow remote users to connect, set the value to the IP address or DNS name of the Wazuh dashboard. The value\u00a0<code>0.0.0.0</code>\u00a0will accept all the available IP addresses of the host.</li> <li><code>opensearch.hosts</code>: The URLs of the Wazuh indexer instances to use for all your queries. The Wazuh dashboard can be configured to connect to multiple Wazuh indexer nodes in the same cluster. The addresses of the nodes can be separated by commas. </li> </ol> <pre><code>server.host: 10.0.0.20\nserver.port: 443\nopensearch.hosts: https://10.0.0.20:9200\nopensearch.ssl.verificationMode: certificate\n</code></pre> <p>Enable and start the Wazuh dashboard. Verify Wazuh dashboard is active and running (exit with <code>q</code>)</p> <pre><code>systemctl daemon-reload\nsystemctl enable wazuh-dashboard\nsystemctl start wazuh-dashboard\nsystemctl status wazuh-dashboard\n</code></pre> <p>Edit the file\u00a0<code>/usr/share/wazuh-dashboard/data/wazuh/config/wazuh.yml</code>\u00a0and replace the\u00a0<code>url</code>\u00a0value with the IP address or hostname of the Wazuh server master node.</p> <pre><code>hosts:\n  - default:\n      url: https://10.0.0.20\n      port: 55000\n      username: wazuh-wui\n      password: wazuh-wui\n      run_as: false\n</code></pre> <p>Access the web interface.</p> <ul> <li>URL:\u00a0https:// <li>Username: admin</li> <li>Password: admin</li> <p></p>"},{"location":"wazuh/wazuh.html#import-certificate-optional","title":"Import Certificate (optional)","text":"<p>Upon the first access to the Wazuh dashboard, the browser shows a warning message stating that the certificate was not issued by a trusted authority. An exception can be added in the advanced options of the web browser or, for increased security, the\u00a0<code>root-ca.pem</code>\u00a0file previously generated can be imported to the certificate manager of the browser. </p> <p>Copy /etc/wazuh-dashboard/certs/root-ca.pem to user\u2019s home directory</p> <p>Change ownership of user's home directory to the non-root user to enable read access to root-ca.pem</p> <pre><code>cp /etc/wazuh-dashboard/certs/root-ca.pem /home/siem/root-ca.pem\n#Example\nchown -R siem:siem /home/siem\n-r--------.  1 siem siem       1204 Aug 30 16:32 root-ca.pem\n</code></pre> <p>On Firefox, go to Settings, Privacy &amp; Security and Certificates</p> <p>Click View Certificates</p> <p></p> <p>Click Import, select root-ca.pem in user\u2019s home directory</p> <p>Select Trust this CA to identify website and email users</p> <p>Click OK</p> <p></p> <p>Delete root-ca.pem from user\u2019s home directory</p> <pre><code>sudo rm root-ca.pem\n</code></pre>"},{"location":"wazuh/wazuh.html#securing-wazuh-installation-optional","title":"Securing Wazuh installation (optional)","text":"<p>You have now installed and configured all the Wazuh central components. We recommend changing the default credentials to protect your infrastructure from possible attacks.</p> <p>Use the Wazuh passwords tool to change all the internal users passwords.</p> <pre><code>/usr/share/wazuh-indexer/plugins/opensearch-security/tools/wazuh-passwords-tool.sh --api --change-all --admin-user wazuh --admin-password wazuh\n\n#Example output\n30/08/2024 23:39:52 INFO: Updating the internal users.\n30/08/2024 23:40:05 INFO: A backup of the internal users has been saved in the /etc/wazuh-indexer/internalusers-backup folder.\n30/08/2024 23:40:51 INFO: The password for user admin is o98ak572UvBhYPf*ldKNFHIbI9.t0ujk\n30/08/2024 23:40:51 INFO: The password for user kibanaserver is GcmzTyUluY?pVq2QsRd3g3Ih4STHj7J6\n30/08/2024 23:40:51 INFO: The password for user kibanaro is U9KOXTQ?T4cojg3inXW6rBjc+l5*PB+p\n30/08/2024 23:40:51 INFO: The password for user logstash is lB6.1iiU1hlJ2XhfL0i0MKuFmbKiiBkV\n30/08/2024 23:40:51 INFO: The password for user readall is BA+9wz*49.KUUPAapEJ8OXon+nQJ9v8a\n30/08/2024 23:40:51 INFO: The password for user snapshotrestore is v?IivWKPCSNrY?V0bp*r25pH?KYd3PMg\n30/08/2024 23:40:51 WARNING: Wazuh indexer passwords changed. Remember to update the password in the Wazuh dashboard, Wazuh server, and Filebeat nodes if necessary, and restart the services.\n30/08/2024 23:40:53 INFO: The password for Wazuh API user wazuh is fpuT5X8qkj3g6Nc64*UZiX8mkeE9atld\n30/08/2024 23:40:54 INFO: The password for Wazuh API user wazuh-wui is c2TDtq34XHGeH?TMkLLE2?Mr6K+W5oKe\n30/08/2024 23:40:54 INFO: Updated wazuh-wui user password in wazuh dashboard. Remember to restart the service.\n</code></pre> <p>Save the new Wazuh indexer password into the Wazuh manager keystore</p> <p>Restart Wazuh manager service</p> <pre><code>/var/ossec/bin/wazuh-keystore -f indexer -k password -v o98ak572UvBhYPf*ldKNFHIbI9.t0ujk\nsystemctl start wazuh-manager\nsystemctl status wazuh-manager\n</code></pre> <p>Add the new password to the Filebeat secrets keystore</p> <p>Restart the Filebeat service</p> <pre><code>echo \"o98ak572UvBhYPf*ldKNFHIbI9.t0ujk\" | filebeat keystore add password --stdin --force\nsystemctl restart filebeat\nfilebeat test output\n</code></pre> <p>Verify that new password has been added to /usr/share/wazuh-dashboard/data/wazuh/config/wazuh.yml</p> <p>Restart the Wazuh dashboard</p> <pre><code>nano /usr/share/wazuh-dashboard/data/wazuh/config/wazuh.yml\nsystemctl restart wazuh-dashboard\nsystemctl status wazuh-dashboard\n</code></pre>"},{"location":"wazuh/wazuh.html#install-wazuh-agents-on-endpoints","title":"Install Wazuh agents on endpoints","text":""},{"location":"wazuh/wazuh.html#configure-firewall-on-windows-endpoints","title":"Configure Firewall on Windows endpoints","text":"<p>For Wazuh agent to communicate with the Wazuh manager services, the following ports needs to be allowed for outbound connection:</p> <ul> <li>1514/TCP for agent communication.</li> <li>1515/TCP for enrollment via automatic agent request.</li> <li>55000/TCP for enrollment via manager API.</li> </ul> <p>Open Windows Defender Firewall with Advanced Security.</p> <p>Right-click Outbound Rules and create new rule.</p> <p>Select Port.</p> <p></p> <p>Select TCP and Specific remote ports.</p> <p>Put 1514, 1515, 55000</p> <p>Click Next</p> <p></p> <p>Select Allow the connection</p> <p></p> <p>Select Domain, Private and Public</p> <p></p> <p>Name the New Outbound Rule as Wazuh outbound and click Finish</p> <p></p>"},{"location":"wazuh/wazuh.html#install-wazuh-agent-on-windows-endpoint","title":"Install Wazuh agent on Windows endpoint","text":"<p>The agent runs on the endpoint you want to monitor and communicates with the Wazuh server, sending data in near real-time through an encrypted and authenticated channel.</p> <p>Note To perform the installation, administrator privileges are required.</p> <p>To start the installation process, download the\u00a0Windows installer from https://packages.wazuh.com/4.x/windows/wazuh-agent-4.9.0-1.msi</p> <p>Open PowerShell as Administrator and change directory to where Windows installer is located.</p> <p>Run the following command</p> <pre><code>.\\wazuh-agent-4.9.0-1.msi /q WAZUH_MANAGER=\"10.0.0.20\"\n</code></pre> <p>The installation process is now complete, and the Wazuh agent is successfully installed and configured. You can start the Wazuh agent from the GUI or by running:</p> <pre><code>NET START Wazuh\n</code></pre> <p>Once started, the Wazuh agent will start the enrollment process and register with the manager.</p>"},{"location":"wazuh/wazuh.html#troubleshooting-windows-wazuh-agent","title":"Troubleshooting Windows Wazuh Agent","text":"<p>If Wazuh agent on Windows is unable to connect to Wazuh server, open Wazuh Agent Manager</p> <p>If Authentication key show as , click Manage then Restart <p>Click Save then Refresh</p> <p></p> <p>You should be able to see Authentication key. The Authentication key is used to encrypt the traffic from the agent to the Wazuh server.</p> <p>If issues still persist, refer to the log file located at <code>C:\\Program Files (x86)\\ossec-agent\\ossec.log</code></p> <p>Alternatively, refer to the Troubleshooting guide from https://documentation.wazuh.com/current/user-manual/agent/agent-enrollment/troubleshooting.html</p> <p></p> <p>On Wazuh web UI, go to Server management, then Endpoints Summary.</p> <p>Verify that the Windows agent is active.</p> <p></p>"},{"location":"wazuh/wazuh.html#sysmon-integration","title":"Sysmon Integration","text":"<p>Perform the steps below to install and configure Sysmon on the Windows endpoint.</p> <p>Download Sysmon from the\u00a0Microsoft Sysinternals page.</p> <p>Download the Sysmon configuration file:\u00a0sysmonconfig.xml. Note this is a modified version of sysmonconfig.xml recommended for integration with Wazuh. </p> <p>Install Sysmon with the downloaded configuration file using PowerShell as an administrator:</p> <pre><code>.\\sysmon64.exe -accepteula -i .\\sysmonconfig.xml\n</code></pre> <p>Open notepad as Administrator and open <code>ossec.conf</code>.</p> <p>Add the following configuration within the\u00a0<code>&lt;ossec_config&gt;</code>\u00a0block to the Wazuh agent\u00a0<code>C:\\Program\u00a0Files\u00a0(x86)\\ossec-agent\\ossec.conf</code>\u00a0file to specify the location to collect Sysmon logs:</p> <pre><code>&lt;localfile&gt;\n  &lt;location&gt;Microsoft-Windows-Sysmon/Operational&lt;/location&gt;\n  &lt;log_format&gt;eventchannel&lt;/log_format&gt;\n&lt;/localfile&gt;\n</code></pre> <p>Restart the Wazuh agent to apply the changes by running the following PowerShell command as an administrator:</p> <pre><code>Restart-Service -Name Wazuh\n</code></pre>"},{"location":"wazuh/wazuh.html#monitoring-network-devices-with-wazuh","title":"Monitoring network devices with Wazuh","text":""},{"location":"wazuh/wazuh.html#configure-fortigate-to-send-syslog","title":"Configure FortiGate to send syslog","text":"<p>Refer to the admin manual for specific details of configuration to send Reliable syslog using RFC 3195 format, a typical logging configuration will include the following features.</p> <pre><code>config log syslogd setting \n\nset status enable\nset server (syslog ip)\nset source-ip (fortigate ip)\n#Verify settings by running \"show\"\nend \n\nconfig log memory filter\nset forward-traffic enable\nset local-traffic enable\nset sniffer-traffic disable\nset anomaly enable\nset voip disable\nset multicast-traffic enable\n#Verify settings by running \"show full-configuration\"\nend\n\nconfig system global\nset cli-audit-log enable\n#Verify settings by running \"show\"\n#Make sure timezone is correct e.g. \"Pacific/Auckland\"\nend\n\nconfig log setting\nset neighbor-event enable\nend\n</code></pre>"},{"location":"wazuh/wazuh.html#configure-log-rotation","title":"Configure log rotation","text":"<p>By default, the <code>logrotate</code> service is configured to rotate logs in directories like <code>/var/log/</code></p> <p>For <code>rsyslog</code>, the rotation of its default log files (e.g., <code>/var/log/syslog</code>) is managed by the configuration file located at <code>/etc/logrotate.d/rsyslog</code>. Open the /etc/logrotate.d/rsyslog file in a text editor:</p> <pre><code>sudo nano /etc/logrotate.d/rsyslog\n</code></pre> <p>Add the path to your <code>fortigate.log</code> file under the existing log files. </p> <pre><code>/var/log/syslog\n**/var/log/fortigate.log**\n...\n{\n    rotate 4\n    weekly\n    missingok\n    notifempty\n    compress\n    delaycompress\n    sharedscripts\n    postrotate\n        /usr/lib/rsyslog/rsyslog-rotate\n    endscript\n}\n</code></pre> <p>Key Settings:</p> <ul> <li>rotate 4: Keeps 4 log files before deleting the oldest one.</li> <li>weekly: Rotates logs once per week.</li> <li>missingok: If the log file is missing, no error will be raised.</li> <li>notifempty: Only rotates logs if they are not empty.</li> <li>compress: Compresses old log files (e.g., to <code>.gz</code>).</li> <li>delaycompress: Compresses the logs on the second rotation cycle, meaning the most recent rotated file is not compressed immediately.</li> <li>sharedscripts: Runs the <code>postrotate</code> script only once, even if multiple logs are rotated.</li> <li>postrotate: After log rotation, it runs <code>/usr/lib/rsyslog/rsyslog-rotate</code> to ensure that <code>rsyslog</code> reopens its log files (so it doesn't keep writing to the old rotated file).</li> </ul>"},{"location":"wazuh/wazuh.html#configuring-syslog-on-the-wazuh-server-optional","title":"Configuring syslog on the Wazuh server (optional)","text":"<p>The Wazuh server can collect logs via syslog from endpoints such as firewalls, switches, routers, and other devices that don\u2019t support the installation of Wazuh agents. More details can be found here.</p> <p>If you have a central logging server like Syslog or Logstash in place, you can install the Wazuh agent on that server to streamline log collection. This setup enables seamless forwarding of logs from multiple sources to the Wazuh server, facilitating comprehensive analysis.</p>"},{"location":"wazuh/wazuh.html#configure-rsyslog-on-ubuntu-endpoint-recommended","title":"Configure Rsyslog on Ubuntu endpoint (recommended)","text":"<p>Rsyslog\u00a0is a preinstalled utility in Ubuntu 22.04 for receiving syslog events. The following section shows the steps for enabling Rsyslog on the Ubuntu endpoint and configuring the Wazuh agent to send the syslog log data to the Wazuh server.</p> <p>Edit /etc/rsyslog.conf. </p> <pre><code>nano /etc/rsyslog.conf\n</code></pre> <p>Uncomment udp/514. Add allowed sender and configure log file format.</p> <p>Save changes.</p> <pre><code>#provides UDP syslog reception\nmodule(load=\u201dimudp\u201d)\ninput(type=\u201dimudp\u201d port=\u201d514\")\n\n#Add allowed sender and configure log file format\n$AllowedSender UDP, 10.0.0.1/24\n$template remote-incoming-logs, \"/var/log/%HOSTNAME%.log\"\n*.* ?remote-incoming-logs\n</code></pre> <p>Permit udp/514 through the firewall.</p> <pre><code>sudo ufw allow 514/udp\n</code></pre> <p>Edit permissions on /var/log as Rsyslog may encounter permission error on relaunch. </p> <pre><code>sudo chmod 775 /var/log\n</code></pre> <p>Add any hosts you are receiving logs from to /etc/hosts</p> <pre><code>sudo nano /etc/hosts\n#Example\n10.0.0.1    Fortigate\n</code></pre> <p>Restart and check status of rsyslog.</p> <pre><code>sudo systemctl restart rsyslog\nsystemctl status rsyslog\n</code></pre> <p>Configure the syslog clients (network devices) to send logs to our syslog server</p> <p>Check /var/log to see that new log files are updating.</p> <pre><code>ls /var/log\ncat fortigate.log\n</code></pre> <p>Example output</p> <pre><code>2024-09-13T08:13:46.806479+12:00 fortigate date=2024-09-12 time=15:44:50 devname=\"Fortigate\" devid=\"FGVMEVUEOETC5XC8\" eventtime=1726112689938988753 tz=\"+1200\" logid=\"0001000014\" type=\"traffic\" subtype=\"local\" level=\"notice\" vd=\"root\" srcip=192.168.1.64 srcport=14712 srcintf=\"root\" srcintfrole=\"undefined\" dstip=38.21.192.5 dstport=443 dstintf=\"port1\" dstintfrole=\"wan\" srccountry=\"Reserved\" dstcountry=\"United States\" sessionid=44992 proto=6 action=\"close\" policyid=0 service=\"HTTPS\" trandisp=\"noop\" app=\"HTTPS\" duration=1 sentbyte=441 rcvdbyte=223 sentpkt=5 rcvdpkt=4\n</code></pre>"},{"location":"wazuh/wazuh.html#install-wazuh-agent-on-ubuntu-endpoint","title":"Install Wazuh agent on Ubuntu endpoint","text":"<p>Configure Firewall:</p> <pre><code>ufw allow 55000/tcp\nufw allow 1514/tcp\nufw allow 1515/tcp\n</code></pre> <p>Download Wazuh agent from the packages list.</p> <pre><code>wget https://packages.wazuh.com/4.x/apt/pool/main/w/wazuh-agent/wazuh-agent_4.9.0-1_amd64.deb\n</code></pre> <p>Transfer the Wazuh agent to Ubuntu endpoint.</p> <p>Install the package using <code>dpkg</code></p> <pre><code>dpkg -i wazuh-agent_4.9.0-1_amd64.deb\n</code></pre> <p>After installing, set the Wazuh manager's IP address by editing the configuration file:</p> <p>Look for the <code>&lt;server&gt;</code> section and update it with the Wazuh manager's IP address</p> <pre><code>nano /var/ossec/etc/ossec.conf\n</code></pre> <pre><code>&lt;ossec_config&gt;\n  &lt;client&gt;\n    &lt;server&gt;\n      **&lt;address&gt;10.0.0.20&lt;/address&gt;**\n      &lt;port&gt;1514&lt;/port&gt;\n      &lt;protocol&gt;tcp&lt;/protocol&gt;\n    &lt;/server&gt;\n    &lt;config-profile&gt;ubuntu, ubuntu22, ubuntu22.04&lt;/config-profile&gt;\n    &lt;notify_time&gt;10&lt;/notify_time&gt;\n    &lt;time-reconnect&gt;60&lt;/time-reconnect&gt;\n    &lt;auto_restart&gt;yes&lt;/auto_restart&gt;\n    &lt;crypto_method&gt;aes&lt;/crypto_method&gt;\n  &lt;/client&gt;\n</code></pre> <p>Start and enable the Wazuh agent. Verify Wazuh agent is active and running.</p> <pre><code>systemctl start wazuh-agent\nsystemctl enable wazuh-agent\nsystemctl status wazuh-agent\n</code></pre> <p>On Wazuh server UI, verify Ubuntu agent is active</p> <p></p>"},{"location":"wazuh/wazuh.html#configure-wazuh-to-monitor-fortigate-log","title":"Configure Wazuh to monitor Fortigate log","text":"<p>Add the following to /var/ossec/etc/ossec.conf file on Wazuh manager and agent</p> <pre><code>#On both Wazuh manager and agent\n&lt;localfile&gt;\n  &lt;log_format&gt;syslog&lt;/log_format&gt;\n  &lt;location&gt;/var/log/fortigate.log&lt;/location&gt;\n&lt;/localfile&gt;\n</code></pre> <p>Restart the manager and agent after adding this setting:</p> <pre><code>systemctl restart wazuh-manager\nsystemctl restart wazuh-agent\n</code></pre> <p>Verify fortigate logs are being ingested.</p> <p>Follow the steps below to enable archiving and set up wazuh-archives-* index.</p> <p>Search wazuh-alerts- and wazuh-archives- index.</p> <p>Add filter for location is /var/log/fortigate.log</p> <p></p> <p></p>"},{"location":"wazuh/wazuh.html#default-decoders-and-rules-for-fortigate","title":"Default decoders and rules for FortiGate","text":"<p>By default, Wazuh has pre-installed decoders and rules for FortiGate. </p> <p>This can be checked in Wazuh server UI under Rules and Decoders</p> <p></p> <p></p> <p>To test the default rule for FortiGate, SSH brute force attack was executed from Kali machine.</p> <p>The alert from the rule \u201cFortigate: Multiple high traffic events from same source\u201d was generated.</p> <p>This can be verified in Threat Intelligent, Events section on the web UI. </p> <p></p>"},{"location":"wazuh/wazuh.html#event-logging","title":"Event Logging","text":""},{"location":"wazuh/wazuh.html#log-compression-and-rotation","title":"Log compression and rotation","text":"<p>Log files can quickly accumulate and consume significant disk space in a system. To prevent this, the Wazuh manager compresses logs during its rotation process, helping to manage disk usage efficiently and maintain system performance. The Wazuh manager compresses log files daily or when they reach a certain threshold (file size, age, time, and more) and archives them. In the log rotation process, Wazuh creates a new log file with the original name to continuously write new events.</p> <p>Log files are compressed daily and digitally signed using MD5, SHA1, and SHA256 hashing algorithms. The compressed log files are stored in the\u00a0<code>/var/ossec/logs/</code>\u00a0directory</p>"},{"location":"wazuh/wazuh.html#archiving-event-logs","title":"Archiving event logs","text":"<p>Events are logs generated by applications, endpoints, and network devices. The Wazuh server stores all events it receives, whether or not they trigger a rule. These events are stored in the Wazuh archives located at\u00a0<code>/var/ossec/logs/archives/archives.log</code>\u00a0and\u00a0<code>/var/ossec/logs/archives/archives.json</code>. Security teams use archived logs to review historical data of security incidents, analyze trends, and generate reports to hunt threats.</p> <p>By default, the Wazuh archives are disabled because it stores logs indefinitely on the Wazuh server. When enabled, the Wazuh manager creates archived files to store and retain security data for compliance and forensic purposes.</p> <p>Note: The Wazuh archives retain logs collected from all monitored endpoints, therefore consuming significant storage resources on the Wazuh server over time. So, it is important to consider the impact on disk space and performance before enabling them.</p>"},{"location":"wazuh/wazuh.html#enabling-archiving","title":"Enabling archiving","text":"<p>Edit the Wazuh manager configuration file\u00a0<code>/var/ossec/etc/ossec.conf</code>\u00a0and set the value of the highlighted fields below to\u00a0<code>yes</code>:</p> <pre><code>&lt;ossec_config&gt;\n  &lt;global&gt;\n    &lt;jsonout_output&gt;yes&lt;/jsonout_output&gt;\n    &lt;alerts_log&gt;yes&lt;/alerts_log&gt;\n    &lt;logall&gt;yes&lt;/logall&gt;\n    &lt;logall_json&gt;yes&lt;/logall_json&gt;\n&lt;/ossec_config&gt;\n</code></pre> <p><code>&lt;logall&gt;</code>\u00a0enables or disables archiving of all log messages. When enabled, the Wazuh server stores the logs in a syslog format. The allowed values are\u00a0<code>yes</code>\u00a0and\u00a0<code>no</code>.<code>&lt;logall_json&gt;</code>\u00a0enables or disables logging of events. When enabled, the Wazuh server stores the events in a JSON format. The allowed values are\u00a0<code>yes</code>\u00a0and\u00a0<code>no</code>.</p> <p>Depending on the format you desire, you can set one or both values of the highlighted fields to\u00a0<code>yes</code>. However, only the\u00a0<code>&lt;logall_json&gt;yes&lt;/logall_json&gt;</code>\u00a0option allows you to create an index that can be used to visualize the events on the Wazuh dashboard.</p> <p>Restart the Wazuh manager to apply the configuration changes:</p> <pre><code>systemctl restart wazuh-manager\n</code></pre> <p>Depending on your chosen format, the file\u00a0<code>archives.log</code>,\u00a0<code>archives.json</code>, or both will be created in the\u00a0<code>/var/ossec/logs/archives/</code>\u00a0directory on the Wazuh server. Wazuh uses a default log rotation policy. It ensures that available disk space is conserved by rotating and compressing logs on a daily, monthly, and yearly basis.</p>"},{"location":"wazuh/wazuh.html#visualising-the-events-on-the-dashboard","title":"Visualising the events on the dashboard","text":"<p>Edit the Filebeat configuration file\u00a0<code>/etc/filebeat/filebeat.yml</code>\u00a0and change the value of\u00a0<code>archives:\u00a0enabled</code>\u00a0from\u00a0<code>false</code>\u00a0to\u00a0<code>true</code>:</p> <pre><code>archives:\n enabled: true\n</code></pre> <p>Restart Filebeat to apply the configuration changes:</p> <pre><code>systemctl restart filebeat\n</code></pre>"},{"location":"wazuh/wazuh.html#wazuh-dashboard","title":"Wazuh dashboard","text":"<p>Click the upper-left menu icon and navigate to\u00a0Dashboard management\u00a0&gt;\u00a0Index patterns\u00a0&gt;\u00a0Create index pattern. Use\u00a0<code>wazuh-archives-*</code>\u00a0as the index pattern name, and set\u00a0<code>timestamp</code>\u00a0in the\u00a0Time field\u00a0drop-down list.</p> <p></p> <p></p> <p>To view the events on the dashboard, click the upper-left menu icon and navigate to\u00a0Discover. Change the index pattern to\u00a0<code>wazuh-archives-*</code>.</p> <p></p>"},{"location":"wazuh/wazuh.html#use-case-detecting-signed-binary-proxy-execution","title":"Use case: Detecting Signed Binary Proxy Execution","text":"<p>Signed binary proxy execution is a technique threat actors use to bypass application whitelisting by using trusted binaries to run malicious code. This technique is identified as\u00a0<code>T1218.010</code>\u00a0based on the MITRE ATT&amp;CK framework.</p> <p>In this use case, we show how to abuse the Windows utility,\u00a0<code>regsvr32.exe</code>, to bypass application controls. We then analyze events in the Wazuh archives to detect suspicious activity related to this technique.</p>"},{"location":"wazuh/wazuh.html#atomic-red-team-installation","title":"Atomic Red Team installation","text":"<p>Note: this has been tested in an isolated Unclassified environment. </p> <p>Perform the following steps to install the Atomic Red Team PowerShell module on a Windows endpoint using PowerShell as an administrator.</p> <p>By default, PowerShell restricts the execution of running scripts. Run the command below to change the default execution policy to\u00a0<code>RemoteSigned</code>:</p> <pre><code>Set-ExecutionPolicy RemoteSigned\n</code></pre> <p>Install the ART execution framework:</p> <p>Internet access has been enabled at this point</p> <pre><code>IEX (IWR 'https://raw.githubusercontent.com/redcanaryco/invoke-atomicredteam/master/install-atomicredteam.ps1' -UseBasicParsing);\nInstall-AtomicRedTeam -getAtomics\n</code></pre> <p>Import the ART module to use\u00a0<code>Invoke-AtomicTest</code>\u00a0function</p> <pre><code>Import-Module \"C:\\AtomicRedTeam\\invoke-atomicredteam\\Invoke-AtomicRedTeam.psd1\" -Force\n</code></pre> <p>Use\u00a0<code>Invoke-AtomicTest</code>\u00a0function to show details of the technique\u00a0<code>T1218.010</code></p> <pre><code>Invoke-AtomicTest T1218.010 -ShowDetailsBrief\n</code></pre> <pre><code>#Output\nPathToAtomicsFolder = C:\\AtomicRedTeam\\atomics\n\nT1218.010-1 Regsvr32 local COM scriptlet execution\nT1218.010-2 Regsvr32 remote COM scriptlet execution\nT1218.010-3 Regsvr32 local DLL execution\nT1218.010-4 Regsvr32 Registering Non DLL\nT1218.010-5 Regsvr32 Silent DLL Install Call DllRegisterServer\n</code></pre>"},{"location":"wazuh/wazuh.html#attack-emulation","title":"Attack emulation","text":"<p>Emulate the signed binary proxy execution technique on the Windows endpoint.</p> <p>Run the command below with Powershell as an administrator to perform the\u00a0<code>T1218.010</code>\u00a0test</p> <pre><code>Invoke-AtomicTest T1218.010\n</code></pre> <pre><code>#Output\nPathToAtomicsFolder = C:\\AtomicRedTeam\\atomics\n\nExecuting test: T1218.010-1 Regsvr32 local COM scriptlet execution\nDone executing test: T1218.010-1 Regsvr32 local COM scriptlet execution\nExecuting test: T1218.010-2 Regsvr32 remote COM scriptlet execution\nDone executing test: T1218.010-2 Regsvr32 remote COM scriptlet execution\nExecuting test: T1218.010-3 Regsvr32 local DLL execution\nDone executing test: T1218.010-3 Regsvr32 local DLL execution\nExecuting test: T1218.010-4 Regsvr32 Registering Non DLL\nDone executing test: T1218.010-4 Regsvr32 Registering Non DLL\nExecuting test: T1218.010-5 Regsvr32 Silent DLL Install Call DllRegisterServer\nDone executing test: T1218.010-5 Regsvr32 Silent DLL Install Call DllRegisterServer\n</code></pre> <p>Several calculator instances will pop up after a successful execution of the exploit.</p> <p></p>"},{"location":"wazuh/wazuh.html#wazuh-dashboard_1","title":"Wazuh dashboard","text":"<p>Use the Wazuh archives to query and display events related to the technique being hunted. It's important to note that while consulting the archives, some events might already be captured as alerts on the Wazuh dashboard. You can use information from the Wazuh archives, including alerts and events that have no detection to create custom rules based on your specific requirements.</p> <p>Apply a time range filter to view events that occurred within the last five minutes of when the test was performed. Filter to view logs from the specific Windows endpoint using\u00a0<code>agent.id</code>,\u00a0<code>agent.ip</code>\u00a0or\u00a0<code>agent.name</code>.</p> <p></p> <p>There are multiple hits that you can investigate to determine a correlation with the earlier attack emulation. For instance, you may notice a calculator spawning event similar to the one observed on the Windows endpoint during the test.</p> <p></p> <p>Type\u00a0<code>regsvr32</code>\u00a0in the search bar to streamline and investigate events related to the\u00a0<code>regsvr32</code>\u00a0utility.</p> <p></p> <p>Expand any of the events to view their associated fields.</p> <p></p> <p>Click on the JSON tab to view the JSON format of the archived logs.</p> <p></p> <p>Apply the\u00a0<code>data.win.eventdata.ruleName:technique_id=T1218.010,technique_name=Regsvr32</code>\u00a0filter to see the technique ID as shown below.</p> <p></p> <p>It is recommended to enable archiving as it allows users to view logs from network devices. However, if you prefer not to enable archiving, similar search can be performed on wazuh-alerts- (default) index instead of wazuh-archives- index.</p> <p>Navigate to Home, then Overview on the web UI</p> <p>Select number displayed on the Critical severity</p> <p></p> <p></p> <p>Clear all filters then add the filter data.wineventda.image is C:\\Windows\\SYSWOW64\\regsvr32.exe</p> <p></p>"},{"location":"wazuh/wazuh.html#troubleshooting-index-patterns","title":"Troubleshooting Index Patterns","text":"<p>If search results displays the error icon and the message \u201cNo cached mapping for this field. Refresh field list from the index patterns page,\u201d go to Dashboard Management, Index patterns and select each index. Click refresh button. </p> <p></p> <p></p>"},{"location":"wazuh/wazuh.html#detecting-suspicious-binaries-testing-endpoint-security","title":"Detecting Suspicious Binaries (Testing Endpoint Security)","text":"<p>Wazuh has anomaly and malware detection capabilities that detect suspicious binaries on an endpoint. Binaries are executable code written to perform automated tasks. Malicious actors use them mostly to carry out exploitation to avoid being detected.</p> <p>In this use case, we demonstrate how the Wazuh rootcheck module can detect a trojan system binary on an Ubuntu endpoint. You perform the exploit by replacing the content of a legitimate binary with malicious code to trick the endpoint into running it as the legitimate binary.</p> <p>The Wazuh rootcheck module also checks for hidden processes, ports, and files.</p>"},{"location":"wazuh/wazuh.html#configuration","title":"Configuration","text":"<p>Take the following steps on the Ubuntu endpoint to enable the Wazuh rootcheck module and perform anomaly and malware detection.</p> <p>By default, the Wazuh rootcheck module is enabled in the Wazuh agent configuration file. Check the\u00a0<code>&lt;rootcheck&gt;</code>\u00a0block in the\u00a0<code>/var/ossec/etc/ossec.conf</code>\u00a0configuration file of the monitored endpoint and make sure that it has the configuration below:</p> <pre><code>&lt;rootcheck&gt;\n    &lt;disabled&gt;no&lt;/disabled&gt;\n    &lt;check_files&gt;yes&lt;/check_files&gt;\n\n    &lt;!-- Line for trojans detection --&gt;\n    &lt;check_trojans&gt;yes&lt;/check_trojans&gt;\n\n    &lt;check_dev&gt;yes&lt;/check_dev&gt;\n    &lt;check_sys&gt;yes&lt;/check_sys&gt;\n    &lt;check_pids&gt;yes&lt;/check_pids&gt;\n    &lt;check_ports&gt;yes&lt;/check_ports&gt;\n    &lt;check_if&gt;yes&lt;/check_if&gt;\n\n    &lt;!-- Frequency that rootcheck is executed - every 12 hours --&gt;\n    &lt;frequency&gt;43200&lt;/frequency&gt;\n    &lt;rootkit_files&gt;/var/ossec/etc/shared/rootkit_files.txt&lt;/rootkit_files&gt;\n    &lt;rootkit_trojans&gt;/var/ossec/etc/shared/rootkit_trojans.txt&lt;/rootkit_trojans&gt;\n    &lt;skip_nfs&gt;yes&lt;/skip_nfs&gt;\n&lt;/rootcheck&gt;\n</code></pre>"},{"location":"wazuh/wazuh.html#attack-emulation_1","title":"Attack emulation","text":"<p>Create a copy of the original system binary:</p> <pre><code>sudo cp -p /usr/bin/w /usr/bin/w.copy\n</code></pre> <p>Replace the original system binary\u00a0<code>/usr/bin/w</code>\u00a0with the following shell script:</p> <pre><code>sudo tee /usr/bin/w &lt;&lt; EOF\n!/bin/bash\necho \"`date` this is evil\" &gt; /tmp/trojan_created_file\necho 'test for /usr/bin/w trojaned file' &gt;&gt; /tmp/trojan_created_file\nNow running original binary\n/usr/bin/w.copy\nEOF\n</code></pre> <p>The rootcheck scan runs every 12 hours by default. Force a scan by restarting the Wazuh agent to see the relevant alert:</p> <pre><code>sudo systemctl restart wazuh-agent\n</code></pre>"},{"location":"wazuh/wazuh.html#visualise-the-alerts","title":"Visualise the alerts","text":"<p>You can visualise the alert data in the Wazuh dashboard. To do this, go to the\u00a0Threat Hunting\u00a0module and add the filters in the search bar to query the alerts. <code>location:rootcheck AND rule.id:510</code></p> <p></p>"},{"location":"wazuh/wazuh.html#file-integrity-monitoring-testing-endpoint-security","title":"File Integrity Monitoring (Testing Endpoint Security)","text":"<p>File Integrity Monitoring (FIM) helps in auditing sensitive files and meeting regulatory compliance requirements. Wazuh has an inbuilt\u00a0FIM\u00a0module that monitors file system changes to detect the creation, modification, and deletion of files.</p>"},{"location":"wazuh/wazuh.html#configuration-on-ubuntu-endpoint","title":"Configuration on Ubuntu endpoint","text":"<p>Edit the Wazuh agent\u00a0<code>/var/ossec/etc/ossec.conf</code>\u00a0configuration file. Add the directories for monitoring within the\u00a0<code>&lt;syscheck&gt;</code>\u00a0block. For this use case, you configure Wazuh to monitor the\u00a0<code>/root</code>\u00a0directory.\u00a0</p> <pre><code>&lt;directories check_all=\"yes\" report_changes=\"yes\" realtime=\"yes\"&gt;/root&lt;/directories&gt;\n</code></pre> <p>Restart the Wazuh agent to apply the configuration changes:</p> <pre><code>sudo systemctl restart wazuh-agent\n</code></pre>"},{"location":"wazuh/wazuh.html#test-the-configuration","title":"Test the configuration","text":"<ol> <li>Create a text file in the monitored directory then wait for 5 seconds.</li> <li>Add content to the text file and save it. Wait for 5 seconds.</li> <li>Delete the text file from the monitored directory.</li> </ol>"},{"location":"wazuh/wazuh.html#visualise-the-alerts_1","title":"Visualise the alerts","text":"<p>You can visualise the alert data in the Wazuh dashboard. To do this, go to the\u00a0File Integrity Monitoring\u00a0module and add the filters in the search bar to query the alerts:<code>rule.id:\u00a0is\u00a0one\u00a0of\u00a0550,553,554</code></p> <p></p>"},{"location":"wazuh/wazuh.html#vulnerability-detection-testing-threat-intelligence","title":"Vulnerability Detection (Testing Threat Intelligence)","text":"<p>Wazuh uses the Vulnerability Detection module to identify vulnerabilities in applications and operating systems running on endpoints.</p> <p>This use case shows how Wazuh detects unpatched Common Vulnerabilities and Exposures (CVEs) in the monitored endpoint.</p>"},{"location":"wazuh/wazuh.html#configuration_1","title":"Configuration","text":"<p>The Vulnerability Detection module is enabled by default. You can perform the following steps on the Wazuh server to ensure that the Wazuh Vulnerability Detection module is enabled and properly configured.</p> <p>Open the\u00a0<code>/var/ossec/etc/ossec.conf</code>\u00a0file on the Wazuh server. Check the following settings. Vulnerability Detection is enabled:</p> <pre><code>&lt;vulnerability-detection&gt;\n   &lt;enabled&gt;yes&lt;/enabled&gt;\n   &lt;index-status&gt;yes&lt;/index-status&gt;\n   &lt;feed-update-interval&gt;60m&lt;/feed-update-interval&gt;\n&lt;/vulnerability-detection&gt;\n</code></pre> <p>The indexer connection is properly configured.</p> <p>By default, the indexer settings have one host configured. It's set to\u00a0<code>0.0.0.0</code>\u00a0as highlighted below.</p> <pre><code>&lt;indexer&gt;\n  &lt;enabled&gt;yes&lt;/enabled&gt;\n  &lt;hosts&gt;\n    &lt;host&gt;https://0.0.0.0:9200&lt;/host&gt;\n  &lt;/hosts&gt;\n  &lt;ssl&gt;\n    &lt;certificate_authorities&gt;\n      &lt;ca&gt;/etc/filebeat/certs/root-ca.pem&lt;/ca&gt;\n    &lt;/certificate_authorities&gt;\n    &lt;certificate&gt;/etc/filebeat/certs/filebeat.pem&lt;/certificate&gt;\n    &lt;key&gt;/etc/filebeat/certs/filebeat-key.pem&lt;/key&gt;\n  &lt;/ssl&gt;\n&lt;/indexer&gt;\n</code></pre> <p>Replace\u00a0<code>0.0.0.0</code>\u00a0with your Wazuh indexer node IP address or hostname. You can find this value in the Filebeat config file\u00a0<code>/etc/filebeat/filebeat.yml</code>.</p> <p>Ensure the Filebeat certificate and key name match the certificate files in\u00a0<code>/etc/filebeat/certs</code>.</p> <p>If you made changes to the configuration, restart the Wazuh manager.</p> <pre><code>sudo systemctl restart wazuh-manager\n</code></pre>"},{"location":"wazuh/wazuh.html#visualise-the-alerts_2","title":"Visualise the alerts","text":"<p>You can visualise the detected vulnerabilities in the Wazuh dashboard. To see a list of active vulnerabilities, go to\u00a0Vulnerability Detection\u00a0and select\u00a0Inventory.</p> <p></p> <p></p>"},{"location":"wazuh/wazuh.html#incident-response","title":"Incident response","text":"<p>The goal of incident response is to effectively handle a security incident and restore normal business operations as quickly as possible. As organizations\u2019 digital assets continuously grow, managing incidents manually becomes increasingly challenging, hence the need for automation.</p>"},{"location":"wazuh/wazuh.html#wazuh-active-response-module","title":"Wazuh Active Response module","text":"<p>The Wazuh\u00a0Active Response\u00a0module allows users to run automated actions when incidents are detected on endpoints. This improves an organization's incident response processes, enabling security teams to take immediate and automated actions to counter detected threats.</p>"},{"location":"wazuh/wazuh.html#default-active-response-actions","title":"Default active response actions","text":"<p>Out-of-the-box scripts are available on every operating system that runs the Wazuh agents. Some of the\u00a0default active response\u00a0scripts include</p> Name of script Description disable-account Disables a user account firewall-drop Adds an IP address to the iptables deny list. firewalld-drop Adds an IP address to the firewalld drop list. restart.sh Restarts the Wazuh agent or server. netsh.exe Blocks an IP address using netsh."},{"location":"wazuh/wazuh.html#custom-active-response-actions","title":"Custom active response actions","text":"<p>One of the benefits of the Wazuh Active Response module is its adaptability. Wazuh allows security teams to create\u00a0custom active response\u00a0actions in any programming language, tailoring them to their specific needs.</p>"},{"location":"wazuh/wazuh.html#disabling-user-account-after-a-brute-force-attack-testing-default-active-response","title":"Disabling User Account After a Brute-Force Attack (Testing Default Active Response)","text":"<p>Account lockout is a security measure used to defend against brute force attacks by limiting the number of login attempts a user can make within a specified time. We use the Wazuh Active Response module to disable the user account whose password is being guessed by an attacker.</p> <p>In the image below, the Wazuh Active Response module disables the account on a Linux endpoint and re-enables it again after 5 minutes.</p> <p>After SSH Brute Force attack was launched from Kali machine, the login was disabled for 60 seconds because of 3 bad attempts</p> <p></p>"},{"location":"wazuh/wazuh.html#blocking-a-known-malicious-actor-testing-custom-active-response","title":"Blocking a Known Malicious Actor (Testing Custom Active Response)","text":"<p>In this use case, we demonstrate how to block malicious IP addresses from accessing web resources on a web server. </p>"},{"location":"wazuh/wazuh.html#configure-ubuntu-endpoint","title":"Configure Ubuntu endpoint","text":"<p>Update local packages and install the Apache web server:</p> <pre><code>sudo apt update\nsudo apt install apache2\n</code></pre> <p>If the firewall is enabled, modify the firewall to allow external access to web ports. Skip this step if the firewall is disabled:</p> <pre><code>sudo ufw status\nsudo ufw app list\nsudo ufw allow 'Apache'\n</code></pre> <p>Check the status of the Apache service to verify that the web server is running:</p> <pre><code>sudo systemctl status apache2\n</code></pre> <p>Use the\u00a0<code>curl</code>\u00a0command or open\u00a0<code>http://&lt;UBUNTU_IP&gt;</code>\u00a0in a browser to view the Apache landing page and verify the installation:</p> <pre><code>curl http://&lt;UBUNTU_IP&gt;\n</code></pre> <p>Add the following to\u00a0<code>/var/ossec/etc/ossec.conf</code>\u00a0file to configure the Wazuh agent and monitor the Apache access logs:</p> <pre><code>&lt;localfile&gt;\n  &lt;log_format&gt;syslog&lt;/log_format&gt;\n  &lt;location&gt;/var/log/apache2/access.log&lt;/location&gt;\n&lt;/localfile&gt;\n</code></pre> <p>Restart the Wazuh agent to apply the changes:</p> <pre><code>sudo systemctl restart wazuh-agent\n</code></pre>"},{"location":"wazuh/wazuh.html#configure-the-wazuh-server","title":"Configure the Wazuh server","text":"<p>Download the utilities and configure the CDB list.</p> <p>Download the Alienvault IP reputation database:</p> <pre><code>sudo wget https://raw.githubusercontent.com/firehol/blocklist-ipsets/master/alienvault_reputation.ipset -O /var/ossec/etc/lists/alienvault_reputation.ipset\n</code></pre> <p>Append the IP address of the attacker endpoint to the IP reputation database. Replace\u00a0<code>&lt;ATTACKER_IP&gt;</code>\u00a0with the Kali IP address in the command below:</p> <pre><code>sudo echo \"&lt;ATTACKER_IP&gt;\" &gt;&gt; /var/ossec/etc/lists/alienvault_reputation.ipset\n</code></pre> <p>Download a script to convert from the\u00a0<code>.ipset</code>\u00a0format to the\u00a0<code>.cdb</code>\u00a0list format:</p> <pre><code>sudo wget https://wazuh.com/resources/iplist-to-cdblist.py -O /tmp/iplist-to-cdblist.py\n</code></pre> <p>Convert the\u00a0<code>alienvault_reputation.ipset</code>\u00a0file to a\u00a0<code>.cdb</code>\u00a0format using the previously downloaded script:</p> <pre><code>sudo /var/ossec/framework/python/bin/python3 /tmp/iplist-to-cdblist.py /var/ossec/etc/lists/alienvault_reputation.ipset /var/ossec/etc/lists/blacklist-alienvault\n</code></pre> <p>Assign the right permissions and ownership to the generated file:</p> <pre><code>sudo chown wazuh:wazuh /var/ossec/etc/lists/blacklist-alienvault\n</code></pre>"},{"location":"wazuh/wazuh.html#configure-the-active-response-module-to-block-the-malicious-ip-address","title":"Configure the active response module to block the malicious IP address","text":"<p>Add a custom rule to trigger a Wazuh\u00a0active response\u00a0script. Do this in the Wazuh server\u00a0<code>/var/ossec/etc/rules/local_rules.xml</code>\u00a0custom ruleset file:</p> <pre><code>&lt;group name=\"attack,\"&gt;\n  &lt;rule id=\"100100\" level=\"10\"&gt;\n    &lt;if_group&gt;web|attack|attacks&lt;/if_group&gt;\n    &lt;list field=\"srcip\" lookup=\"address_match_key\"&gt;etc/lists/blacklist-alienvault&lt;/list&gt;\n    &lt;description&gt;IP address found in AlienVault reputation database.&lt;/description&gt;\n  &lt;/rule&gt;\n&lt;/group&gt;\n</code></pre> <p>Edit the Wazuh server\u00a0<code>/var/ossec/etc/ossec.conf</code>\u00a0configuration file and add the\u00a0<code>etc/lists/blacklist-alienvault</code>\u00a0list to the\u00a0<code>&lt;ruleset&gt;</code>\u00a0section:</p> <pre><code>&lt;ossec_config&gt;\n  &lt;ruleset&gt;\n    &lt;!-- Default ruleset --&gt;\n    &lt;decoder_dir&gt;ruleset/decoders&lt;/decoder_dir&gt;\n    &lt;rule_dir&gt;ruleset/rules&lt;/rule_dir&gt;\n    &lt;rule_exclude&gt;0215-policy_rules.xml&lt;/rule_exclude&gt;\n    &lt;list&gt;etc/lists/audit-keys&lt;/list&gt;\n    &lt;list&gt;etc/lists/amazon/aws-eventnames&lt;/list&gt;\n    &lt;list&gt;etc/lists/security-eventchannel&lt;/list&gt;\n    **&lt;list&gt;etc/lists/blacklist-alienvault&lt;/list&gt;**\n\n    &lt;!-- User-defined ruleset --&gt;\n    &lt;decoder_dir&gt;etc/decoders&lt;/decoder_dir&gt;\n    &lt;rule_dir&gt;etc/rules&lt;/rule_dir&gt;\n  &lt;/ruleset&gt;\n\n&lt;/ossec_config&gt;\n</code></pre> <p>Add the active response block to the Wazuh server\u00a0<code>/var/ossec/etc/ossec.conf</code>\u00a0file:</p> <p>The\u00a0<code>firewall-drop</code>\u00a0command integrates with the Ubuntu local iptables firewall and drops incoming network connection from the attacker endpoint for 60 seconds: Remember to uncomment the code block (remove <code>&lt;!--</code> and <code>--&gt;</code> )</p> <pre><code>&lt;ossec_config&gt;\n  &lt;active-response&gt;\n    &lt;command&gt;firewall-drop&lt;/command&gt;\n    &lt;location&gt;local&lt;/location&gt;\n    &lt;rules_id&gt;100100&lt;/rules_id&gt;\n    &lt;timeout&gt;60&lt;/timeout&gt;\n  &lt;/active-response&gt;\n&lt;/ossec_config&gt;\n</code></pre> <p>Restart the Wazuh manager to apply the changes:</p> <pre><code>sudo systemctl restart wazuh-manager\n</code></pre>"},{"location":"wazuh/wazuh.html#attack-emulation_2","title":"Attack emulation","text":"<p>Access any of the web servers from the Kali endpoint using the corresponding IP address. Replace\u00a0<code>&lt;WEBSERVER_IP&gt;</code>\u00a0with the appropriate value and execute the following command from the attacker endpoint:</p> <pre><code>curl http://&lt;WEBSERVER_IP&gt;\n</code></pre> <p>The attacker endpoint connects to the victim's web servers the first time. After the first connection, the Wazuh active response module temporarily blocks any successive connection to the web servers for 60 seconds.</p> <p></p>"},{"location":"wazuh/wazuh.html#visualise-the-alerts_3","title":"Visualise the alerts","text":"<p>You can visualize the alert data in the Wazuh dashboard. To do this, go to the\u00a0Threat Hunting\u00a0module and add the filters in the search bar to query the alerts:\u00a0<code>rule.id is one of 651, 100100</code></p> <p></p>"},{"location":"wazuh/wazuh.html#network-ids-integration","title":"Network IDS integration","text":""},{"location":"wazuh/wazuh.html#snort3","title":"Snort3","text":"<p>Install Wazuh agent on a Linux host where Snort3 is installed.</p> <p>Edit Snort\u2019s configuration </p> <pre><code>sudo nano /usr/local/etc/snort/snort.lua\n</code></pre> <p>Uncomment alert_full and add file=true</p> <pre><code>---------------------------------------------------------------------------\n-- 7. configure outputs\n---------------------------------------------------------------------------\n\n-- event logging\n-- you can enable with defaults from the command line with -A &lt;alert_type&gt;\n-- uncomment below to set non-default configs\n--alert_csv = { }\n--alert_fast = {file=true}\nalert_full = {file=true}\n--alert_sfsocket = { }\n--alert_syslog = { }\n--unified2 = { }\n</code></pre> <p>Edit the\u00a0<code>/var/ossec/etc/ossec.conf</code>\u00a0file of Wazuh agent and add the new\u00a0<code>localfile</code>\u00a0entry: Make sure indentation is correct.</p> <pre><code>&lt;localfile&gt;\n  &lt;log_format&gt;snort-full&lt;/log_format&gt;\n  &lt;location&gt;/var/log/snort/alert_full.txt&lt;/location&gt;\n&lt;/localfile&gt;\n</code></pre> <p>Restart the Wazuh agent</p> <pre><code>systemctl restart wazuh-agent\n</code></pre> <p>Run Snort3 with the following parameter</p> <pre><code>sudo snort -c /usr/local/etc/snort/snort.lua -i ens32 -A alert_full -l /var/log/snort\n</code></pre> <p>Note: Snort3 is currently configured to read local.rules for demonstration purposes.</p> <p>Execute ping to 10.0.0.22 (Snort3 VM) from another host.</p> <p>Verify alert_full.txt is generated</p> <pre><code>root@Snort:/var/log/snort# ls\nalert_fast.txt  alert_full.txt\n</code></pre> <p>On Wazuh dashboard, verify IDS Event alerts are generated and it points to alert_full.txt</p> <p></p> <p></p>"},{"location":"wazuh/wazuh.html#suricata","title":"Suricata","text":"<p>Install Wazuh agent on a Linux host where Suricata is installed.</p> <p>Changes the permissions of all files in the Suricata\u2019s <code>/rules/</code> directories</p> <pre><code>sudo chmod 640 /var/lib/suricata/rules/*.rules\nsudo chmod 640 /usr/share/suricata/rules/*.rules\n</code></pre> <p>Modify Suricata settings in the\u00a0<code>/etc/suricata/suricata.yaml</code>\u00a0file and set the following variables:</p> <pre><code>vars:\n  # more specific is better for alert accuracy and performance\n  address-groups:\n    HOME_NET: \"[10.0.0.0/24]\"\n...\ncommunity-id: true\n...\naf-packet:\n    - interface: ens32\n      cluster-id: 99\n      cluster-type: cluster_flow\n      defrag: yes\n      use-mmap: yes\n...\n# Cross platform libpcap capture support\npcap:\n  - interface: ens32\n</code></pre> <p><code>interface</code>\u00a0represents the network interface you want to monitor. Replace the value with the interface name of the Ubuntu endpoint. For example,\u00a0<code>ens32</code> </p> <p>Restart the Suricata service:</p> <pre><code>sudo systemctl restart suricata\n</code></pre> <p>Add the following configuration to the <code>/var/ossec/etc/ossec.conf</code> file of the Wazuh agent. This allows the Wazuh agent to read the Suricata logs file:</p> <pre><code>&lt;ossec_config&gt;\n  &lt;localfile&gt;\n    &lt;log_format&gt;json&lt;/log_format&gt;\n    &lt;location&gt;/var/log/suricata/eve.json&lt;/location&gt;\n  &lt;/localfile&gt;\n&lt;/ossec_config&gt;\n</code></pre> <p>Restart the Wazuh agent to apply the changes:</p> <pre><code>sudo systemctl restart wazuh-agent\n</code></pre>"},{"location":"wazuh/wazuh.html#attack-emulation_3","title":"Attack emulation","text":"<p>Wazuh automatically parses data from\u00a0<code>/var/log/suricata/eve.json</code>\u00a0and generates related alerts on the Wazuh dashboard. From the Ubuntu host, run </p> <pre><code>curl http://testmynids.org/uid/index.html\n</code></pre> <p>Expected response should be similar to:</p> <pre><code>09/12/2024-13:51:32.520238  [**] [1:2100498:7] GPL ATTACK_RESPONSE id check returned root [**] [Classification: Potentially Bad Traffic] [Priority: 2] {TCP} 65.9.141.53:80 -&gt; 10.0.0.25:34606Alerts:\n</code></pre> <p>Verify the results in Wazuh dashboard. Naviage to Threat Hunting &gt; Suricata</p> <p></p>"},{"location":"wazuh/wazuh.html#references","title":"References","text":"<ul> <li>https://www.youtube.com/watch?v=Lb_ukgtYK_U&amp;list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&amp;index=5</li> <li>https://documentation.wazuh.com/current/deployment-options/offline-installation.html</li> <li>https://wazuh.com/blog/monitoring-network-devices/?highlight=network device</li> <li>https://dorian5.medium.com/rsyslog-setup-on-ubuntu-for-fortigate-log-data-9d6c651acbd0</li> <li>https://wazuh.com/blog/monitoring-network-devices/?highlight=network device</li> <li>https://wazuh.com/blog/creating-decoders-and-rules-from-scratch/?highlight=fortigate</li> </ul>"}]}